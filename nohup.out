wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 1024
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_Math1.5B_tok1k_dapo17k
2025-04-18 17:13:57,631	INFO worker.py:1832 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=13351)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=13351)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=13351)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=13351)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=13351)[0m                                                  'param_offload': False,
[36m(main_task pid=13351)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=13351)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=13351)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=13351)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=13351)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=13351)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=13351)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=13351)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=13351)[0m                                            'total_training_steps': -1,
[36m(main_task pid=13351)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=13351)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=13351)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=13351)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=13351)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=13351)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=13351)[0m                                  'response_length': 1024,
[36m(main_task pid=13351)[0m                                  'shuffle': False,
[36m(main_task pid=13351)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=13351)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=13351)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=13351)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=13351)[0m                                  'use_kl_loss': False,
[36m(main_task pid=13351)[0m                                  'use_torch_compile': True},
[36m(main_task pid=13351)[0m                        'hybrid_engine': True,
[36m(main_task pid=13351)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=13351)[0m                                  'external_lib': None,
[36m(main_task pid=13351)[0m                                  'override_config': {},
[36m(main_task pid=13351)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=13351)[0m                                  'use_remove_padding': True},
[36m(main_task pid=13351)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=13351)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=13351)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=13351)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=13351)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=13351)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=13351)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=13351)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=13351)[0m                                    'disable_log_stats': True,
[36m(main_task pid=13351)[0m                                    'do_sample': True,
[36m(main_task pid=13351)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=13351)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=13351)[0m                                    'enforce_eager': True,
[36m(main_task pid=13351)[0m                                    'free_cache_engine': True,
[36m(main_task pid=13351)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=13351)[0m                                    'ignore_eos': False,
[36m(main_task pid=13351)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=13351)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=13351)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=13351)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=13351)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=13351)[0m                                    'max_model_len': None,
[36m(main_task pid=13351)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=13351)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=13351)[0m                                    'n': 1,
[36m(main_task pid=13351)[0m                                    'name': 'vllm',
[36m(main_task pid=13351)[0m                                    'prompt_length': 512,
[36m(main_task pid=13351)[0m                                    'response_length': 1024,
[36m(main_task pid=13351)[0m                                    'temperature': 1.0,
[36m(main_task pid=13351)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=13351)[0m                                    'top_k': -1,
[36m(main_task pid=13351)[0m                                    'top_p': 1,
[36m(main_task pid=13351)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=13351)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=13351)[0m                                                   'n': 1,
[36m(main_task pid=13351)[0m                                                   'temperature': 0,
[36m(main_task pid=13351)[0m                                                   'top_k': -1,
[36m(main_task pid=13351)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=13351)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=13351)[0m                'gamma': 1.0,
[36m(main_task pid=13351)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=13351)[0m                'kl_penalty': 'kl',
[36m(main_task pid=13351)[0m                'lam': 1.0},
[36m(main_task pid=13351)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=13351)[0m             'estimate_prompts_value': False,
[36m(main_task pid=13351)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=13351)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=13351)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=13351)[0m             'grad_clip': 1.0,
[36m(main_task pid=13351)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=13351)[0m                       'external_lib': None,
[36m(main_task pid=13351)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=13351)[0m                                       'optimizer_offload': False,
[36m(main_task pid=13351)[0m                                       'param_offload': False,
[36m(main_task pid=13351)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=13351)[0m                       'override_config': {},
[36m(main_task pid=13351)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=13351)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=13351)[0m                       'use_remove_padding': False},
[36m(main_task pid=13351)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=13351)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=13351)[0m                       'min_lr_ratio': None,
[36m(main_task pid=13351)[0m                       'total_training_steps': -1,
[36m(main_task pid=13351)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=13351)[0m             'ppo_epochs': 1,
[36m(main_task pid=13351)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=13351)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=13351)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=13351)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=13351)[0m             'shuffle': False,
[36m(main_task pid=13351)[0m             'strategy': 'fsdp',
[36m(main_task pid=13351)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=13351)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=13351)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=13351)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=13351)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=13351)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=13351)[0m                 'warmup_steps': 2},
[36m(main_task pid=13351)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=13351)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=13351)[0m           'image_key': 'images',
[36m(main_task pid=13351)[0m           'max_prompt_length': 512,
[36m(main_task pid=13351)[0m           'max_response_length': 1024,
[36m(main_task pid=13351)[0m           'prompt_key': 'prompt',
[36m(main_task pid=13351)[0m           'return_raw_chat': False,
[36m(main_task pid=13351)[0m           'return_raw_input_ids': False,
[36m(main_task pid=13351)[0m           'shuffle': True,
[36m(main_task pid=13351)[0m           'tokenizer': None,
[36m(main_task pid=13351)[0m           'train_batch_size': 1024,
[36m(main_task pid=13351)[0m           'train_files': './data/DAPO-base/train.parquet',
[36m(main_task pid=13351)[0m           'truncation': 'error',
[36m(main_task pid=13351)[0m           'use_chat_template': False,
[36m(main_task pid=13351)[0m           'val_batch_size': None,
[36m(main_task pid=13351)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=13351)[0m  'reward_model': {'enable': False,
[36m(main_task pid=13351)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=13351)[0m                   'max_length': None,
[36m(main_task pid=13351)[0m                   'micro_batch_size': None,
[36m(main_task pid=13351)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=13351)[0m                   'model': {'external_lib': None,
[36m(main_task pid=13351)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=13351)[0m                                             'param_offload': False,
[36m(main_task pid=13351)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=13351)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=13351)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=13351)[0m                             'use_remove_padding': False},
[36m(main_task pid=13351)[0m                   'reward_manager': 'naive',
[36m(main_task pid=13351)[0m                   'strategy': 'fsdp',
[36m(main_task pid=13351)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=13351)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=13351)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=13351)[0m              'critic_warmup': 0,
[36m(main_task pid=13351)[0m              'default_hdfs_dir': None,
[36m(main_task pid=13351)[0m              'default_local_dir': 'checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=13351)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=13351)[0m              'experiment_name': 'ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=13351)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=13351)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=13351)[0m              'nnodes': 1,
[36m(main_task pid=13351)[0m              'project_name': 'grpo',
[36m(main_task pid=13351)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=13351)[0m              'resume_from_path': False,
[36m(main_task pid=13351)[0m              'resume_mode': 'auto',
[36m(main_task pid=13351)[0m              'save_freq': -1,
[36m(main_task pid=13351)[0m              'test_freq': 3,
[36m(main_task pid=13351)[0m              'total_epochs': 10,
[36m(main_task pid=13351)[0m              'total_training_steps': None,
[36m(main_task pid=13351)[0m              'val_before_train': True,
[36m(main_task pid=13351)[0m              'val_generations_to_log_to_wandb': 0}}
[36m(main_task pid=13351)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=13351)[0m No module named 'vllm._version'
[36m(main_task pid=13351)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=13351)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=13351)[0m dataset len: 1791700
[36m(main_task pid=13351)[0m Example prompt before filtering: [{'content': 'Solve the following math problem step by step. The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.\n\nIn triangle $ABC$, $\\sin \\angle A = \\frac{4}{5}$ and $\\angle A < 90^\\circ$. Let $D$ be a point outside triangle $ABC$ such that $\\angle BAD = \\angle DAC$ and $\\angle BDC = 90^\\circ$. Suppose that $AD = 1$ and that $\\frac{BD}{CD} = \\frac{3}{2}$. If $AB + AC$ can be expressed in the form $\\frac{a\\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.\n\nRemember to put your answer on its own line after "Answer:".', 'role': 'user'}]
Error executing job with overrides: ['data.train_files=./data/DAPO-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=1024', 'data.max_prompt_length=512', 'data.max_response_length=1024', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=256', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-1.5B', 'critic.ppo_micro_batch_size_per_gpu=32', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=True', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=3', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo_Math1.5B_tok1k_dapo17k', 'trainer.total_epochs=10']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TypeError): [36mray::main_task()[39m (pid=13351, ip=192.168.159.207)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 170, in main_task
    trainer = RayPPOTrainer(config=config,
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 310, in __init__
    self._create_dataloader()
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 408, in _create_dataloader
    self.train_dataset = RLHFDataset(parquet_files=self.config.data.train_files,
  File "/home/jovyan/project/verl/verl/utils/dataset/rl_dataset.py", line 119, in __init__
    self._read_files_and_tokenize()
  File "/home/jovyan/project/verl/verl/utils/dataset/rl_dataset.py", line 151, in _read_files_and_tokenize
    self.dataframe = self.dataframe[self.dataframe.apply(lambda doc: len(
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/pandas/core/frame.py", line 10374, in apply
    return op.apply().__finalize__(self, method="apply")
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/pandas/core/apply.py", line 916, in apply
    return self.apply_standard()
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/pandas/core/apply.py", line 1063, in apply_standard
    results, res_index = self.apply_series_generator()
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/pandas/core/apply.py", line 1081, in apply_series_generator
    results[i] = self.func(v, *self.args, **self.kwargs)
  File "/home/jovyan/project/verl/verl/utils/dataset/rl_dataset.py", line 152, in <lambda>
    tokenizer.encode(doc[prompt_key], add_special_tokens=False)) <= self.max_prompt_length,
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2627, in encode
    encoded_inputs = self.encode_plus(
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 3046, in encode_plus
    return self._encode_plus(
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py", line 600, in _encode_plus
    batched_output = self._batch_encode_plus(
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py", line 526, in _batch_encode_plus
    encodings = self._tokenizer.encode_batch(
TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 1024
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_Math1.5B_tok1k_dapo17k
2025-04-18 17:22:28,911	INFO worker.py:1832 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=20870)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=20870)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=20870)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=20870)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=20870)[0m                                                  'param_offload': False,
[36m(main_task pid=20870)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=20870)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=20870)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=20870)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=20870)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=20870)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=20870)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=20870)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=20870)[0m                                            'total_training_steps': -1,
[36m(main_task pid=20870)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=20870)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=20870)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=20870)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=20870)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=20870)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=20870)[0m                                  'response_length': 1024,
[36m(main_task pid=20870)[0m                                  'shuffle': False,
[36m(main_task pid=20870)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=20870)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=20870)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=20870)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=20870)[0m                                  'use_kl_loss': False,
[36m(main_task pid=20870)[0m                                  'use_torch_compile': True},
[36m(main_task pid=20870)[0m                        'hybrid_engine': True,
[36m(main_task pid=20870)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=20870)[0m                                  'external_lib': None,
[36m(main_task pid=20870)[0m                                  'override_config': {},
[36m(main_task pid=20870)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=20870)[0m                                  'use_remove_padding': True},
[36m(main_task pid=20870)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=20870)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=20870)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=20870)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=20870)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=20870)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=20870)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=20870)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=20870)[0m                                    'disable_log_stats': True,
[36m(main_task pid=20870)[0m                                    'do_sample': True,
[36m(main_task pid=20870)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=20870)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=20870)[0m                                    'enforce_eager': True,
[36m(main_task pid=20870)[0m                                    'free_cache_engine': True,
[36m(main_task pid=20870)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=20870)[0m                                    'ignore_eos': False,
[36m(main_task pid=20870)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=20870)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=20870)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=20870)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=20870)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=20870)[0m                                    'max_model_len': None,
[36m(main_task pid=20870)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=20870)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=20870)[0m                                    'n': 1,
[36m(main_task pid=20870)[0m                                    'name': 'vllm',
[36m(main_task pid=20870)[0m                                    'prompt_length': 512,
[36m(main_task pid=20870)[0m                                    'response_length': 1024,
[36m(main_task pid=20870)[0m                                    'temperature': 1.0,
[36m(main_task pid=20870)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=20870)[0m                                    'top_k': -1,
[36m(main_task pid=20870)[0m                                    'top_p': 1,
[36m(main_task pid=20870)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=20870)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=20870)[0m                                                   'n': 1,
[36m(main_task pid=20870)[0m                                                   'temperature': 0,
[36m(main_task pid=20870)[0m                                                   'top_k': -1,
[36m(main_task pid=20870)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=20870)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=20870)[0m                'gamma': 1.0,
[36m(main_task pid=20870)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=20870)[0m                'kl_penalty': 'kl',
[36m(main_task pid=20870)[0m                'lam': 1.0},
[36m(main_task pid=20870)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=20870)[0m             'estimate_prompts_value': False,
[36m(main_task pid=20870)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=20870)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=20870)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=20870)[0m             'grad_clip': 1.0,
[36m(main_task pid=20870)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=20870)[0m                       'external_lib': None,
[36m(main_task pid=20870)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=20870)[0m                                       'optimizer_offload': False,
[36m(main_task pid=20870)[0m                                       'param_offload': False,
[36m(main_task pid=20870)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=20870)[0m                       'override_config': {},
[36m(main_task pid=20870)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=20870)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=20870)[0m                       'use_remove_padding': False},
[36m(main_task pid=20870)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=20870)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=20870)[0m                       'min_lr_ratio': None,
[36m(main_task pid=20870)[0m                       'total_training_steps': -1,
[36m(main_task pid=20870)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=20870)[0m             'ppo_epochs': 1,
[36m(main_task pid=20870)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=20870)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=20870)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=20870)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=20870)[0m             'shuffle': False,
[36m(main_task pid=20870)[0m             'strategy': 'fsdp',
[36m(main_task pid=20870)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=20870)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=20870)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=20870)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=20870)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=20870)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=20870)[0m                 'warmup_steps': 2},
[36m(main_task pid=20870)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=20870)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=20870)[0m           'image_key': 'images',
[36m(main_task pid=20870)[0m           'max_prompt_length': 512,
[36m(main_task pid=20870)[0m           'max_response_length': 1024,
[36m(main_task pid=20870)[0m           'prompt_key': 'prompt',
[36m(main_task pid=20870)[0m           'return_raw_chat': False,
[36m(main_task pid=20870)[0m           'return_raw_input_ids': False,
[36m(main_task pid=20870)[0m           'shuffle': True,
[36m(main_task pid=20870)[0m           'tokenizer': None,
[36m(main_task pid=20870)[0m           'train_batch_size': 1024,
[36m(main_task pid=20870)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=20870)[0m           'truncation': 'error',
[36m(main_task pid=20870)[0m           'use_chat_template': False,
[36m(main_task pid=20870)[0m           'val_batch_size': None,
[36m(main_task pid=20870)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=20870)[0m  'reward_model': {'enable': False,
[36m(main_task pid=20870)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=20870)[0m                   'max_length': None,
[36m(main_task pid=20870)[0m                   'micro_batch_size': None,
[36m(main_task pid=20870)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=20870)[0m                   'model': {'external_lib': None,
[36m(main_task pid=20870)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=20870)[0m                                             'param_offload': False,
[36m(main_task pid=20870)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=20870)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=20870)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=20870)[0m                             'use_remove_padding': False},
[36m(main_task pid=20870)[0m                   'reward_manager': 'naive',
[36m(main_task pid=20870)[0m                   'strategy': 'fsdp',
[36m(main_task pid=20870)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=20870)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=20870)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=20870)[0m              'critic_warmup': 0,
[36m(main_task pid=20870)[0m              'default_hdfs_dir': None,
[36m(main_task pid=20870)[0m              'default_local_dir': 'checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=20870)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=20870)[0m              'experiment_name': 'ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=20870)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=20870)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=20870)[0m              'nnodes': 1,
[36m(main_task pid=20870)[0m              'project_name': 'grpo',
[36m(main_task pid=20870)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=20870)[0m              'resume_from_path': False,
[36m(main_task pid=20870)[0m              'resume_mode': 'auto',
[36m(main_task pid=20870)[0m              'save_freq': -1,
[36m(main_task pid=20870)[0m              'test_freq': 3,
[36m(main_task pid=20870)[0m              'total_epochs': 10,
[36m(main_task pid=20870)[0m              'total_training_steps': None,
[36m(main_task pid=20870)[0m              'val_before_train': True,
[36m(main_task pid=20870)[0m              'val_generations_to_log_to_wandb': 0}}
[36m(main_task pid=20870)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=20870)[0m No module named 'vllm._version'
[36m(main_task pid=20870)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=20870)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=20870)[0m dataset len: 1791700
[36m(main_task pid=20870)[0m Example prompt before filtering: Solve the following math problem step by step. The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=20870)[0m 
[36m(main_task pid=20870)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.
[36m(main_task pid=20870)[0m 
[36m(main_task pid=20870)[0m Remember to put your answer on its own line after "Answer:".
[36m(main_task pid=20870)[0m filter dataset len: 1786000
[36m(main_task pid=20870)[0m dataset len: 500
[36m(main_task pid=20870)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=20870)[0m filter dataset len: 497
[36m(main_task pid=20870)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=20870)[0m Size of train dataloader: 1744
[36m(main_task pid=20870)[0m Size of val dataloader: 1
[36m(main_task pid=20870)[0m Total training steps: 17440
[36m(main_task pid=20870)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=26820)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=26820)[0m No module named 'vllm._version'
[36m(pid=26820)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=27023)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=27023)[0m No module named 'vllm._version'
[36m(pid=27023)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=27025)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=27025)[0m No module named 'vllm._version'
[36m(pid=27025)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=26820)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=26820)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=26820)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=26820)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=26820)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(pid=27024)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=27024)[0m No module named 'vllm._version'
[36m(pid=27024)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=27024)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=27024)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=26820)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=26820)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=26820)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=26820)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.63671875
[36m(WorkerDict pid=26820)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=26820)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=26820)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=26820)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=26820)[0m   "architectures": [
[36m(WorkerDict pid=26820)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=26820)[0m   ],
[36m(WorkerDict pid=26820)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=26820)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=26820)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=26820)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=26820)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=26820)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=26820)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=26820)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=26820)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=26820)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=26820)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=26820)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=26820)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=26820)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=26820)[0m   "rope_scaling": null,
[36m(WorkerDict pid=26820)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=26820)[0m   "sliding_window": null,
[36m(WorkerDict pid=26820)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=26820)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=26820)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=26820)[0m   "use_cache": true,
[36m(WorkerDict pid=26820)[0m   "use_mrope": false,
[36m(WorkerDict pid=26820)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=26820)[0m   "vocab_size": 151936
[36m(WorkerDict pid=26820)[0m }
[36m(WorkerDict pid=26820)[0m 
[36m(WorkerDict pid=26820)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=26820)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fac49ddbbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fac49ddbac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=27025)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=27024)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=27024)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=27025)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=26820)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=26820)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=26820)[0m   "architectures": [
[36m(WorkerDict pid=26820)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=26820)[0m   ],
[36m(WorkerDict pid=26820)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=26820)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=26820)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=26820)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=26820)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=26820)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=26820)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=26820)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=26820)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=26820)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=26820)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=26820)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=26820)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=26820)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=26820)[0m   "rope_scaling": null,
[36m(WorkerDict pid=26820)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=26820)[0m   "sliding_window": null,
[36m(WorkerDict pid=26820)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=26820)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=26820)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=26820)[0m   "use_cache": true,
[36m(WorkerDict pid=26820)[0m   "use_mrope": false,
[36m(WorkerDict pid=26820)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=26820)[0m   "vocab_size": 151936
[36m(WorkerDict pid=26820)[0m }
[36m(WorkerDict pid=26820)[0m 
[36m(WorkerDict pid=26820)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=26820)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=27024)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=27024)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=26820)[0m Before building vllm rollout, memory allocated (GB): 2.8754353523254395, memory reserved (GB): 6.37890625
[36m(WorkerDict pid=26820)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=27024)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f936c26bbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f936c26bac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=27025)[0m WARNING 04-18 17:31:10 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=27024)[0m Actor use_remove_padding=True[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=27025)[0m local rank 0
[36m(WorkerDict pid=27024)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=27023)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=27024)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=26820)[0m before init cache memory allocated: 6.220035072GB, reserved: 6.381633536GB
[36m(WorkerDict pid=26820)[0m after init cache memory allocated: 58.977432576GB, reserved: 59.17114368GB
[36m(WorkerDict pid=26820)[0m WARNING 04-18 17:31:11 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=26820)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=27023)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=27024)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=27023)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=27023)[0m   warnings.warn(
[36m(WorkerDict pid=27023)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=26820)[0m After building vllm rollout, memory allocated (GB): 52.048779010772705, memory reserved (GB): 55.107421875
[36m(WorkerDict pid=26820)[0m After building sharding manager, memory allocated (GB): 52.048779010772705, memory reserved (GB): 55.107421875
[36m(main_task pid=20870)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=20870)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=20870)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=20870)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_173121-cvottori
[36m(main_task pid=20870)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=20870)[0m wandb: Syncing run ppo_Math1.5B_tok1k_dapo17k
[36m(main_task pid=20870)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=20870)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/cvottori
[36m(main_task pid=20870)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=20870)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k/latest_checkpointed_iteration.txt
[36m(main_task pid=20870)[0m Training from scratch
[36m(main_task pid=20870)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=20870)[0m validation generation end
[36m(WorkerDict pid=27024)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=20870)[0m Not computing the values of prompts.
[36m(main_task pid=20870)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=20870)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=20870)[0m 
[36m(main_task pid=20870)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=20870)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=20870)[0m    \[
[36m(main_task pid=20870)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=20870)[0m    \]
[36m(main_task pid=20870)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=20870)[0m 
[36m(main_task pid=20870)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=20870)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=20870)[0m    \[
[36m(main_task pid=20870)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=20870)[0m    \]
[36m(main_task pid=20870)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=20870)[0m 
[36m(main_task pid=20870)[0m Let's implement this in Python to get the exact values for \(r\) and \(\theta\).
[36m(main_task pid=20870)[0m 
[36m(main_task pid=20870)[0m ```python
[36m(main_task pid=20870)[0m import sympy as sp
[36m(main_task pid=20870)[0m 
[36m(main_task pid=20870)[0m # Define the rectangular coordinates
[36m(main_task pid=20870)[0m x = 0
[36m(main_task pid=20870)[0m y = 3
[36m(main_task pid=20870)[0m 
[36m(main_task pid=20870)[0m # Calculate the radius r
[36m(main_task pid=20870)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=20870)[0m 
[36m(main_task pid=20870)[0m # Calculate the angle theta
[36m(main_task pid=20870)[0m theta = sp.atan2(y, x)
[36m(main_task pid=20870)[0m 
[36m(main_task pid=20870)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=20870)[0m if theta < 0:
[36m(main_task pid=20870)[0m     theta += 2 * sp.pi
[36m(main_task pid=20870)[0m 
[36m(main_task pid=20870)[0m # Print the result
[36m(main_task pid=20870)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=20870)[0m ```
[36m(main_task pid=20870)[0m ```output
[36m(main_task pid=20870)[0m r = 3, theta = pi/2
[36m(main_task pid=20870)[0m ```
[36m(main_task pid=20870)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=20870)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=20870)[0m [score] 1.0
[36m(main_task pid=20870)[0m ERROR:2025-04-18 17:32:03,568:Error during comparison
[36m(main_task pid=20870)[0m Traceback (most recent call last):
[36m(main_task pid=20870)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=20870)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=20870)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=20870)[0m     return func(*args, **kwargs)
[36m(main_task pid=20870)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=20870)[0m     return sympy_expr_eq(
[36m(main_task pid=20870)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=20870)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=20870)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=20870)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=20870)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=20870)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=20870)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=20870)[0m     d[None].extend(seq)
[36m(main_task pid=20870)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(WorkerDict pid=27024)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=27024)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=20870)[0m ("Initial validation metrics: {'val/test_score/di-zhang-fdu/MATH500': "
[36m(main_task pid=20870)[0m  "0.46169354838709675, 'val/pass_rate/avg': 0.46169354838709675, "
[36m(main_task pid=20870)[0m  "'val/pass_rate/median': 0.0, 'val/pass_rate/bucket_0%': 0.5383064516129032, "
[36m(main_task pid=20870)[0m  "'val/pass_rate/bucket_0-20%': 0.0, 'val/pass_rate/bucket_20-40%': 0.0, "
[36m(main_task pid=20870)[0m  "'val/pass_rate/bucket_40-60%': 0.0, 'val/pass_rate/bucket_60-80%': 0.0, "
[36m(main_task pid=20870)[0m  "'val/pass_rate/bucket_80-100%': 0.0, 'val/pass_rate/bucket_100%': "
[36m(main_task pid=20870)[0m  '0.46169354838709675}')
[36m(main_task pid=20870)[0m step:0 - val/test_score/di-zhang-fdu/MATH500:0.462 - val/pass_rate/avg:0.462 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.538 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.462
[36m(main_task pid=20870)[0m wandb:                                                                                
[36m(main_task pid=20870)[0m wandb: 
[36m(main_task pid=20870)[0m wandb: Run history:
[36m(main_task pid=20870)[0m wandb:                   val/pass_rate/avg ▁
[36m(main_task pid=20870)[0m wandb:             val/pass_rate/bucket_0% ▁
[36m(main_task pid=20870)[0m wandb:          val/pass_rate/bucket_0-20% ▁
[36m(main_task pid=20870)[0m wandb:           val/pass_rate/bucket_100% ▁
[36m(main_task pid=20870)[0m wandb:         val/pass_rate/bucket_20-40% ▁
[36m(main_task pid=20870)[0m wandb:         val/pass_rate/bucket_40-60% ▁
[36m(main_task pid=20870)[0m wandb:         val/pass_rate/bucket_60-80% ▁
[36m(main_task pid=20870)[0m wandb:        val/pass_rate/bucket_80-100% ▁
[36m(main_task pid=20870)[0m wandb:                val/pass_rate/median ▁
[36m(main_task pid=20870)[0m wandb: val/test_score/di-zhang-fdu/MATH500 ▁
[36m(main_task pid=20870)[0m wandb: 
[36m(main_task pid=20870)[0m wandb: Run summary:
[36m(main_task pid=20870)[0m wandb:                   val/pass_rate/avg 0.46169
[36m(main_task pid=20870)[0m wandb:             val/pass_rate/bucket_0% 0.53831
[36m(main_task pid=20870)[0m wandb:          val/pass_rate/bucket_0-20% 0
[36m(main_task pid=20870)[0m wandb:           val/pass_rate/bucket_100% 0.46169
[36m(main_task pid=20870)[0m wandb:         val/pass_rate/bucket_20-40% 0
[36m(main_task pid=20870)[0m wandb:         val/pass_rate/bucket_40-60% 0
[36m(main_task pid=20870)[0m wandb:         val/pass_rate/bucket_60-80% 0
[36m(main_task pid=20870)[0m wandb:        val/pass_rate/bucket_80-100% 0
[36m(main_task pid=20870)[0m wandb:                val/pass_rate/median 0
[36m(main_task pid=20870)[0m wandb: val/test_score/di-zhang-fdu/MATH500 0.46169
[36m(main_task pid=20870)[0m wandb: 
[36m(main_task pid=20870)[0m wandb: 🚀 View run ppo_Math1.5B_tok1k_dapo17k at: https://wandb.ai/sample-efficient-RL/grpo/runs/cvottori
[36m(main_task pid=20870)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=20870)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=20870)[0m wandb: Find logs at: ./wandb/run-20250418_173121-cvottori/logs
Error executing job with overrides: ['data.train_files=./data/DAPO-17k-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=1024', 'data.max_prompt_length=512', 'data.max_response_length=1024', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=256', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-1.5B', 'critic.ppo_micro_batch_size_per_gpu=32', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=True', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=3', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo_Math1.5B_tok1k_dapo17k', 'trainer.total_epochs=10']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TypeError): [36mray::main_task()[39m (pid=20870, ip=192.168.159.207)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 1028, in fit
    reward_tensor = self.reward_fn(batch)
  File "/home/jovyan/project/verl/verl/workers/reward_manager/naive.py", line 107, in __call__
    reward_tensor[i, valid_response_length - 1] = score
TypeError: can't assign a dict to a torch.FloatTensor

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 1024
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_Math1.5B_tok1k_dapo17k
2025-04-18 17:54:09,840	INFO worker.py:1832 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=38228)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=38228)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=38228)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=38228)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=38228)[0m                                                  'param_offload': False,
[36m(main_task pid=38228)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=38228)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=38228)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=38228)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=38228)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=38228)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=38228)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=38228)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=38228)[0m                                            'total_training_steps': -1,
[36m(main_task pid=38228)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=38228)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=38228)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=38228)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=38228)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=38228)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=38228)[0m                                  'response_length': 1024,
[36m(main_task pid=38228)[0m                                  'shuffle': False,
[36m(main_task pid=38228)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=38228)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=38228)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=38228)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=38228)[0m                                  'use_kl_loss': False,
[36m(main_task pid=38228)[0m                                  'use_torch_compile': True},
[36m(main_task pid=38228)[0m                        'hybrid_engine': True,
[36m(main_task pid=38228)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=38228)[0m                                  'external_lib': None,
[36m(main_task pid=38228)[0m                                  'override_config': {},
[36m(main_task pid=38228)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=38228)[0m                                  'use_remove_padding': True},
[36m(main_task pid=38228)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=38228)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=38228)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=38228)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=38228)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=38228)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=38228)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=38228)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=38228)[0m                                    'disable_log_stats': True,
[36m(main_task pid=38228)[0m                                    'do_sample': True,
[36m(main_task pid=38228)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=38228)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=38228)[0m                                    'enforce_eager': True,
[36m(main_task pid=38228)[0m                                    'free_cache_engine': True,
[36m(main_task pid=38228)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=38228)[0m                                    'ignore_eos': False,
[36m(main_task pid=38228)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=38228)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=38228)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=38228)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=38228)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=38228)[0m                                    'max_model_len': None,
[36m(main_task pid=38228)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=38228)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=38228)[0m                                    'n': 1,
[36m(main_task pid=38228)[0m                                    'name': 'vllm',
[36m(main_task pid=38228)[0m                                    'prompt_length': 512,
[36m(main_task pid=38228)[0m                                    'response_length': 1024,
[36m(main_task pid=38228)[0m                                    'temperature': 1.0,
[36m(main_task pid=38228)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=38228)[0m                                    'top_k': -1,
[36m(main_task pid=38228)[0m                                    'top_p': 1,
[36m(main_task pid=38228)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=38228)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=38228)[0m                                                   'n': 1,
[36m(main_task pid=38228)[0m                                                   'temperature': 0,
[36m(main_task pid=38228)[0m                                                   'top_k': -1,
[36m(main_task pid=38228)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=38228)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=38228)[0m                'gamma': 1.0,
[36m(main_task pid=38228)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=38228)[0m                'kl_penalty': 'kl',
[36m(main_task pid=38228)[0m                'lam': 1.0},
[36m(main_task pid=38228)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=38228)[0m             'estimate_prompts_value': False,
[36m(main_task pid=38228)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=38228)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=38228)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=38228)[0m             'grad_clip': 1.0,
[36m(main_task pid=38228)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=38228)[0m                       'external_lib': None,
[36m(main_task pid=38228)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=38228)[0m                                       'optimizer_offload': False,
[36m(main_task pid=38228)[0m                                       'param_offload': False,
[36m(main_task pid=38228)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=38228)[0m                       'override_config': {},
[36m(main_task pid=38228)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=38228)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=38228)[0m                       'use_remove_padding': False},
[36m(main_task pid=38228)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=38228)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=38228)[0m                       'min_lr_ratio': None,
[36m(main_task pid=38228)[0m                       'total_training_steps': -1,
[36m(main_task pid=38228)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=38228)[0m             'ppo_epochs': 1,
[36m(main_task pid=38228)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=38228)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=38228)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=38228)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=38228)[0m             'shuffle': False,
[36m(main_task pid=38228)[0m             'strategy': 'fsdp',
[36m(main_task pid=38228)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=38228)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=38228)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=38228)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=38228)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=38228)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=38228)[0m                 'warmup_steps': 2},
[36m(main_task pid=38228)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=38228)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=38228)[0m           'image_key': 'images',
[36m(main_task pid=38228)[0m           'max_prompt_length': 512,
[36m(main_task pid=38228)[0m           'max_response_length': 1024,
[36m(main_task pid=38228)[0m           'prompt_key': 'prompt',
[36m(main_task pid=38228)[0m           'return_raw_chat': False,
[36m(main_task pid=38228)[0m           'return_raw_input_ids': False,
[36m(main_task pid=38228)[0m           'shuffle': True,
[36m(main_task pid=38228)[0m           'tokenizer': None,
[36m(main_task pid=38228)[0m           'train_batch_size': 1024,
[36m(main_task pid=38228)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=38228)[0m           'truncation': 'error',
[36m(main_task pid=38228)[0m           'use_chat_template': False,
[36m(main_task pid=38228)[0m           'val_batch_size': None,
[36m(main_task pid=38228)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=38228)[0m  'reward_model': {'enable': False,
[36m(main_task pid=38228)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=38228)[0m                   'max_length': None,
[36m(main_task pid=38228)[0m                   'micro_batch_size': None,
[36m(main_task pid=38228)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=38228)[0m                   'model': {'external_lib': None,
[36m(main_task pid=38228)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=38228)[0m                                             'param_offload': False,
[36m(main_task pid=38228)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=38228)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=38228)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=38228)[0m                             'use_remove_padding': False},
[36m(main_task pid=38228)[0m                   'reward_manager': 'naive',
[36m(main_task pid=38228)[0m                   'strategy': 'fsdp',
[36m(main_task pid=38228)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=38228)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=38228)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=38228)[0m              'critic_warmup': 0,
[36m(main_task pid=38228)[0m              'default_hdfs_dir': None,
[36m(main_task pid=38228)[0m              'default_local_dir': 'checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=38228)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=38228)[0m              'experiment_name': 'ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=38228)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=38228)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=38228)[0m              'nnodes': 1,
[36m(main_task pid=38228)[0m              'project_name': 'grpo',
[36m(main_task pid=38228)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=38228)[0m              'resume_from_path': False,
[36m(main_task pid=38228)[0m              'resume_mode': 'auto',
[36m(main_task pid=38228)[0m              'save_freq': -1,
[36m(main_task pid=38228)[0m              'test_freq': 3,
[36m(main_task pid=38228)[0m              'total_epochs': 10,
[36m(main_task pid=38228)[0m              'total_training_steps': None,
[36m(main_task pid=38228)[0m              'val_before_train': True,
[36m(main_task pid=38228)[0m              'val_generations_to_log_to_wandb': 0}}
[36m(main_task pid=38228)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=38228)[0m No module named 'vllm._version'
[36m(main_task pid=38228)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=38228)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=38228)[0m dataset len: 1791700
[36m(main_task pid=38228)[0m Example prompt before filtering: Solve the following math problem step by step. The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=38228)[0m 
[36m(main_task pid=38228)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.
[36m(main_task pid=38228)[0m 
[36m(main_task pid=38228)[0m Remember to put your answer on its own line after "Answer:".
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 1024
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_Math1.5B_tok1k_dapo17k
2025-04-18 17:59:12,522	INFO worker.py:1832 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8266 [39m[22m
[36m(main_task pid=48249)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=48249)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=48249)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=48249)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=48249)[0m                                                  'param_offload': False,
[36m(main_task pid=48249)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=48249)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=48249)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=48249)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=48249)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=48249)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=48249)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=48249)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=48249)[0m                                            'total_training_steps': -1,
[36m(main_task pid=48249)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=48249)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=48249)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=48249)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=48249)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=48249)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=48249)[0m                                  'response_length': 1024,
[36m(main_task pid=48249)[0m                                  'shuffle': False,
[36m(main_task pid=48249)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=48249)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=48249)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=48249)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=48249)[0m                                  'use_kl_loss': False,
[36m(main_task pid=48249)[0m                                  'use_torch_compile': True},
[36m(main_task pid=48249)[0m                        'hybrid_engine': True,
[36m(main_task pid=48249)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=48249)[0m                                  'external_lib': None,
[36m(main_task pid=48249)[0m                                  'override_config': {},
[36m(main_task pid=48249)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=48249)[0m                                  'use_remove_padding': True},
[36m(main_task pid=48249)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=48249)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=48249)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=48249)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=48249)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=48249)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=48249)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=48249)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=48249)[0m                                    'disable_log_stats': True,
[36m(main_task pid=48249)[0m                                    'do_sample': True,
[36m(main_task pid=48249)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=48249)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=48249)[0m                                    'enforce_eager': True,
[36m(main_task pid=48249)[0m                                    'free_cache_engine': True,
[36m(main_task pid=48249)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=48249)[0m                                    'ignore_eos': False,
[36m(main_task pid=48249)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=48249)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=48249)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=48249)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=48249)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=48249)[0m                                    'max_model_len': None,
[36m(main_task pid=48249)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=48249)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=48249)[0m                                    'n': 1,
[36m(main_task pid=48249)[0m                                    'name': 'vllm',
[36m(main_task pid=48249)[0m                                    'prompt_length': 512,
[36m(main_task pid=48249)[0m                                    'response_length': 1024,
[36m(main_task pid=48249)[0m                                    'temperature': 1.0,
[36m(main_task pid=48249)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=48249)[0m                                    'top_k': -1,
[36m(main_task pid=48249)[0m                                    'top_p': 1,
[36m(main_task pid=48249)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=48249)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=48249)[0m                                                   'n': 1,
[36m(main_task pid=48249)[0m                                                   'temperature': 0,
[36m(main_task pid=48249)[0m                                                   'top_k': -1,
[36m(main_task pid=48249)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=48249)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=48249)[0m                'gamma': 1.0,
[36m(main_task pid=48249)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=48249)[0m                'kl_penalty': 'kl',
[36m(main_task pid=48249)[0m                'lam': 1.0},
[36m(main_task pid=48249)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=48249)[0m             'estimate_prompts_value': False,
[36m(main_task pid=48249)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=48249)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=48249)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=48249)[0m             'grad_clip': 1.0,
[36m(main_task pid=48249)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=48249)[0m                       'external_lib': None,
[36m(main_task pid=48249)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=48249)[0m                                       'optimizer_offload': False,
[36m(main_task pid=48249)[0m                                       'param_offload': False,
[36m(main_task pid=48249)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=48249)[0m                       'override_config': {},
[36m(main_task pid=48249)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=48249)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=48249)[0m                       'use_remove_padding': False},
[36m(main_task pid=48249)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=48249)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=48249)[0m                       'min_lr_ratio': None,
[36m(main_task pid=48249)[0m                       'total_training_steps': -1,
[36m(main_task pid=48249)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=48249)[0m             'ppo_epochs': 1,
[36m(main_task pid=48249)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=48249)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=48249)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=48249)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=48249)[0m             'shuffle': False,
[36m(main_task pid=48249)[0m             'strategy': 'fsdp',
[36m(main_task pid=48249)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=48249)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=48249)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=48249)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=48249)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=48249)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=48249)[0m                 'warmup_steps': 2},
[36m(main_task pid=48249)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=48249)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=48249)[0m           'image_key': 'images',
[36m(main_task pid=48249)[0m           'max_prompt_length': 512,
[36m(main_task pid=48249)[0m           'max_response_length': 1024,
[36m(main_task pid=48249)[0m           'prompt_key': 'prompt',
[36m(main_task pid=48249)[0m           'return_raw_chat': False,
[36m(main_task pid=48249)[0m           'return_raw_input_ids': False,
[36m(main_task pid=48249)[0m           'shuffle': True,
[36m(main_task pid=48249)[0m           'tokenizer': None,
[36m(main_task pid=48249)[0m           'train_batch_size': 1024,
[36m(main_task pid=48249)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=48249)[0m           'truncation': 'error',
[36m(main_task pid=48249)[0m           'use_chat_template': False,
[36m(main_task pid=48249)[0m           'val_batch_size': None,
[36m(main_task pid=48249)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=48249)[0m  'reward_model': {'enable': False,
[36m(main_task pid=48249)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=48249)[0m                   'max_length': None,
[36m(main_task pid=48249)[0m                   'micro_batch_size': None,
[36m(main_task pid=48249)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=48249)[0m                   'model': {'external_lib': None,
[36m(main_task pid=48249)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=48249)[0m                                             'param_offload': False,
[36m(main_task pid=48249)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=48249)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=48249)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=48249)[0m                             'use_remove_padding': False},
[36m(main_task pid=48249)[0m                   'reward_manager': 'naive',
[36m(main_task pid=48249)[0m                   'strategy': 'fsdp',
[36m(main_task pid=48249)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=48249)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=48249)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=48249)[0m              'critic_warmup': 0,
[36m(main_task pid=48249)[0m              'default_hdfs_dir': None,
[36m(main_task pid=48249)[0m              'default_local_dir': 'checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=48249)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=48249)[0m              'experiment_name': 'ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=48249)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=48249)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=48249)[0m              'nnodes': 1,
[36m(main_task pid=48249)[0m              'project_name': 'grpo',
[36m(main_task pid=48249)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=48249)[0m              'resume_from_path': False,
[36m(main_task pid=48249)[0m              'resume_mode': 'auto',
[36m(main_task pid=48249)[0m              'save_freq': -1,
[36m(main_task pid=48249)[0m              'test_freq': 3,
[36m(main_task pid=48249)[0m              'total_epochs': 10,
[36m(main_task pid=48249)[0m              'total_training_steps': None,
[36m(main_task pid=48249)[0m              'val_before_train': True,
[36m(main_task pid=48249)[0m              'val_generations_to_log_to_wandb': 0}}
[36m(main_task pid=48249)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=48249)[0m No module named 'vllm._version'
[36m(main_task pid=48249)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=48249)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=48249)[0m dataset len: 1791700
[36m(main_task pid=48249)[0m Example prompt before filtering: Solve the following math problem step by step. The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=48249)[0m 
[36m(main_task pid=48249)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.
[36m(main_task pid=48249)[0m 
[36m(main_task pid=48249)[0m Remember to put your answer on its own line after "Answer:".
[36m(main_task pid=38228)[0m filter dataset len: 1786000
[36m(main_task pid=38228)[0m dataset len: 500
[36m(main_task pid=38228)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=38228)[0m filter dataset len: 497
[36m(main_task pid=38228)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=38228)[0m  dataloader: 1744
[36m(main_task pid=38228)[0m Size of val dataloader: 1
[36m(main_task pid=38228)[0m Total training steps: 17440
[36m(main_task pid=38228)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=53663)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=53663)[0m No module named 'vllm._version'
[36m(pid=53663)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=53879)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=53879)[0m No module named 'vllm._version'
[36m(pid=53879)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=53881)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=53881)[0m No module named 'vllm._version'
[36m(pid=53881)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=53663)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=53879)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=53879)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=53879)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=53879)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(pid=53880)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=53880)[0m No module named 'vllm._version'
[36m(pid=53880)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=53663)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=53663)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=53880)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=53880)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=53663)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=53663)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=53663)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=53663)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.6328125
[36m(WorkerDict pid=53663)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=53663)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=53663)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=53663)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=53663)[0m   "architectures": [
[36m(WorkerDict pid=53663)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=53663)[0m   ],
[36m(WorkerDict pid=53663)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=53663)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=53663)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=53663)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=53663)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=53663)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=53663)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=53663)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=53663)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=53663)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=53663)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=53663)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=53663)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=53663)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=53663)[0m   "rope_scaling": null,
[36m(WorkerDict pid=53663)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=53663)[0m   "sliding_window": null,
[36m(WorkerDict pid=53663)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=53663)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=53663)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=53663)[0m   "use_cache": true,
[36m(WorkerDict pid=53663)[0m   "use_mrope": false,
[36m(WorkerDict pid=53663)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=53663)[0m   "vocab_size": 151936
[36m(WorkerDict pid=53663)[0m }
[36m(WorkerDict pid=53663)[0m 
[36m(WorkerDict pid=53663)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=53663)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fa4013cbbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fa4013cbac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=53663)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=53663)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=53663)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=53663)[0m   "architectures": [
[36m(WorkerDict pid=53663)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=53663)[0m   ],
[36m(WorkerDict pid=53663)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=53663)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=53663)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=53663)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=53663)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=53663)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=53663)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=53663)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=53663)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=53663)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=53663)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=53663)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=53663)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=53663)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=53663)[0m   "rope_scaling": null,
[36m(WorkerDict pid=53663)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=53663)[0m   "sliding_window": null,
[36m(WorkerDict pid=53663)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=53663)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=53663)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=53663)[0m   "use_cache": true,
[36m(WorkerDict pid=53663)[0m   "use_mrope": false,
[36m(WorkerDict pid=53663)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=53663)[0m   "vocab_size": 151936
[36m(WorkerDict pid=53663)[0m }
[36m(WorkerDict pid=53663)[0m 
[36m(WorkerDict pid=53663)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=53663)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=53663)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=53880)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=53663)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=53880)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=53880)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=53880)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fbed0c9bbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fbed0c9bac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=53663)[0m Before building vllm rollout, memory allocated (GB): 2.8754353523254395, memory reserved (GB): 6.375
[36m(WorkerDict pid=53663)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=53663)[0m WARNING 04-18 18:02:47 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=53880)[0m Actor use_remove_padding=True[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=53663)[0m local rank 0
[36m(WorkerDict pid=53880)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=53880)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=53879)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=53879)[0m WARNING 04-18 18:02:52 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=53879)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=53663)[0m before init cache memory allocated: 6.220035072GB, reserved: 6.377439232GB
[36m(WorkerDict pid=53663)[0m after init cache memory allocated: 59.009545216GB, reserved: 59.166949376GB
[36m(WorkerDict pid=53880)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=53663)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=53663)[0m After building vllm rollout, memory allocated (GB): 52.078686237335205, memory reserved (GB): 55.103515625
[36m(WorkerDict pid=53663)[0m After building sharding manager, memory allocated (GB): 52.078686237335205, memory reserved (GB): 55.103515625
[36m(WorkerDict pid=53663)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=53663)[0m   warnings.warn(
[36m(WorkerDict pid=53881)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 2x across cluster][0m
[36m(main_task pid=38228)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=38228)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=38228)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=38228)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_180301-rz1wqocr
[36m(main_task pid=38228)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=38228)[0m wandb: Syncing run ppo_Math1.5B_tok1k_dapo17k
[36m(main_task pid=38228)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=38228)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/rz1wqocr
[36m(main_task pid=38228)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=38228)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k/latest_checkpointed_iteration.txt
[36m(main_task pid=38228)[0m Training from scratch
[36m(main_task pid=38228)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=38228)[0m validation generation end
[36m(WorkerDict pid=53880)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=38228)[0m Not computing the values of prompts.
[36m(main_task pid=38228)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=38228)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=38228)[0m 
[36m(main_task pid=38228)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=38228)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=38228)[0m    \[
[36m(main_task pid=38228)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=38228)[0m    \]
[36m(main_task pid=38228)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=38228)[0m 
[36m(main_task pid=38228)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=38228)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=38228)[0m    \[
[36m(main_task pid=38228)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=38228)[0m    \]
[36m(main_task pid=38228)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=38228)[0m 
[36m(main_task pid=38228)[0m Let's implement this in Python to get the exact values for \(r\) and \(\theta\).
[36m(main_task pid=38228)[0m 
[36m(main_task pid=38228)[0m ```python
[36m(main_task pid=38228)[0m import sympy as sp
[36m(main_task pid=38228)[0m 
[36m(main_task pid=38228)[0m # Define the rectangular coordinates
[36m(main_task pid=38228)[0m x = 0
[36m(main_task pid=38228)[0m y = 3
[36m(main_task pid=38228)[0m 
[36m(main_task pid=38228)[0m # Calculate the radius r
[36m(main_task pid=38228)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=38228)[0m 
[36m(main_task pid=38228)[0m # Calculate the angle theta
[36m(main_task pid=38228)[0m theta = sp.atan2(y, x)
[36m(main_task pid=38228)[0m 
[36m(main_task pid=38228)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=38228)[0m if theta < 0:
[36m(main_task pid=38228)[0m     theta += 2 * sp.pi
[36m(main_task pid=38228)[0m 
[36m(main_task pid=38228)[0m # Print the result
[36m(main_task pid=38228)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=38228)[0m ```
[36m(main_task pid=38228)[0m ```output
[36m(main_task pid=38228)[0m r = 3, theta = pi/2
[36m(main_task pid=38228)[0m ```
[36m(main_task pid=38228)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=38228)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=38228)[0m [score] 1.0
[36m(main_task pid=38228)[0m ERROR:2025-04-18 18:03:36,087:Error during comparison
[36m(main_task pid=38228)[0m Traceback (most recent call last):
[36m(main_task pid=38228)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=38228)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=38228)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=38228)[0m     return func(*args, **kwargs)
[36m(main_task pid=38228)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=38228)[0m     return sympy_expr_eq(
[36m(main_task pid=38228)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=38228)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=38228)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=38228)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=38228)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=38228)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=38228)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=38228)[0m     d[None].extend(seq)
[36m(main_task pid=38228)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(WorkerDict pid=53880)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=53880)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=38228)[0m ("Initial validation metrics: {'val/test_score/MATH500': 0.46169354838709675, "
[36m(main_task pid=38228)[0m  "'val/pass_rate/avg': 0.46169354838709675, 'val/pass_rate/median': 0.0, "
[36m(main_task pid=38228)[0m  "'val/pass_rate/bucket_0%': 0.5383064516129032, 'val/pass_rate/bucket_0-20%': "
[36m(main_task pid=38228)[0m  "0.0, 'val/pass_rate/bucket_20-40%': 0.0, 'val/pass_rate/bucket_40-60%': 0.0, "
[36m(main_task pid=38228)[0m  "'val/pass_rate/bucket_60-80%': 0.0, 'val/pass_rate/bucket_80-100%': 0.0, "
[36m(main_task pid=38228)[0m  "'val/pass_rate/bucket_100%': 0.46169354838709675}")
[36m(main_task pid=38228)[0m step:0 - val/test_score/MATH500:0.462 - val/pass_rate/avg:0.462 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.538 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.462
[36m(main_task pid=38228)[0m wandb:                                                                                
[36m(main_task pid=38228)[0m wandb: 
[36m(main_task pid=38228)[0m wandb: Run history:
[36m(main_task pid=38228)[0m wandb:            val/pass_rate/avg ▁
[36m(main_task pid=38228)[0m wandb:      val/pass_rate/bucket_0% ▁
[36m(main_task pid=38228)[0m wandb:   val/pass_rate/bucket_0-20% ▁
[36m(main_task pid=38228)[0m wandb:    val/pass_rate/bucket_100% ▁
[36m(main_task pid=38228)[0m wandb:  val/pass_rate/bucket_20-40% ▁
[36m(main_task pid=38228)[0m wandb:  val/pass_rate/bucket_40-60% ▁
[36m(main_task pid=38228)[0m wandb:  val/pass_rate/bucket_60-80% ▁
[36m(main_task pid=38228)[0m wandb: val/pass_rate/bucket_80-100% ▁
[36m(main_task pid=38228)[0m wandb:         val/pass_rate/median ▁
[36m(main_task pid=38228)[0m wandb:       val/test_score/MATH500 ▁
[36m(main_task pid=38228)[0m wandb: 
[36m(main_task pid=38228)[0m wandb: Run summary:
[36m(main_task pid=38228)[0m wandb:            val/pass_rate/avg 0.46169
[36m(main_task pid=38228)[0m wandb:      val/pass_rate/bucket_0% 0.53831
[36m(main_task pid=38228)[0m wandb:   val/pass_rate/bucket_0-20% 0
[36m(main_task pid=38228)[0m wandb:    val/pass_rate/bucket_100% 0.46169
[36m(main_task pid=38228)[0m wandb:  val/pass_rate/bucket_20-40% 0
[36m(main_task pid=38228)[0m wandb:  val/pass_rate/bucket_40-60% 0
[36m(main_task pid=38228)[0m wandb:  val/pass_rate/bucket_60-80% 0
[36m(main_task pid=38228)[0m wandb: val/pass_rate/bucket_80-100% 0
[36m(main_task pid=38228)[0m wandb:         val/pass_rate/median 0
[36m(main_task pid=38228)[0m wandb:       val/test_score/MATH500 0.46169
[36m(main_task pid=38228)[0m wandb: 
[36m(main_task pid=38228)[0m wandb: 🚀 View run ppo_Math1.5B_tok1k_dapo17k at: https://wandb.ai/sample-efficient-RL/grpo/runs/rz1wqocr
[36m(main_task pid=38228)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=38228)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=38228)[0m wandb: Find logs at: ./wandb/run-20250418_180301-rz1wqocr/logs
Error executing job with overrides: ['data.train_files=./data/DAPO-17k-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=1024', 'data.max_prompt_length=512', 'data.max_response_length=1024', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=256', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-1.5B', 'critic.ppo_micro_batch_size_per_gpu=32', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=True', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=3', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo_Math1.5B_tok1k_dapo17k', 'trainer.total_epochs=10']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TypeError): [36mray::main_task()[39m (pid=38228, ip=192.168.159.207)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 1028, in fit
    reward_tensor = self.reward_fn(batch)
  File "/home/jovyan/project/verl/verl/workers/reward_manager/naive.py", line 107, in __call__
    reward_tensor[i, valid_response_length - 1] = score
TypeError: can't assign a dict to a torch.FloatTensor

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(main_task pid=48249)[0m filter dataset len: 1786000
[36m(main_task pid=48249)[0m dataset len: 500
[36m(main_task pid=48249)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=48249)[0m filter dataset len: 497
[36m(main_task pid=48249)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=48249)[0m Size of train dataloader: 1744
[36m(main_task pid=48249)[0m Size of val dataloader: 1
[36m(main_task pid=48249)[0m Total training steps: 17440
[36m(main_task pid=48249)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=57117)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=57117)[0m No module named 'vllm._version'
[36m(pid=57117)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=57317)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=57317)[0m No module named 'vllm._version'
[36m(pid=57317)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=57318)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=57318)[0m No module named 'vllm._version'
[36m(pid=57318)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=57117)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=57317)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=57317)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=57317)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=57317)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=57117)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=57117)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=57117)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=57117)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.6328125
[36m(WorkerDict pid=57117)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=57117)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=57117)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=57117)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=57117)[0m   "architectures": [
[36m(WorkerDict pid=57117)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=57117)[0m   ],
[36m(WorkerDict pid=57117)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=57117)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=57117)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=57117)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=57117)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=57117)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=57117)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=57117)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=57117)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=57117)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=57117)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=57117)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=57117)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=57117)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=57117)[0m   "rope_scaling": null,
[36m(WorkerDict pid=57117)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=57117)[0m   "sliding_window": null,
[36m(WorkerDict pid=57117)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=57117)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=57117)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=57117)[0m   "use_cache": true,
[36m(WorkerDict pid=57117)[0m   "use_mrope": false,
[36m(WorkerDict pid=57117)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=57117)[0m   "vocab_size": 151936
[36m(WorkerDict pid=57117)[0m }
[36m(WorkerDict pid=57117)[0m 
[36m(WorkerDict pid=57117)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=57117)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fb7760c7be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fb7760c7ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=57117)[0m Actor use_remove_padding=True
[36m(pid=57319)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=57319)[0m No module named 'vllm._version'
[36m(pid=57319)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=57317)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=57318)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=57318)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=57318)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=57117)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=57117)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=57117)[0m   "architectures": [
[36m(WorkerDict pid=57117)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=57117)[0m   ],
[36m(WorkerDict pid=57117)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=57117)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=57117)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=57117)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=57117)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=57117)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=57117)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=57117)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=57117)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=57117)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=57117)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=57117)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=57117)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=57117)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=57117)[0m   "rope_scaling": null,
[36m(WorkerDict pid=57117)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=57117)[0m   "sliding_window": null,
[36m(WorkerDict pid=57117)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=57117)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=57117)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=57117)[0m   "use_cache": true,
[36m(WorkerDict pid=57117)[0m   "use_mrope": false,
[36m(WorkerDict pid=57117)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=57117)[0m   "vocab_size": 151936
[36m(WorkerDict pid=57117)[0m }
[36m(WorkerDict pid=57117)[0m 
[36m(WorkerDict pid=57117)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=57319)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=57319)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=57117)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fb7760c7be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fb7760c7ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=57319)[0m Actor use_remove_padding=True[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=57117)[0m Before building vllm rollout, memory allocated (GB): 2.8754353523254395, memory reserved (GB): 6.375
[36m(WorkerDict pid=57117)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=57318)[0m WARNING 04-18 18:07:43 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=57317)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=57319)[0m wrap_policy: functools.partial(<function _or_policy at 0x7ef7a8c0bbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7ef7a8c0bac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=57317)[0m Actor use_remove_padding=True[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=57318)[0m local rank 0
[36m(WorkerDict pid=57319)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=57318)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=57117)[0m before init cache memory allocated: 6.22053888GB, reserved: 6.381633536GB
[36m(WorkerDict pid=57117)[0m after init cache memory allocated: 58.977936384GB, reserved: 59.17114368GB
[36m(WorkerDict pid=57317)[0m WARNING 04-18 18:07:45 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=57317)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=57319)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=57317)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=57319)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=57319)[0m   warnings.warn(
[36m(WorkerDict pid=57319)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=57117)[0m After building vllm rollout, memory allocated (GB): 52.048779010772705, memory reserved (GB): 55.107421875
[36m(WorkerDict pid=57117)[0m After building sharding manager, memory allocated (GB): 52.048779010772705, memory reserved (GB): 55.107421875
[36m(main_task pid=48249)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=48249)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=48249)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=48249)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_180752-09f398ky
[36m(main_task pid=48249)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=48249)[0m wandb: Syncing run ppo_Math1.5B_tok1k_dapo17k
[36m(main_task pid=48249)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=48249)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/09f398ky
[36m(main_task pid=48249)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=48249)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k/latest_checkpointed_iteration.txt
[36m(main_task pid=48249)[0m Training from scratch
[36m(main_task pid=48249)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=48249)[0m validation generation end
[36m(WorkerDict pid=57318)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=48249)[0m Not computing the values of prompts.
[36m(main_task pid=48249)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=48249)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=48249)[0m 
[36m(main_task pid=48249)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=48249)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=48249)[0m    \[
[36m(main_task pid=48249)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=48249)[0m    \]
[36m(main_task pid=48249)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=48249)[0m 
[36m(main_task pid=48249)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=48249)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=48249)[0m    \[
[36m(main_task pid=48249)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=48249)[0m    \]
[36m(main_task pid=48249)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=48249)[0m 
[36m(main_task pid=48249)[0m Let's implement this in Python to get the exact values for \(r\) and \(\theta\).
[36m(main_task pid=48249)[0m 
[36m(main_task pid=48249)[0m ```python
[36m(main_task pid=48249)[0m import sympy as sp
[36m(main_task pid=48249)[0m 
[36m(main_task pid=48249)[0m # Define the rectangular coordinates
[36m(main_task pid=48249)[0m x = 0
[36m(main_task pid=48249)[0m y = 3
[36m(main_task pid=48249)[0m 
[36m(main_task pid=48249)[0m # Calculate the radius r
[36m(main_task pid=48249)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=48249)[0m 
[36m(main_task pid=48249)[0m # Calculate the angle theta
[36m(main_task pid=48249)[0m theta = sp.atan2(y, x)
[36m(main_task pid=48249)[0m 
[36m(main_task pid=48249)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=48249)[0m if theta < 0:
[36m(main_task pid=48249)[0m     theta += 2 * sp.pi
[36m(main_task pid=48249)[0m 
[36m(main_task pid=48249)[0m # Print the result
[36m(main_task pid=48249)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=48249)[0m ```
[36m(main_task pid=48249)[0m ```output
[36m(main_task pid=48249)[0m r = 3, theta = pi/2
[36m(main_task pid=48249)[0m ```
[36m(main_task pid=48249)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=48249)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=48249)[0m [score] 1.0
[36m(main_task pid=48249)[0m ERROR:2025-04-18 18:08:25,571:Error during comparison
[36m(main_task pid=48249)[0m Traceback (most recent call last):
[36m(main_task pid=48249)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=48249)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=48249)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=48249)[0m     return func(*args, **kwargs)
[36m(main_task pid=48249)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=48249)[0m     return sympy_expr_eq(
[36m(main_task pid=48249)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=48249)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=48249)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=48249)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=48249)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=48249)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=48249)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=48249)[0m     d[None].extend(seq)
[36m(main_task pid=48249)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(WorkerDict pid=57117)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=57117)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=48249)[0m ("Initial validation metrics: {'val/test_score/MATH500': 0.46169354838709675, "
[36m(main_task pid=48249)[0m  "'val/pass_rate/avg': 0.46169354838709675, 'val/pass_rate/median': 0.0, "
[36m(main_task pid=48249)[0m  "'val/pass_rate/bucket_0%': 0.5383064516129032, 'val/pass_rate/bucket_0-20%': "
[36m(main_task pid=48249)[0m  "0.0, 'val/pass_rate/bucket_20-40%': 0.0, 'val/pass_rate/bucket_40-60%': 0.0, "
[36m(main_task pid=48249)[0m  "'val/pass_rate/bucket_60-80%': 0.0, 'val/pass_rate/bucket_80-100%': 0.0, "
[36m(main_task pid=48249)[0m  "'val/pass_rate/bucket_100%': 0.46169354838709675}")
[36m(main_task pid=48249)[0m step:0 - val/test_score/MATH500:0.462 - val/pass_rate/avg:0.462 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.538 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.462
[36m(main_task pid=48249)[0m wandb:                                                                                
[36m(main_task pid=48249)[0m wandb: 
[36m(main_task pid=48249)[0m wandb: Run history:
[36m(main_task pid=48249)[0m wandb:            val/pass_rate/avg ▁
[36m(main_task pid=48249)[0m wandb:      val/pass_rate/bucket_0% ▁
[36m(main_task pid=48249)[0m wandb:   val/pass_rate/bucket_0-20% ▁
[36m(main_task pid=48249)[0m wandb:    val/pass_rate/bucket_100% ▁
[36m(main_task pid=48249)[0m wandb:  val/pass_rate/bucket_20-40% ▁
[36m(main_task pid=48249)[0m wandb:  val/pass_rate/bucket_40-60% ▁
[36m(main_task pid=48249)[0m wandb:  val/pass_rate/bucket_60-80% ▁
[36m(main_task pid=48249)[0m wandb: val/pass_rate/bucket_80-100% ▁
[36m(main_task pid=48249)[0m wandb:         val/pass_rate/median ▁
[36m(main_task pid=48249)[0m wandb:       val/test_score/MATH500 ▁
[36m(main_task pid=48249)[0m wandb: 
[36m(main_task pid=48249)[0m wandb: Run summary:
[36m(main_task pid=48249)[0m wandb:            val/pass_rate/avg 0.46169
[36m(main_task pid=48249)[0m wandb:      val/pass_rate/bucket_0% 0.53831
[36m(main_task pid=48249)[0m wandb:   val/pass_rate/bucket_0-20% 0
[36m(main_task pid=48249)[0m wandb:    val/pass_rate/bucket_100% 0.46169
[36m(main_task pid=48249)[0m wandb:  val/pass_rate/bucket_20-40% 0
[36m(main_task pid=48249)[0m wandb:  val/pass_rate/bucket_40-60% 0
[36m(main_task pid=48249)[0m wandb:  val/pass_rate/bucket_60-80% 0
[36m(main_task pid=48249)[0m wandb: val/pass_rate/bucket_80-100% 0
[36m(main_task pid=48249)[0m wandb:         val/pass_rate/median 0
[36m(main_task pid=48249)[0m wandb:       val/test_score/MATH500 0.46169
[36m(main_task pid=48249)[0m wandb: 
[36m(main_task pid=48249)[0m wandb: 🚀 View run ppo_Math1.5B_tok1k_dapo17k at: https://wandb.ai/sample-efficient-RL/grpo/runs/09f398ky
[36m(main_task pid=48249)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=48249)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=48249)[0m wandb: Find logs at: ./wandb/run-20250418_180752-09f398ky/logs
Error executing job with overrides: ['data.train_files=./data/DAPO-17k-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=1024', 'data.max_prompt_length=512', 'data.max_response_length=1024', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=256', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-1.5B', 'critic.ppo_micro_batch_size_per_gpu=32', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=True', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=3', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo_Math1.5B_tok1k_dapo17k', 'trainer.total_epochs=10']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TypeError): [36mray::main_task()[39m (pid=48249, ip=192.168.159.207)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 1028, in fit
    reward_tensor = self.reward_fn(batch)
  File "/home/jovyan/project/verl/verl/workers/reward_manager/naive.py", line 107, in __call__
    reward_tensor[i, valid_response_length - 1] = score
TypeError: can't assign a dict to a torch.FloatTensor

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 1024
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_Math1.5B_tok1k_dapo17k
2025-04-18 19:56:14,761	INFO worker.py:1832 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=82371)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=82371)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=82371)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=82371)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=82371)[0m                                                  'param_offload': False,
[36m(main_task pid=82371)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=82371)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=82371)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=82371)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=82371)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=82371)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=82371)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=82371)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=82371)[0m                                            'total_training_steps': -1,
[36m(main_task pid=82371)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=82371)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=82371)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=82371)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=82371)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=82371)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=82371)[0m                                  'response_length': 1024,
[36m(main_task pid=82371)[0m                                  'shuffle': False,
[36m(main_task pid=82371)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=82371)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=82371)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=82371)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=82371)[0m                                  'use_kl_loss': False,
[36m(main_task pid=82371)[0m                                  'use_torch_compile': True},
[36m(main_task pid=82371)[0m                        'hybrid_engine': True,
[36m(main_task pid=82371)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=82371)[0m                                  'external_lib': None,
[36m(main_task pid=82371)[0m                                  'override_config': {},
[36m(main_task pid=82371)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=82371)[0m                                  'use_remove_padding': True},
[36m(main_task pid=82371)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=82371)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=82371)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=82371)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=82371)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=82371)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=82371)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=82371)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=82371)[0m                                    'disable_log_stats': True,
[36m(main_task pid=82371)[0m                                    'do_sample': True,
[36m(main_task pid=82371)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=82371)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=82371)[0m                                    'enforce_eager': True,
[36m(main_task pid=82371)[0m                                    'free_cache_engine': True,
[36m(main_task pid=82371)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=82371)[0m                                    'ignore_eos': False,
[36m(main_task pid=82371)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=82371)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=82371)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=82371)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=82371)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=82371)[0m                                    'max_model_len': None,
[36m(main_task pid=82371)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=82371)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=82371)[0m                                    'n': 1,
[36m(main_task pid=82371)[0m                                    'name': 'vllm',
[36m(main_task pid=82371)[0m                                    'prompt_length': 512,
[36m(main_task pid=82371)[0m                                    'response_length': 1024,
[36m(main_task pid=82371)[0m                                    'temperature': 1.0,
[36m(main_task pid=82371)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=82371)[0m                                    'top_k': -1,
[36m(main_task pid=82371)[0m                                    'top_p': 1,
[36m(main_task pid=82371)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=82371)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=82371)[0m                                                   'n': 1,
[36m(main_task pid=82371)[0m                                                   'temperature': 0,
[36m(main_task pid=82371)[0m                                                   'top_k': -1,
[36m(main_task pid=82371)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=82371)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=82371)[0m                'gamma': 1.0,
[36m(main_task pid=82371)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=82371)[0m                'kl_penalty': 'kl',
[36m(main_task pid=82371)[0m                'lam': 1.0},
[36m(main_task pid=82371)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=82371)[0m             'estimate_prompts_value': False,
[36m(main_task pid=82371)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=82371)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=82371)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=82371)[0m             'grad_clip': 1.0,
[36m(main_task pid=82371)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=82371)[0m                       'external_lib': None,
[36m(main_task pid=82371)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=82371)[0m                                       'optimizer_offload': False,
[36m(main_task pid=82371)[0m                                       'param_offload': False,
[36m(main_task pid=82371)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=82371)[0m                       'override_config': {},
[36m(main_task pid=82371)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=82371)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=82371)[0m                       'use_remove_padding': False},
[36m(main_task pid=82371)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=82371)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=82371)[0m                       'min_lr_ratio': None,
[36m(main_task pid=82371)[0m                       'total_training_steps': -1,
[36m(main_task pid=82371)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=82371)[0m             'ppo_epochs': 1,
[36m(main_task pid=82371)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=82371)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=82371)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=82371)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=82371)[0m             'shuffle': False,
[36m(main_task pid=82371)[0m             'strategy': 'fsdp',
[36m(main_task pid=82371)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=82371)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=82371)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=82371)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=82371)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=82371)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=82371)[0m                 'warmup_steps': 2},
[36m(main_task pid=82371)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=82371)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=82371)[0m           'image_key': 'images',
[36m(main_task pid=82371)[0m           'max_prompt_length': 512,
[36m(main_task pid=82371)[0m           'max_response_length': 1024,
[36m(main_task pid=82371)[0m           'prompt_key': 'prompt',
[36m(main_task pid=82371)[0m           'return_raw_chat': False,
[36m(main_task pid=82371)[0m           'return_raw_input_ids': False,
[36m(main_task pid=82371)[0m           'shuffle': True,
[36m(main_task pid=82371)[0m           'tokenizer': None,
[36m(main_task pid=82371)[0m           'train_batch_size': 1024,
[36m(main_task pid=82371)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=82371)[0m           'truncation': 'error',
[36m(main_task pid=82371)[0m           'use_chat_template': False,
[36m(main_task pid=82371)[0m           'val_batch_size': None,
[36m(main_task pid=82371)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=82371)[0m  'reward_model': {'enable': False,
[36m(main_task pid=82371)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=82371)[0m                   'max_length': None,
[36m(main_task pid=82371)[0m                   'micro_batch_size': None,
[36m(main_task pid=82371)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=82371)[0m                   'model': {'external_lib': None,
[36m(main_task pid=82371)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=82371)[0m                                             'param_offload': False,
[36m(main_task pid=82371)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=82371)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=82371)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=82371)[0m                             'use_remove_padding': False},
[36m(main_task pid=82371)[0m                   'reward_manager': 'naive',
[36m(main_task pid=82371)[0m                   'strategy': 'fsdp',
[36m(main_task pid=82371)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=82371)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=82371)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=82371)[0m              'critic_warmup': 0,
[36m(main_task pid=82371)[0m              'default_hdfs_dir': None,
[36m(main_task pid=82371)[0m              'default_local_dir': 'checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=82371)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=82371)[0m              'experiment_name': 'ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=82371)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=82371)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=82371)[0m              'nnodes': 1,
[36m(main_task pid=82371)[0m              'project_name': 'grpo',
[36m(main_task pid=82371)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=82371)[0m              'resume_from_path': False,
[36m(main_task pid=82371)[0m              'resume_mode': 'auto',
[36m(main_task pid=82371)[0m              'save_freq': -1,
[36m(main_task pid=82371)[0m              'test_freq': 3,
[36m(main_task pid=82371)[0m              'total_epochs': 10,
[36m(main_task pid=82371)[0m              'total_training_steps': None,
[36m(main_task pid=82371)[0m              'val_before_train': True,
[36m(main_task pid=82371)[0m              'val_generations_to_log_to_wandb': 0}}
[36m(main_task pid=82371)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=82371)[0m No module named 'vllm._version'
[36m(main_task pid=82371)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=82371)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=82371)[0m dataset len: 1791700
[36m(main_task pid=82371)[0m Example prompt before filtering: Solve the following math problem step by step. The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=82371)[0m 
[36m(main_task pid=82371)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.
[36m(main_task pid=82371)[0m 
[36m(main_task pid=82371)[0m Remember to put your answer on its own line after "Answer:".
[36m(main_task pid=82371)[0m filter dataset len: 1786000
[36m(main_task pid=82371)[0m dataset len: 500
[36m(main_task pid=82371)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=82371)[0m filter dataset len: 497
[36m(main_task pid=82371)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=82371)[0m Size of train dataloader: 1744
[36m(main_task pid=82371)[0m Size of val dataloader: 1
[36m(main_task pid=82371)[0m Total training steps: 17440
[36m(main_task pid=82371)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=88346)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=88346)[0m No module named 'vllm._version'
[36m(pid=88346)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=88549)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=88549)[0m No module named 'vllm._version'
[36m(pid=88549)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=88550)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=88550)[0m No module named 'vllm._version'
[36m(pid=88550)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=88346)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=88550)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=88550)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=88550)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=88550)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=88346)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=88346)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=88346)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=88346)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.640625
[36m(WorkerDict pid=88346)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=88346)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=88346)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=88346)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=88346)[0m   "architectures": [
[36m(WorkerDict pid=88346)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=88346)[0m   ],
[36m(WorkerDict pid=88346)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=88346)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=88346)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=88346)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=88346)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=88346)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=88346)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=88346)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=88346)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=88346)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=88346)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=88346)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=88346)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=88346)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=88346)[0m   "rope_scaling": null,
[36m(WorkerDict pid=88346)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=88346)[0m   "sliding_window": null,
[36m(WorkerDict pid=88346)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=88346)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=88346)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=88346)[0m   "use_cache": true,
[36m(WorkerDict pid=88346)[0m   "use_mrope": false,
[36m(WorkerDict pid=88346)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=88346)[0m   "vocab_size": 151936
[36m(WorkerDict pid=88346)[0m }
[36m(WorkerDict pid=88346)[0m 
[36m(WorkerDict pid=88346)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=88346)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f38d4a03be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f38d4a03ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=88551)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=88551)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=88346)[0m Actor use_remove_padding=True
[36m(pid=88551)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=88551)[0m No module named 'vllm._version'
[36m(pid=88551)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=88550)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=88551)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=88549)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=88549)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=88346)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=88346)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=88346)[0m   "architectures": [
[36m(WorkerDict pid=88346)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=88346)[0m   ],
[36m(WorkerDict pid=88346)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=88346)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=88346)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=88346)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=88346)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=88346)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=88346)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=88346)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=88346)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=88346)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=88346)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=88346)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=88346)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=88346)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=88346)[0m   "rope_scaling": null,
[36m(WorkerDict pid=88346)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=88346)[0m   "sliding_window": null,
[36m(WorkerDict pid=88346)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=88346)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=88346)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=88346)[0m   "use_cache": true,
[36m(WorkerDict pid=88346)[0m   "use_mrope": false,
[36m(WorkerDict pid=88346)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=88346)[0m   "vocab_size": 151936
[36m(WorkerDict pid=88346)[0m }
[36m(WorkerDict pid=88346)[0m 
[36m(WorkerDict pid=88551)[0m wrap_policy: functools.partial(<function _or_policy at 0x7ef4adfa7be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7ef4adfa7ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=88551)[0m Actor use_remove_padding=True[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=88346)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=88346)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=88551)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=88346)[0m Before building vllm rollout, memory allocated (GB): 2.8754353523254395, memory reserved (GB): 6.3828125
[36m(WorkerDict pid=88346)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=88346)[0m WARNING 04-18 20:04:55 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=88551)[0m wrap_policy: functools.partial(<function _or_policy at 0x7ef4adfa7be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7ef4adfa7ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=88550)[0m Actor use_remove_padding=True[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=88346)[0m local rank 0
[36m(WorkerDict pid=88550)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=88551)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=88549)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=88346)[0m before init cache memory allocated: 6.220035072GB, reserved: 6.38582784GB
[36m(WorkerDict pid=88346)[0m after init cache memory allocated: 58.974680064GB, reserved: 59.175337984GB
[36m(WorkerDict pid=88551)[0m WARNING 04-18 20:04:57 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=88551)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=88549)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=88550)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=88549)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=88549)[0m   warnings.warn(
[36m(WorkerDict pid=88549)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=88346)[0m After building vllm rollout, memory allocated (GB): 52.046215534210205, memory reserved (GB): 55.111328125
[36m(WorkerDict pid=88346)[0m After building sharding manager, memory allocated (GB): 52.046215534210205, memory reserved (GB): 55.111328125
[36m(main_task pid=82371)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=82371)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=82371)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=82371)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_200505-d6m8ker7
[36m(main_task pid=82371)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=82371)[0m wandb: Syncing run ppo_Math1.5B_tok1k_dapo17k
[36m(main_task pid=82371)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=82371)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/d6m8ker7
[36m(main_task pid=82371)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=82371)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k/latest_checkpointed_iteration.txt
[36m(main_task pid=82371)[0m Training from scratch
[36m(main_task pid=82371)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=82371)[0m validation generation end
[36m(WorkerDict pid=88551)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=82371)[0m Not computing the values of prompts.
[36m(main_task pid=82371)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=82371)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=82371)[0m 
[36m(main_task pid=82371)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=82371)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=82371)[0m    \[
[36m(main_task pid=82371)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=82371)[0m    \]
[36m(main_task pid=82371)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=82371)[0m 
[36m(main_task pid=82371)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=82371)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=82371)[0m    \[
[36m(main_task pid=82371)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=82371)[0m    \]
[36m(main_task pid=82371)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=82371)[0m 
[36m(main_task pid=82371)[0m Let's implement this in Python to get the exact values for \(r\) and \(\theta\).
[36m(main_task pid=82371)[0m 
[36m(main_task pid=82371)[0m ```python
[36m(main_task pid=82371)[0m import sympy as sp
[36m(main_task pid=82371)[0m 
[36m(main_task pid=82371)[0m # Define the rectangular coordinates
[36m(main_task pid=82371)[0m x = 0
[36m(main_task pid=82371)[0m y = 3
[36m(main_task pid=82371)[0m 
[36m(main_task pid=82371)[0m # Calculate the radius r
[36m(main_task pid=82371)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=82371)[0m 
[36m(main_task pid=82371)[0m # Calculate the angle theta
[36m(main_task pid=82371)[0m theta = sp.atan2(y, x)
[36m(main_task pid=82371)[0m 
[36m(main_task pid=82371)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=82371)[0m if theta < 0:
[36m(main_task pid=82371)[0m     theta += 2 * sp.pi
[36m(main_task pid=82371)[0m 
[36m(main_task pid=82371)[0m # Print the result
[36m(main_task pid=82371)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=82371)[0m ```
[36m(main_task pid=82371)[0m ```output
[36m(main_task pid=82371)[0m r = 3, theta = pi/2
[36m(main_task pid=82371)[0m ```
[36m(main_task pid=82371)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=82371)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=82371)[0m [score] 1.0
[36m(main_task pid=82371)[0m ERROR:2025-04-18 20:05:47,730:Error during comparison
[36m(main_task pid=82371)[0m Traceback (most recent call last):
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=82371)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=82371)[0m     return func(*args, **kwargs)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=82371)[0m     return sympy_expr_eq(
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=82371)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=82371)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=82371)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=82371)[0m     d[None].extend(seq)
[36m(main_task pid=82371)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(WorkerDict pid=88551)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=88551)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=82371)[0m ("Initial validation metrics: {'val/test_score/MATH500': 0.46169354838709675, "
[36m(main_task pid=82371)[0m  "'val/pass_rate/avg': 0.46169354838709675, 'val/pass_rate/median': 0.0, "
[36m(main_task pid=82371)[0m  "'val/pass_rate/bucket_0%': 0.5383064516129032, 'val/pass_rate/bucket_0-20%': "
[36m(main_task pid=82371)[0m  "0.0, 'val/pass_rate/bucket_20-40%': 0.0, 'val/pass_rate/bucket_40-60%': 0.0, "
[36m(main_task pid=82371)[0m  "'val/pass_rate/bucket_60-80%': 0.0, 'val/pass_rate/bucket_80-100%': 0.0, "
[36m(main_task pid=82371)[0m  "'val/pass_rate/bucket_100%': 0.46169354838709675}")
[36m(main_task pid=82371)[0m step:0 - val/test_score/MATH500:0.462 - val/pass_rate/avg:0.462 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.538 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.462
[36m(WorkerDict pid=88346)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=88346)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
[36m(main_task pid=82371)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=88550, ip=192.168.159.207, actor_id=45601c5c97ea70c6f42832c001000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f7bbed6c130>)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=82371)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=82371)[0m     return func(*args, **kwargs)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
[36m(main_task pid=82371)[0m     metrics = self.actor.update_policy(data=data)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
[36m(main_task pid=82371)[0m     loss.backward()
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
[36m(main_task pid=82371)[0m     torch.autograd.backward(
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
[36m(main_task pid=82371)[0m     grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
[36m(main_task pid=82371)[0m     raise RuntimeError(
[36m(main_task pid=82371)[0m RuntimeError: grad can be implicitly created only for scalar outputs
[36m(main_task pid=82371)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=88551, ip=192.168.159.207, actor_id=07d197f6e9e100948ad2c5e501000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7ef48f100070>)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=82371)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=82371)[0m     return func(*args, **kwargs)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
[36m(main_task pid=82371)[0m     metrics = self.actor.update_policy(data=data)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
[36m(main_task pid=82371)[0m     loss.backward()
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
[36m(main_task pid=82371)[0m     torch.autograd.backward(
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
[36m(main_task pid=82371)[0m     grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
[36m(main_task pid=82371)[0m     raise RuntimeError(
[36m(main_task pid=82371)[0m RuntimeError: grad can be implicitly created only for scalar outputs
[36m(main_task pid=82371)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=88549, ip=192.168.159.207, actor_id=de1beecf09a24aa40c2e979f01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f42d70280a0>)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=82371)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=82371)[0m     return func(*args, **kwargs)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
[36m(main_task pid=82371)[0m     metrics = self.actor.update_policy(data=data)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
[36m(main_task pid=82371)[0m     loss.backward()
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
[36m(main_task pid=82371)[0m     torch.autograd.backward(
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
[36m(main_task pid=82371)[0m     grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
[36m(main_task pid=82371)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
[36m(main_task pid=82371)[0m     raise RuntimeError(
[36m(main_task pid=82371)[0m RuntimeError: grad can be implicitly created only for scalar outputs
[36m(WorkerDict pid=88551)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=88551)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 3x across cluster][0m
[36m(main_task pid=82371)[0m wandb:                                                                                
[36m(main_task pid=82371)[0m wandb: 
[36m(main_task pid=82371)[0m wandb: Run history:
[36m(main_task pid=82371)[0m wandb:            val/pass_rate/avg ▁
[36m(main_task pid=82371)[0m wandb:      val/pass_rate/bucket_0% ▁
[36m(main_task pid=82371)[0m wandb:   val/pass_rate/bucket_0-20% ▁
[36m(main_task pid=82371)[0m wandb:    val/pass_rate/bucket_100% ▁
[36m(main_task pid=82371)[0m wandb:  val/pass_rate/bucket_20-40% ▁
[36m(main_task pid=82371)[0m wandb:  val/pass_rate/bucket_40-60% ▁
[36m(main_task pid=82371)[0m wandb:  val/pass_rate/bucket_60-80% ▁
[36m(main_task pid=82371)[0m wandb: val/pass_rate/bucket_80-100% ▁
[36m(main_task pid=82371)[0m wandb:         val/pass_rate/median ▁
[36m(main_task pid=82371)[0m wandb:       val/test_score/MATH500 ▁
[36m(main_task pid=82371)[0m wandb: 
[36m(main_task pid=82371)[0m wandb: Run summary:
[36m(main_task pid=82371)[0m wandb:            val/pass_rate/avg 0.46169
[36m(main_task pid=82371)[0m wandb:      val/pass_rate/bucket_0% 0.53831
[36m(main_task pid=82371)[0m wandb:   val/pass_rate/bucket_0-20% 0
[36m(main_task pid=82371)[0m wandb:    val/pass_rate/bucket_100% 0.46169
[36m(main_task pid=82371)[0m wandb:  val/pass_rate/bucket_20-40% 0
[36m(main_task pid=82371)[0m wandb:  val/pass_rate/bucket_40-60% 0
[36m(main_task pid=82371)[0m wandb:  val/pass_rate/bucket_60-80% 0
[36m(main_task pid=82371)[0m wandb: val/pass_rate/bucket_80-100% 0
[36m(main_task pid=82371)[0m wandb:         val/pass_rate/median 0
[36m(main_task pid=82371)[0m wandb:       val/test_score/MATH500 0.46169
[36m(main_task pid=82371)[0m wandb: 
[36m(main_task pid=82371)[0m wandb: 🚀 View run ppo_Math1.5B_tok1k_dapo17k at: https://wandb.ai/sample-efficient-RL/grpo/runs/d6m8ker7
[36m(main_task pid=82371)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=82371)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=82371)[0m wandb: Find logs at: ./wandb/run-20250418_200505-d6m8ker7/logs
Error executing job with overrides: ['data.train_files=./data/DAPO-17k-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=1024', 'data.max_prompt_length=512', 'data.max_response_length=1024', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=256', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-1.5B', 'critic.ppo_micro_batch_size_per_gpu=32', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=True', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=3', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo_Math1.5B_tok1k_dapo17k', 'trainer.total_epochs=10']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::main_task()[39m (pid=82371, ip=192.168.159.207)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 1058, in fit
    actor_output = self.actor_rollout_wg.update_actor(batch)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
ray.exceptions.RayTaskError(RuntimeError): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=88346, ip=192.168.159.207, actor_id=3ca43687b1d8bc81cd1fc04701000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f38888ac400>)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
    metrics = self.actor.update_policy(data=data)
  File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
    loss.backward()
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
    raise RuntimeError(
RuntimeError: grad can be implicitly created only for scalar outputs

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 1024
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_Math1.5B_tok1k_dapo17k
2025-04-18 20:21:51,870	INFO worker.py:1832 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=98357)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=98357)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=98357)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=98357)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=98357)[0m                                                  'param_offload': False,
[36m(main_task pid=98357)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=98357)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=98357)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=98357)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=98357)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=98357)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=98357)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=98357)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=98357)[0m                                            'total_training_steps': -1,
[36m(main_task pid=98357)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=98357)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=98357)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=98357)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=98357)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=98357)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=98357)[0m                                  'response_length': 1024,
[36m(main_task pid=98357)[0m                                  'shuffle': False,
[36m(main_task pid=98357)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=98357)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=98357)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=98357)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=98357)[0m                                  'use_kl_loss': False,
[36m(main_task pid=98357)[0m                                  'use_torch_compile': True},
[36m(main_task pid=98357)[0m                        'hybrid_engine': True,
[36m(main_task pid=98357)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=98357)[0m                                  'external_lib': None,
[36m(main_task pid=98357)[0m                                  'override_config': {},
[36m(main_task pid=98357)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=98357)[0m                                  'use_remove_padding': True},
[36m(main_task pid=98357)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=98357)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=98357)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=98357)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=98357)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=98357)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=98357)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=98357)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=98357)[0m                                    'disable_log_stats': True,
[36m(main_task pid=98357)[0m                                    'do_sample': True,
[36m(main_task pid=98357)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=98357)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=98357)[0m                                    'enforce_eager': True,
[36m(main_task pid=98357)[0m                                    'free_cache_engine': True,
[36m(main_task pid=98357)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=98357)[0m                                    'ignore_eos': False,
[36m(main_task pid=98357)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=98357)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=98357)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=98357)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=98357)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=98357)[0m                                    'max_model_len': None,
[36m(main_task pid=98357)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=98357)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=98357)[0m                                    'n': 1,
[36m(main_task pid=98357)[0m                                    'name': 'vllm',
[36m(main_task pid=98357)[0m                                    'prompt_length': 512,
[36m(main_task pid=98357)[0m                                    'response_length': 1024,
[36m(main_task pid=98357)[0m                                    'temperature': 1.0,
[36m(main_task pid=98357)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=98357)[0m                                    'top_k': -1,
[36m(main_task pid=98357)[0m                                    'top_p': 1,
[36m(main_task pid=98357)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=98357)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=98357)[0m                                                   'n': 1,
[36m(main_task pid=98357)[0m                                                   'temperature': 0,
[36m(main_task pid=98357)[0m                                                   'top_k': -1,
[36m(main_task pid=98357)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=98357)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=98357)[0m                'gamma': 1.0,
[36m(main_task pid=98357)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=98357)[0m                'kl_penalty': 'kl',
[36m(main_task pid=98357)[0m                'lam': 1.0},
[36m(main_task pid=98357)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=98357)[0m             'estimate_prompts_value': False,
[36m(main_task pid=98357)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=98357)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=98357)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=98357)[0m             'grad_clip': 1.0,
[36m(main_task pid=98357)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=98357)[0m                       'external_lib': None,
[36m(main_task pid=98357)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=98357)[0m                                       'optimizer_offload': False,
[36m(main_task pid=98357)[0m                                       'param_offload': False,
[36m(main_task pid=98357)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=98357)[0m                       'override_config': {},
[36m(main_task pid=98357)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=98357)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=98357)[0m                       'use_remove_padding': False},
[36m(main_task pid=98357)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=98357)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=98357)[0m                       'min_lr_ratio': None,
[36m(main_task pid=98357)[0m                       'total_training_steps': -1,
[36m(main_task pid=98357)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=98357)[0m             'ppo_epochs': 1,
[36m(main_task pid=98357)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=98357)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=98357)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=98357)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=98357)[0m             'shuffle': False,
[36m(main_task pid=98357)[0m             'strategy': 'fsdp',
[36m(main_task pid=98357)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=98357)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=98357)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=98357)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=98357)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=98357)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=98357)[0m                 'warmup_steps': 2},
[36m(main_task pid=98357)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=98357)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=98357)[0m           'image_key': 'images',
[36m(main_task pid=98357)[0m           'max_prompt_length': 512,
[36m(main_task pid=98357)[0m           'max_response_length': 1024,
[36m(main_task pid=98357)[0m           'prompt_key': 'prompt',
[36m(main_task pid=98357)[0m           'return_raw_chat': False,
[36m(main_task pid=98357)[0m           'return_raw_input_ids': False,
[36m(main_task pid=98357)[0m           'shuffle': True,
[36m(main_task pid=98357)[0m           'tokenizer': None,
[36m(main_task pid=98357)[0m           'train_batch_size': 1024,
[36m(main_task pid=98357)[0m           'train_files': './data/math500-base/train.parquet',
[36m(main_task pid=98357)[0m           'truncation': 'error',
[36m(main_task pid=98357)[0m           'use_chat_template': False,
[36m(main_task pid=98357)[0m           'val_batch_size': None,
[36m(main_task pid=98357)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=98357)[0m  'reward_model': {'enable': False,
[36m(main_task pid=98357)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=98357)[0m                   'max_length': None,
[36m(main_task pid=98357)[0m                   'micro_batch_size': None,
[36m(main_task pid=98357)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=98357)[0m                   'model': {'external_lib': None,
[36m(main_task pid=98357)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=98357)[0m                                             'param_offload': False,
[36m(main_task pid=98357)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=98357)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=98357)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=98357)[0m                             'use_remove_padding': False},
[36m(main_task pid=98357)[0m                   'reward_manager': 'naive',
[36m(main_task pid=98357)[0m                   'strategy': 'fsdp',
[36m(main_task pid=98357)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=98357)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=98357)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=98357)[0m              'critic_warmup': 0,
[36m(main_task pid=98357)[0m              'default_hdfs_dir': None,
[36m(main_task pid=98357)[0m              'default_local_dir': 'checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=98357)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=98357)[0m              'experiment_name': 'ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=98357)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=98357)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=98357)[0m              'nnodes': 1,
[36m(main_task pid=98357)[0m              'project_name': 'grpo',
[36m(main_task pid=98357)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=98357)[0m              'resume_from_path': False,
[36m(main_task pid=98357)[0m              'resume_mode': 'auto',
[36m(main_task pid=98357)[0m              'save_freq': -1,
[36m(main_task pid=98357)[0m              'test_freq': 3,
[36m(main_task pid=98357)[0m              'total_epochs': 10,
[36m(main_task pid=98357)[0m              'total_training_steps': None,
[36m(main_task pid=98357)[0m              'val_before_train': True,
[36m(main_task pid=98357)[0m              'val_generations_to_log_to_wandb': 0}}
[36m(main_task pid=98357)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=98357)[0m No module named 'vllm._version'
[36m(main_task pid=98357)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=98357)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=98357)[0m dataset len: 12000
[36m(main_task pid=98357)[0m Example prompt before filtering: How many vertical asymptotes does the graph of $y=\frac{2}{x^2+x-6}$ have? Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=98357)[0m filter dataset len: 11910
[36m(main_task pid=98357)[0m dataset len: 500
[36m(main_task pid=98357)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=98357)[0m filter dataset len: 497
[36m(main_task pid=98357)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=98357)[0m Size of train dataloader: 11
[36m(main_task pid=98357)[0m Size of val dataloader: 1
[36m(main_task pid=98357)[0m Total training steps: 110
[36m(main_task pid=98357)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=98967)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=98967)[0m No module named 'vllm._version'
[36m(pid=98967)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=99300)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=99300)[0m No module named 'vllm._version'
[36m(pid=99300)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=98967)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=99299)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=99299)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=98967)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=98967)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=98967)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=98967)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=98967)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=98967)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.6328125
[36m(WorkerDict pid=98967)[0m Total steps: 110, num_warmup_steps: 0
[36m(WorkerDict pid=98967)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=98967)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=98967)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=98967)[0m   "architectures": [
[36m(WorkerDict pid=98967)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=98967)[0m   ],
[36m(WorkerDict pid=98967)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=98967)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=98967)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=98967)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=98967)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=98967)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=98967)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=98967)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=98967)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=98967)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=98967)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=98967)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=98967)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=98967)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=98967)[0m   "rope_scaling": null,
[36m(WorkerDict pid=98967)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=98967)[0m   "sliding_window": null,
[36m(WorkerDict pid=98967)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=98967)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=98967)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=98967)[0m   "use_cache": true,
[36m(WorkerDict pid=98967)[0m   "use_mrope": false,
[36m(WorkerDict pid=98967)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=98967)[0m   "vocab_size": 151936
[36m(WorkerDict pid=98967)[0m }
[36m(WorkerDict pid=98967)[0m 
[36m(WorkerDict pid=98967)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=98967)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fc9258b3be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fc9258b3ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=99301)[0m Total steps: 110, num_warmup_steps: 0[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=99301)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=98967)[0m Actor use_remove_padding=True
[36m(pid=99299)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 2x across cluster][0m
[36m(pid=99299)[0m No module named 'vllm._version'[32m [repeated 2x across cluster][0m
[36m(pid=99299)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=99301)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=99300)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=99300)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=99300)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=98967)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=98967)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=98967)[0m   "architectures": [
[36m(WorkerDict pid=98967)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=98967)[0m   ],
[36m(WorkerDict pid=98967)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=98967)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=98967)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=98967)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=98967)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=98967)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=98967)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=98967)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=98967)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=98967)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=98967)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=98967)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=98967)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=98967)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=98967)[0m   "rope_scaling": null,
[36m(WorkerDict pid=98967)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=98967)[0m   "sliding_window": null,
[36m(WorkerDict pid=98967)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=98967)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=98967)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=98967)[0m   "use_cache": true,
[36m(WorkerDict pid=98967)[0m   "use_mrope": false,
[36m(WorkerDict pid=98967)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=98967)[0m   "vocab_size": 151936
[36m(WorkerDict pid=98967)[0m }
[36m(WorkerDict pid=98967)[0m 
[36m(WorkerDict pid=99301)[0m wrap_policy: functools.partial(<function _or_policy at 0x7ee1110d7be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7ee1110d7ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=99299)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=98967)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=99301)[0m Actor use_remove_padding=True[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=98967)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fc9258b3be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fc9258b3ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=99299)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f11357abbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f11357abac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=98967)[0m Total steps: 110, num_warmup_steps: 0
[36m(WorkerDict pid=98967)[0m Before building vllm rollout, memory allocated (GB): 2.8754353523254395, memory reserved (GB): 6.375
[36m(WorkerDict pid=98967)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=99299)[0m WARNING 04-18 20:22:43 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=99301)[0m Actor use_remove_padding=True[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=99301)[0m wrap_policy: functools.partial(<function _or_policy at 0x7ee1110d7be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7ee1110d7ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=99299)[0m local rank 0
[36m(WorkerDict pid=99301)[0m Total steps: 110, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=99301)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=99301)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=98967)[0m before init cache memory allocated: 6.22053888GB, reserved: 6.381633536GB
[36m(WorkerDict pid=98967)[0m after init cache memory allocated: 58.977936384GB, reserved: 59.17114368GB
[36m(WorkerDict pid=99300)[0m WARNING 04-18 20:22:46 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=99300)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=99300)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=99299)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=99299)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=99299)[0m   warnings.warn(
[36m(main_task pid=98357)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(WorkerDict pid=98967)[0m After building vllm rollout, memory allocated (GB): 52.048779010772705, memory reserved (GB): 55.107421875
[36m(WorkerDict pid=98967)[0m After building sharding manager, memory allocated (GB): 52.048779010772705, memory reserved (GB): 55.107421875
[36m(main_task pid=98357)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=98357)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=98357)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_202255-ms6qpn2c
[36m(main_task pid=98357)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=98357)[0m wandb: Syncing run ppo_Math1.5B_tok1k_dapo17k
[36m(main_task pid=98357)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=98357)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/ms6qpn2c
[36m(main_task pid=98357)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=98357)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k/latest_checkpointed_iteration.txt
[36m(main_task pid=98357)[0m Training from scratch
[36m(main_task pid=98357)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=98357)[0m validation generation end
[36m(WorkerDict pid=99301)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=98357)[0m Not computing the values of prompts.
[36m(main_task pid=98357)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=98357)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=98357)[0m 
[36m(main_task pid=98357)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=98357)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=98357)[0m    \[
[36m(main_task pid=98357)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=98357)[0m    \]
[36m(main_task pid=98357)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=98357)[0m 
[36m(main_task pid=98357)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=98357)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=98357)[0m    \[
[36m(main_task pid=98357)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=98357)[0m    \]
[36m(main_task pid=98357)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=98357)[0m 
[36m(main_task pid=98357)[0m Let's implement this in Python to get the exact values for \(r\) and \(\theta\).
[36m(main_task pid=98357)[0m 
[36m(main_task pid=98357)[0m ```python
[36m(main_task pid=98357)[0m import sympy as sp
[36m(main_task pid=98357)[0m 
[36m(main_task pid=98357)[0m # Define the rectangular coordinates
[36m(main_task pid=98357)[0m x = 0
[36m(main_task pid=98357)[0m y = 3
[36m(main_task pid=98357)[0m 
[36m(main_task pid=98357)[0m # Calculate the radius r
[36m(main_task pid=98357)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=98357)[0m 
[36m(main_task pid=98357)[0m # Calculate the angle theta
[36m(main_task pid=98357)[0m theta = sp.atan2(y, x)
[36m(main_task pid=98357)[0m 
[36m(main_task pid=98357)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=98357)[0m if theta < 0:
[36m(main_task pid=98357)[0m     theta += 2 * sp.pi
[36m(main_task pid=98357)[0m 
[36m(main_task pid=98357)[0m # Print the result
[36m(main_task pid=98357)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=98357)[0m ```
[36m(main_task pid=98357)[0m ```output
[36m(main_task pid=98357)[0m r = 3, theta = pi/2
[36m(main_task pid=98357)[0m ```
[36m(main_task pid=98357)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=98357)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=98357)[0m [score] 1.0
[36m(main_task pid=98357)[0m ERROR:2025-04-18 20:23:26,905:Error during comparison
[36m(main_task pid=98357)[0m Traceback (most recent call last):
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=98357)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=98357)[0m     return func(*args, **kwargs)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=98357)[0m     return sympy_expr_eq(
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=98357)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=98357)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=98357)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=98357)[0m     d[None].extend(seq)
[36m(main_task pid=98357)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(WorkerDict pid=99301)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=99301)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=98357)[0m ("Initial validation metrics: {'val/test_score/MATH500': 0.46169354838709675, "
[36m(main_task pid=98357)[0m  "'val/pass_rate/avg': 0.46169354838709675, 'val/pass_rate/median': 0.0, "
[36m(main_task pid=98357)[0m  "'val/pass_rate/bucket_0%': 0.5383064516129032, 'val/pass_rate/bucket_0-20%': "
[36m(main_task pid=98357)[0m  "0.0, 'val/pass_rate/bucket_20-40%': 0.0, 'val/pass_rate/bucket_40-60%': 0.0, "
[36m(main_task pid=98357)[0m  "'val/pass_rate/bucket_60-80%': 0.0, 'val/pass_rate/bucket_80-100%': 0.0, "
[36m(main_task pid=98357)[0m  "'val/pass_rate/bucket_100%': 0.46169354838709675}")
[36m(main_task pid=98357)[0m step:0 - val/test_score/MATH500:0.462 - val/pass_rate/avg:0.462 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.538 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.462
[36m(main_task pid=98357)[0m WARNING:2025-04-18 20:24:23,087:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=98357)[0m WARNING:2025-04-18 20:24:24,648:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{900}'], Pred: ['<|endoftext|>']
[36m(main_task pid=98357)[0m WARNING:2025-04-18 20:24:24,682:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{50}'], Pred: ['<|endoftext|>']
[36m(main_task pid=98357)[0m WARNING:2025-04-18 20:24:25,140:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=98357)[0m WARNING:2025-04-18 20:24:25,223:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=98357)[0m WARNING:2025-04-18 20:24:26,116:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=98357)[0m ERROR:2025-04-18 20:24:27,175:Error during comparison
[36m(main_task pid=98357)[0m Traceback (most recent call last):
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=98357)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=98357)[0m     return func(*args, **kwargs)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=98357)[0m     return sympy_expr_eq(
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=98357)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=98357)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
[36m(main_task pid=98357)[0m     return all(
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
[36m(main_task pid=98357)[0m     for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
[36m(main_task pid=98357)[0m AttributeError: 'Rational' object has no attribute 'items'
[36m(main_task pid=98357)[0m WARNING:2025-04-18 20:24:27,816:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=98357)[0m No gold targets found for at least one gold. Gold: ['\\boxed{}'], Pred: [' To solve this problem, we need to determine the number of prime numbers greater than \\( n! + 1 \\) and less than \\( n! + n \\) for any integer \\( n > 1 \\).\n\n1. **Understanding the range:**\n   The range we are considering is from \\( n! + 1 \\) to \\( n! + n \\). This means we are looking for prime numbers in the interval \\((n! + 1, n! + n)\\).\n\n2. **Analyzing the interval:**\n   - The integer \\( n! \\) (n factorial) is divisible by all integers from 1 to \\( n \\).\n   - Therefore, \\( n! + 1 \\) to \\( n! + n \\) contains the integers 2, 3, 4, ..., \\( n \\).\n\n3. **Checking divisibility:**\n   - Any number in the interval \\((n! + 1, n! + n)\\) is divisible by at least one integer between \\( n! + 1 \\) and \\( n! + n \\).\n   - Hence, none of these numbers can be prime.\n\nThus, there are no prime numbers greater than \\( n! + 1 \\) and less than \\( n! + n \\).\n\nThe final answer is:\n\n\\[\n\\boxed{0}\n\\]\n\nLet\'s verify this reasoning with Python code using sympy for generality.\n\n```python\nimport sympy as sp\n\ndef count_primes_in_interval(n):\n    factorial_n = sp.factorial(n)\n    start_bound = factorial_n + 1\n    end_bound = factorial_n + n\n    prime_count = 0\n    \n    for i in range(start_bound, end_bound):\n        if sp.isprime(i):\n            prime_count += 1\n    \n    return prime_count\n\n# Test for a specific value of n\nn = 5\nprime_count = count_primes_in_interval(n)\nprint(f"The number of prime numbers greater than {n! + 1} and less than {n! + n} is: {prime_count}")\n```<|endoftext|>']
[36m(main_task pid=98357)[0m WARNING:2025-04-18 20:24:28,158:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{255}'], Pred: ['<|endoftext|>']
[36m(main_task pid=98357)[0m WARNING:2025-04-18 20:24:28,886:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=98357)[0m WARNING:2025-04-18 20:24:29,303:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=98967)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=98967)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
[36m(main_task pid=98357)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=99300, ip=192.168.159.207, actor_id=83c553638d571ec00ac7f2c101000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7eed0be881f0>)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=98357)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=98357)[0m     return func(*args, **kwargs)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
[36m(main_task pid=98357)[0m     metrics = self.actor.update_policy(data=data)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
[36m(main_task pid=98357)[0m     loss.backward()
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
[36m(main_task pid=98357)[0m     torch.autograd.backward(
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
[36m(main_task pid=98357)[0m     grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
[36m(main_task pid=98357)[0m     raise RuntimeError(
[36m(main_task pid=98357)[0m RuntimeError: grad can be implicitly created only for scalar outputs
[36m(main_task pid=98357)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=99301, ip=192.168.159.207, actor_id=0e22d8bda0c44a7d6827ac9601000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7ee0c4f28070>)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=98357)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=98357)[0m     return func(*args, **kwargs)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
[36m(main_task pid=98357)[0m     metrics = self.actor.update_policy(data=data)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
[36m(main_task pid=98357)[0m     loss.backward()
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
[36m(main_task pid=98357)[0m     torch.autograd.backward(
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
[36m(main_task pid=98357)[0m     grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
[36m(main_task pid=98357)[0m     raise RuntimeError(
[36m(main_task pid=98357)[0m RuntimeError: grad can be implicitly created only for scalar outputs
[36m(WorkerDict pid=99301)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=99301)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 3x across cluster][0m
[36m(main_task pid=98357)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=98967, ip=192.168.159.207, actor_id=34a3fa7b8135b378e3fa8c7e01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7fc8d97641f0>)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=98357)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=98357)[0m     return func(*args, **kwargs)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
[36m(main_task pid=98357)[0m     metrics = self.actor.update_policy(data=data)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
[36m(main_task pid=98357)[0m     loss.backward()
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
[36m(main_task pid=98357)[0m     torch.autograd.backward(
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
[36m(main_task pid=98357)[0m     grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
[36m(main_task pid=98357)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
[36m(main_task pid=98357)[0m     raise RuntimeError(
[36m(main_task pid=98357)[0m RuntimeError: grad can be implicitly created only for scalar outputs
[36m(main_task pid=98357)[0m wandb:                                                                                
[36m(main_task pid=98357)[0m wandb: 
[36m(main_task pid=98357)[0m wandb: Run history:
[36m(main_task pid=98357)[0m wandb:            val/pass_rate/avg ▁
[36m(main_task pid=98357)[0m wandb:      val/pass_rate/bucket_0% ▁
[36m(main_task pid=98357)[0m wandb:   val/pass_rate/bucket_0-20% ▁
[36m(main_task pid=98357)[0m wandb:    val/pass_rate/bucket_100% ▁
[36m(main_task pid=98357)[0m wandb:  val/pass_rate/bucket_20-40% ▁
[36m(main_task pid=98357)[0m wandb:  val/pass_rate/bucket_40-60% ▁
[36m(main_task pid=98357)[0m wandb:  val/pass_rate/bucket_60-80% ▁
[36m(main_task pid=98357)[0m wandb: val/pass_rate/bucket_80-100% ▁
[36m(main_task pid=98357)[0m wandb:         val/pass_rate/median ▁
[36m(main_task pid=98357)[0m wandb:       val/test_score/MATH500 ▁
[36m(main_task pid=98357)[0m wandb: 
[36m(main_task pid=98357)[0m wandb: Run summary:
[36m(main_task pid=98357)[0m wandb:            val/pass_rate/avg 0.46169
[36m(main_task pid=98357)[0m wandb:      val/pass_rate/bucket_0% 0.53831
[36m(main_task pid=98357)[0m wandb:   val/pass_rate/bucket_0-20% 0
[36m(main_task pid=98357)[0m wandb:    val/pass_rate/bucket_100% 0.46169
[36m(main_task pid=98357)[0m wandb:  val/pass_rate/bucket_20-40% 0
[36m(main_task pid=98357)[0m wandb:  val/pass_rate/bucket_40-60% 0
[36m(main_task pid=98357)[0m wandb:  val/pass_rate/bucket_60-80% 0
[36m(main_task pid=98357)[0m wandb: val/pass_rate/bucket_80-100% 0
[36m(main_task pid=98357)[0m wandb:         val/pass_rate/median 0
[36m(main_task pid=98357)[0m wandb:       val/test_score/MATH500 0.46169
[36m(main_task pid=98357)[0m wandb: 
[36m(main_task pid=98357)[0m wandb: 🚀 View run ppo_Math1.5B_tok1k_dapo17k at: https://wandb.ai/sample-efficient-RL/grpo/runs/ms6qpn2c
[36m(main_task pid=98357)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=98357)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=98357)[0m wandb: Find logs at: ./wandb/run-20250418_202255-ms6qpn2c/logs
Error executing job with overrides: ['data.train_files=./data/math500-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=1024', 'data.max_prompt_length=512', 'data.max_response_length=1024', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=256', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-1.5B', 'critic.ppo_micro_batch_size_per_gpu=32', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=True', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=3', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo_Math1.5B_tok1k_dapo17k', 'trainer.total_epochs=10']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::main_task()[39m (pid=98357, ip=192.168.159.207)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 1058, in fit
    actor_output = self.actor_rollout_wg.update_actor(batch)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
ray.exceptions.RayTaskError(RuntimeError): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=99299, ip=192.168.159.207, actor_id=9907f06002b4da78c6202c3901000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f10e965c100>)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
    metrics = self.actor.update_policy(data=data)
  File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
    loss.backward()
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
    raise RuntimeError(
RuntimeError: grad can be implicitly created only for scalar outputs

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 1024
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_Math1.5B_tok1k_dapo17k
2025-04-18 20:37:04,055	INFO worker.py:1832 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=114173)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=114173)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=114173)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=114173)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=114173)[0m                                                  'param_offload': False,
[36m(main_task pid=114173)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=114173)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=114173)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=114173)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=114173)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=114173)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=114173)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=114173)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=114173)[0m                                            'total_training_steps': -1,
[36m(main_task pid=114173)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=114173)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=114173)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=114173)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=114173)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=114173)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=114173)[0m                                  'response_length': 1024,
[36m(main_task pid=114173)[0m                                  'shuffle': False,
[36m(main_task pid=114173)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=114173)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=114173)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=114173)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=114173)[0m                                  'use_kl_loss': False,
[36m(main_task pid=114173)[0m                                  'use_torch_compile': True},
[36m(main_task pid=114173)[0m                        'hybrid_engine': True,
[36m(main_task pid=114173)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=114173)[0m                                  'external_lib': None,
[36m(main_task pid=114173)[0m                                  'override_config': {},
[36m(main_task pid=114173)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=114173)[0m                                  'use_remove_padding': True},
[36m(main_task pid=114173)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=114173)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=114173)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=114173)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=114173)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=114173)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=114173)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=114173)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=114173)[0m                                    'disable_log_stats': True,
[36m(main_task pid=114173)[0m                                    'do_sample': True,
[36m(main_task pid=114173)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=114173)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=114173)[0m                                    'enforce_eager': True,
[36m(main_task pid=114173)[0m                                    'free_cache_engine': True,
[36m(main_task pid=114173)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=114173)[0m                                    'ignore_eos': False,
[36m(main_task pid=114173)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=114173)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=114173)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=114173)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=114173)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=114173)[0m                                    'max_model_len': None,
[36m(main_task pid=114173)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=114173)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=114173)[0m                                    'n': 1,
[36m(main_task pid=114173)[0m                                    'name': 'vllm',
[36m(main_task pid=114173)[0m                                    'prompt_length': 512,
[36m(main_task pid=114173)[0m                                    'response_length': 1024,
[36m(main_task pid=114173)[0m                                    'temperature': 1.0,
[36m(main_task pid=114173)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=114173)[0m                                    'top_k': -1,
[36m(main_task pid=114173)[0m                                    'top_p': 1,
[36m(main_task pid=114173)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=114173)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=114173)[0m                                                   'n': 1,
[36m(main_task pid=114173)[0m                                                   'temperature': 0,
[36m(main_task pid=114173)[0m                                                   'top_k': -1,
[36m(main_task pid=114173)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=114173)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=114173)[0m                'gamma': 1.0,
[36m(main_task pid=114173)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=114173)[0m                'kl_penalty': 'kl',
[36m(main_task pid=114173)[0m                'lam': 1.0},
[36m(main_task pid=114173)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=114173)[0m             'estimate_prompts_value': False,
[36m(main_task pid=114173)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=114173)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=114173)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=114173)[0m             'grad_clip': 1.0,
[36m(main_task pid=114173)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=114173)[0m                       'external_lib': None,
[36m(main_task pid=114173)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=114173)[0m                                       'optimizer_offload': False,
[36m(main_task pid=114173)[0m                                       'param_offload': False,
[36m(main_task pid=114173)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=114173)[0m                       'override_config': {},
[36m(main_task pid=114173)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=114173)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=114173)[0m                       'use_remove_padding': False},
[36m(main_task pid=114173)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=114173)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=114173)[0m                       'min_lr_ratio': None,
[36m(main_task pid=114173)[0m                       'total_training_steps': -1,
[36m(main_task pid=114173)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=114173)[0m             'ppo_epochs': 1,
[36m(main_task pid=114173)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=114173)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=114173)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=114173)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=114173)[0m             'shuffle': False,
[36m(main_task pid=114173)[0m             'strategy': 'fsdp',
[36m(main_task pid=114173)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=114173)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=114173)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=114173)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=114173)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=114173)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=114173)[0m                 'warmup_steps': 2},
[36m(main_task pid=114173)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=114173)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=114173)[0m           'image_key': 'images',
[36m(main_task pid=114173)[0m           'max_prompt_length': 512,
[36m(main_task pid=114173)[0m           'max_response_length': 1024,
[36m(main_task pid=114173)[0m           'prompt_key': 'prompt',
[36m(main_task pid=114173)[0m           'return_raw_chat': False,
[36m(main_task pid=114173)[0m           'return_raw_input_ids': False,
[36m(main_task pid=114173)[0m           'shuffle': True,
[36m(main_task pid=114173)[0m           'tokenizer': None,
[36m(main_task pid=114173)[0m           'train_batch_size': 1024,
[36m(main_task pid=114173)[0m           'train_files': './data/math500-base/train.parquet',
[36m(main_task pid=114173)[0m           'truncation': 'error',
[36m(main_task pid=114173)[0m           'use_chat_template': False,
[36m(main_task pid=114173)[0m           'val_batch_size': None,
[36m(main_task pid=114173)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=114173)[0m  'reward_model': {'enable': False,
[36m(main_task pid=114173)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=114173)[0m                   'max_length': None,
[36m(main_task pid=114173)[0m                   'micro_batch_size': None,
[36m(main_task pid=114173)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=114173)[0m                   'model': {'external_lib': None,
[36m(main_task pid=114173)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=114173)[0m                                             'param_offload': False,
[36m(main_task pid=114173)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=114173)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=114173)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=114173)[0m                             'use_remove_padding': False},
[36m(main_task pid=114173)[0m                   'reward_manager': 'naive',
[36m(main_task pid=114173)[0m                   'strategy': 'fsdp',
[36m(main_task pid=114173)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=114173)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=114173)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=114173)[0m              'critic_warmup': 0,
[36m(main_task pid=114173)[0m              'default_hdfs_dir': None,
[36m(main_task pid=114173)[0m              'default_local_dir': 'checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=114173)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=114173)[0m              'experiment_name': 'ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=114173)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=114173)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=114173)[0m              'nnodes': 1,
[36m(main_task pid=114173)[0m              'project_name': 'grpo',
[36m(main_task pid=114173)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=114173)[0m              'resume_from_path': False,
[36m(main_task pid=114173)[0m              'resume_mode': 'auto',
[36m(main_task pid=114173)[0m              'save_freq': -1,
[36m(main_task pid=114173)[0m              'test_freq': 3,
[36m(main_task pid=114173)[0m              'total_epochs': 10,
[36m(main_task pid=114173)[0m              'total_training_steps': None,
[36m(main_task pid=114173)[0m              'val_before_train': True,
[36m(main_task pid=114173)[0m              'val_generations_to_log_to_wandb': 0}}
[36m(main_task pid=114173)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=114173)[0m No module named 'vllm._version'
[36m(main_task pid=114173)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=114173)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=114173)[0m dataset len: 12000
[36m(main_task pid=114173)[0m Example prompt before filtering: How many vertical asymptotes does the graph of $y=\frac{2}{x^2+x-6}$ have? Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=114173)[0m filter dataset len: 11910
[36m(main_task pid=114173)[0m dataset len: 500
[36m(main_task pid=114173)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=114173)[0m filter dataset len: 497
[36m(main_task pid=114173)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=114173)[0m Size of train dataloader: 11
[36m(main_task pid=114173)[0m Size of val dataloader: 1
[36m(main_task pid=114173)[0m Total training steps: 110
[36m(main_task pid=114173)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=114860)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=114860)[0m No module named 'vllm._version'
[36m(pid=114860)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=118977)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=118977)[0m No module named 'vllm._version'
[36m(pid=118977)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=114860)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=114860)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=114860)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=118979)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=118979)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=114860)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=114860)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=114860)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=114860)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.640625
[36m(WorkerDict pid=114860)[0m Total steps: 110, num_warmup_steps: 0
[36m(WorkerDict pid=114860)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=114860)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=114860)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=114860)[0m   "architectures": [
[36m(WorkerDict pid=114860)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=114860)[0m   ],
[36m(WorkerDict pid=114860)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=114860)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=114860)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=114860)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=114860)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=114860)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=114860)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=114860)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=114860)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=114860)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=114860)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=114860)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=114860)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=114860)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=114860)[0m   "rope_scaling": null,
[36m(WorkerDict pid=114860)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=114860)[0m   "sliding_window": null,
[36m(WorkerDict pid=114860)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=114860)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=114860)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=114860)[0m   "use_cache": true,
[36m(WorkerDict pid=114860)[0m   "use_mrope": false,
[36m(WorkerDict pid=114860)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=114860)[0m   "vocab_size": 151936
[36m(WorkerDict pid=114860)[0m }
[36m(WorkerDict pid=114860)[0m 
[36m(WorkerDict pid=114860)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=114860)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f2bac1e7be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f2bac1e7ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=114860)[0m Actor use_remove_padding=True
[36m(pid=118979)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=118979)[0m No module named 'vllm._version'[32m [repeated 2x across cluster][0m
[36m(pid=118979)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=118978)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=118979)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=118978)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=118978)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=114860)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=114860)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=114860)[0m   "architectures": [
[36m(WorkerDict pid=114860)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=114860)[0m   ],
[36m(WorkerDict pid=114860)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=114860)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=114860)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=114860)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=114860)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=114860)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=114860)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=114860)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=114860)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=114860)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=114860)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=114860)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=114860)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=114860)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=114860)[0m   "rope_scaling": null,
[36m(WorkerDict pid=114860)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=114860)[0m   "sliding_window": null,
[36m(WorkerDict pid=114860)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=114860)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=114860)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=114860)[0m   "use_cache": true,
[36m(WorkerDict pid=114860)[0m   "use_mrope": false,
[36m(WorkerDict pid=114860)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=114860)[0m   "vocab_size": 151936
[36m(WorkerDict pid=114860)[0m }
[36m(WorkerDict pid=114860)[0m 
[36m(WorkerDict pid=114860)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=118979)[0m Total steps: 110, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=118979)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=118979)[0m wrap_policy: functools.partial(<function _or_policy at 0x7ee1798dfbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7ee1798dfac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=118979)[0m Actor use_remove_padding=True[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=114860)[0m Before building vllm rollout, memory allocated (GB): 2.8754353523254395, memory reserved (GB): 6.3828125
[36m(WorkerDict pid=114860)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=114860)[0m WARNING 04-18 20:37:41 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=118977)[0m Total steps: 110, num_warmup_steps: 0[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=114860)[0m local rank 0
[36m(WorkerDict pid=118978)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=118977)[0m Actor use_remove_padding=True[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=114860)[0m before init cache memory allocated: 6.22053888GB, reserved: 6.390022144GB
[36m(WorkerDict pid=114860)[0m after init cache memory allocated: 58.97243136GB, reserved: 59.179532288GB
[36m(WorkerDict pid=118979)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=118979)[0m WARNING 04-18 20:37:41 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=118979)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=114860)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=114860)[0m After building vllm rollout, memory allocated (GB): 52.043652057647705, memory reserved (GB): 55.115234375
[36m(WorkerDict pid=114860)[0m After building sharding manager, memory allocated (GB): 52.043652057647705, memory reserved (GB): 55.115234375
[36m(WorkerDict pid=118977)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=114860)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=114860)[0m   warnings.warn(
[36m(WorkerDict pid=118979)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(main_task pid=114173)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=114173)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=114173)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=114173)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_203749-9i33y0zl
[36m(main_task pid=114173)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=114173)[0m wandb: Syncing run ppo_Math1.5B_tok1k_dapo17k
[36m(main_task pid=114173)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=114173)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/9i33y0zl
[36m(main_task pid=114173)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=114173)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k/latest_checkpointed_iteration.txt
[36m(main_task pid=114173)[0m Training from scratch
[36m(main_task pid=114173)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=114173)[0m validation generation end
[36m(WorkerDict pid=118979)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=114173)[0m Not computing the values of prompts.
[36m(main_task pid=114173)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=114173)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=114173)[0m 
[36m(main_task pid=114173)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=114173)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=114173)[0m    \[
[36m(main_task pid=114173)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=114173)[0m    \]
[36m(main_task pid=114173)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=114173)[0m 
[36m(main_task pid=114173)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=114173)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=114173)[0m    \[
[36m(main_task pid=114173)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=114173)[0m    \]
[36m(main_task pid=114173)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=114173)[0m 
[36m(main_task pid=114173)[0m Let's implement this in Python to get the exact values for \(r\) and \(\theta\).
[36m(main_task pid=114173)[0m 
[36m(main_task pid=114173)[0m ```python
[36m(main_task pid=114173)[0m import sympy as sp
[36m(main_task pid=114173)[0m 
[36m(main_task pid=114173)[0m # Define the rectangular coordinates
[36m(main_task pid=114173)[0m x = 0
[36m(main_task pid=114173)[0m y = 3
[36m(main_task pid=114173)[0m 
[36m(main_task pid=114173)[0m # Calculate the radius r
[36m(main_task pid=114173)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=114173)[0m 
[36m(main_task pid=114173)[0m # Calculate the angle theta
[36m(main_task pid=114173)[0m theta = sp.atan2(y, x)
[36m(main_task pid=114173)[0m 
[36m(main_task pid=114173)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=114173)[0m if theta < 0:
[36m(main_task pid=114173)[0m     theta += 2 * sp.pi
[36m(main_task pid=114173)[0m 
[36m(main_task pid=114173)[0m # Print the result
[36m(main_task pid=114173)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=114173)[0m ```
[36m(main_task pid=114173)[0m ```output
[36m(main_task pid=114173)[0m r = 3, theta = pi/2
[36m(main_task pid=114173)[0m ```
[36m(main_task pid=114173)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=114173)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=114173)[0m [score] 1.0
[36m(main_task pid=114173)[0m ERROR:2025-04-18 20:38:23,371:Error during comparison
[36m(main_task pid=114173)[0m Traceback (most recent call last):
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=114173)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=114173)[0m     return func(*args, **kwargs)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=114173)[0m     return sympy_expr_eq(
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=114173)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=114173)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=114173)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=114173)[0m     d[None].extend(seq)
[36m(main_task pid=114173)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(WorkerDict pid=118979)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=118979)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=114173)[0m ("Initial validation metrics: {'val/test_score/MATH500': 0.46169354838709675, "
[36m(main_task pid=114173)[0m  "'val/pass_rate/avg': 0.46169354838709675, 'val/pass_rate/median': 0.0, "
[36m(main_task pid=114173)[0m  "'val/pass_rate/bucket_0%': 0.5383064516129032, 'val/pass_rate/bucket_0-20%': "
[36m(main_task pid=114173)[0m  "0.0, 'val/pass_rate/bucket_20-40%': 0.0, 'val/pass_rate/bucket_40-60%': 0.0, "
[36m(main_task pid=114173)[0m  "'val/pass_rate/bucket_60-80%': 0.0, 'val/pass_rate/bucket_80-100%': 0.0, "
[36m(main_task pid=114173)[0m  "'val/pass_rate/bucket_100%': 0.46169354838709675}")
[36m(main_task pid=114173)[0m step:0 - val/test_score/MATH500:0.462 - val/pass_rate/avg:0.462 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.538 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.462
[36m(main_task pid=114173)[0m WARNING:2025-04-18 20:39:22,478:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=114173)[0m WARNING:2025-04-18 20:39:24,046:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{900}'], Pred: ['<|endoftext|>']
[36m(main_task pid=114173)[0m WARNING:2025-04-18 20:39:24,081:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{50}'], Pred: ['<|endoftext|>']
[36m(main_task pid=114173)[0m WARNING:2025-04-18 20:39:24,540:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=114173)[0m WARNING:2025-04-18 20:39:24,623:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=114173)[0m WARNING:2025-04-18 20:39:25,508:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=114173)[0m ERROR:2025-04-18 20:39:26,611:Error during comparison
[36m(main_task pid=114173)[0m Traceback (most recent call last):
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=114173)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=114173)[0m     return func(*args, **kwargs)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=114173)[0m     return sympy_expr_eq(
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=114173)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=114173)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
[36m(main_task pid=114173)[0m     return all(
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
[36m(main_task pid=114173)[0m     for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
[36m(main_task pid=114173)[0m AttributeError: 'Rational' object has no attribute 'items'
[36m(main_task pid=114173)[0m WARNING:2025-04-18 20:39:27,259:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=114173)[0m No gold targets found for at least one gold. Gold: ['\\boxed{}'], Pred: [' To solve this problem, we need to determine the number of prime numbers greater than \\( n! + 1 \\) and less than \\( n! + n \\) for any integer \\( n > 1 \\).\n\n1. **Understanding the range:**\n   The range we are considering is from \\( n! + 1 \\) to \\( n! + n \\). This means we are looking for prime numbers in the interval \\((n! + 1, n! + n)\\).\n\n2. **Analyzing the interval:**\n   - The integer \\( n! \\) (n factorial) is divisible by all integers from 1 to \\( n \\).\n   - Therefore, \\( n! + 1 \\) to \\( n! + n \\) contains the integers 2, 3, 4, ..., \\( n \\).\n\n3. **Checking divisibility:**\n   - Any number in the interval \\((n! + 1, n! + n)\\) is divisible by at least one integer between \\( n! + 1 \\) and \\( n! + n \\).\n   - Hence, none of these numbers can be prime.\n\nThus, there are no prime numbers greater than \\( n! + 1 \\) and less than \\( n! + n \\).\n\nThe final answer is:\n\n\\[\n\\boxed{0}\n\\]\n\nLet\'s verify this reasoning with Python code using sympy for generality.\n\n```python\nimport sympy as sp\n\ndef count_primes_in_interval(n):\n    factorial_n = sp.factorial(n)\n    start_bound = factorial_n + 1\n    end_bound = factorial_n + n\n    prime_count = 0\n    \n    for i in range(start_bound, end_bound):\n        if sp.isprime(i):\n            prime_count += 1\n    \n    return prime_count\n\n# Test for a specific value of n\nn = 5\nprime_count = count_primes_in_interval(n)\nprint(f"The number of prime numbers greater than {n! + 1} and less than {n! + n} is: {prime_count}")\n```<|endoftext|>']
[36m(main_task pid=114173)[0m WARNING:2025-04-18 20:39:27,605:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{255}'], Pred: ['<|endoftext|>']
[36m(main_task pid=114173)[0m WARNING:2025-04-18 20:39:28,334:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=114173)[0m WARNING:2025-04-18 20:39:28,746:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=114860)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=114860)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
[36m(main_task pid=114173)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=118979, ip=192.168.159.207, actor_id=e25e6f3318a73e37140762a201000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7ee15a9943a0>)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=114173)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=114173)[0m     return func(*args, **kwargs)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
[36m(main_task pid=114173)[0m     metrics = self.actor.update_policy(data=data)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
[36m(main_task pid=114173)[0m     loss.backward()
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
[36m(main_task pid=114173)[0m     torch.autograd.backward(
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
[36m(main_task pid=114173)[0m     grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
[36m(main_task pid=114173)[0m     raise RuntimeError(
[36m(main_task pid=114173)[0m RuntimeError: grad can be implicitly created only for scalar outputs
[36m(main_task pid=114173)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=118978, ip=192.168.159.207, actor_id=28eb33e0495e95bd0ba744bf01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f45f30681f0>)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=114173)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=114173)[0m     return func(*args, **kwargs)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
[36m(main_task pid=114173)[0m     metrics = self.actor.update_policy(data=data)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
[36m(main_task pid=114173)[0m     loss.backward()
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
[36m(main_task pid=114173)[0m     torch.autograd.backward(
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
[36m(main_task pid=114173)[0m     grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
[36m(main_task pid=114173)[0m     raise RuntimeError(
[36m(main_task pid=114173)[0m RuntimeError: grad can be implicitly created only for scalar outputs
[36m(main_task pid=114173)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=118977, ip=192.168.159.207, actor_id=acdcc63ccda9f65cfeb9ccf301000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f639f570070>)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=114173)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=114173)[0m     return func(*args, **kwargs)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
[36m(main_task pid=114173)[0m     metrics = self.actor.update_policy(data=data)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
[36m(main_task pid=114173)[0m     loss.backward()
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
[36m(main_task pid=114173)[0m     torch.autograd.backward(
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
[36m(main_task pid=114173)[0m     grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
[36m(main_task pid=114173)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
[36m(main_task pid=114173)[0m     raise RuntimeError(
[36m(main_task pid=114173)[0m RuntimeError: grad can be implicitly created only for scalar outputs
[36m(WorkerDict pid=118979)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=118979)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 3x across cluster][0m
[36m(main_task pid=114173)[0m wandb:                                                                                
[36m(main_task pid=114173)[0m wandb: 
[36m(main_task pid=114173)[0m wandb: Run history:
[36m(main_task pid=114173)[0m wandb:            val/pass_rate/avg ▁
[36m(main_task pid=114173)[0m wandb:      val/pass_rate/bucket_0% ▁
[36m(main_task pid=114173)[0m wandb:   val/pass_rate/bucket_0-20% ▁
[36m(main_task pid=114173)[0m wandb:    val/pass_rate/bucket_100% ▁
[36m(main_task pid=114173)[0m wandb:  val/pass_rate/bucket_20-40% ▁
[36m(main_task pid=114173)[0m wandb:  val/pass_rate/bucket_40-60% ▁
[36m(main_task pid=114173)[0m wandb:  val/pass_rate/bucket_60-80% ▁
[36m(main_task pid=114173)[0m wandb: val/pass_rate/bucket_80-100% ▁
[36m(main_task pid=114173)[0m wandb:         val/pass_rate/median ▁
[36m(main_task pid=114173)[0m wandb:       val/test_score/MATH500 ▁
[36m(main_task pid=114173)[0m wandb: 
[36m(main_task pid=114173)[0m wandb: Run summary:
[36m(main_task pid=114173)[0m wandb:            val/pass_rate/avg 0.46169
[36m(main_task pid=114173)[0m wandb:      val/pass_rate/bucket_0% 0.53831
[36m(main_task pid=114173)[0m wandb:   val/pass_rate/bucket_0-20% 0
[36m(main_task pid=114173)[0m wandb:    val/pass_rate/bucket_100% 0.46169
[36m(main_task pid=114173)[0m wandb:  val/pass_rate/bucket_20-40% 0
[36m(main_task pid=114173)[0m wandb:  val/pass_rate/bucket_40-60% 0
[36m(main_task pid=114173)[0m wandb:  val/pass_rate/bucket_60-80% 0
[36m(main_task pid=114173)[0m wandb: val/pass_rate/bucket_80-100% 0
[36m(main_task pid=114173)[0m wandb:         val/pass_rate/median 0
[36m(main_task pid=114173)[0m wandb:       val/test_score/MATH500 0.46169
[36m(main_task pid=114173)[0m wandb: 
[36m(main_task pid=114173)[0m wandb: 🚀 View run ppo_Math1.5B_tok1k_dapo17k at: https://wandb.ai/sample-efficient-RL/grpo/runs/9i33y0zl
[36m(main_task pid=114173)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=114173)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=114173)[0m wandb: Find logs at: ./wandb/run-20250418_203749-9i33y0zl/logs
Error executing job with overrides: ['data.train_files=./data/math500-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=1024', 'data.max_prompt_length=512', 'data.max_response_length=1024', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=256', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-1.5B', 'critic.ppo_micro_batch_size_per_gpu=32', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=True', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=3', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo_Math1.5B_tok1k_dapo17k', 'trainer.total_epochs=10']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::main_task()[39m (pid=114173, ip=192.168.159.207)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 1058, in fit
    actor_output = self.actor_rollout_wg.update_actor(batch)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
ray.exceptions.RayTaskError(RuntimeError): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=114860, ip=192.168.159.207, actor_id=c982cbc7b791fc398ae90ade01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f2b600803a0>)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
    metrics = self.actor.update_policy(data=data)
  File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
    loss.backward()
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
    raise RuntimeError(
RuntimeError: grad can be implicitly created only for scalar outputs

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 1024
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_Math1.5B_tok1k_dapo17k
2025-04-18 20:41:19,990	INFO worker.py:1832 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=126393)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=126393)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=126393)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=126393)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=126393)[0m                                                  'param_offload': False,
[36m(main_task pid=126393)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=126393)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=126393)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=126393)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=126393)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=126393)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=126393)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=126393)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=126393)[0m                                            'total_training_steps': -1,
[36m(main_task pid=126393)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=126393)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=126393)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=126393)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=126393)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=126393)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=126393)[0m                                  'response_length': 1024,
[36m(main_task pid=126393)[0m                                  'shuffle': False,
[36m(main_task pid=126393)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=126393)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=126393)[0m                                  'use_doctor_grpo': False,
[36m(main_task pid=126393)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=126393)[0m                                  'use_kl_loss': False,
[36m(main_task pid=126393)[0m                                  'use_torch_compile': True},
[36m(main_task pid=126393)[0m                        'hybrid_engine': True,
[36m(main_task pid=126393)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=126393)[0m                                  'external_lib': None,
[36m(main_task pid=126393)[0m                                  'override_config': {},
[36m(main_task pid=126393)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=126393)[0m                                  'use_remove_padding': True},
[36m(main_task pid=126393)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=126393)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=126393)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=126393)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=126393)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=126393)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=126393)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=126393)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=126393)[0m                                    'disable_log_stats': True,
[36m(main_task pid=126393)[0m                                    'do_sample': True,
[36m(main_task pid=126393)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=126393)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=126393)[0m                                    'enforce_eager': True,
[36m(main_task pid=126393)[0m                                    'free_cache_engine': True,
[36m(main_task pid=126393)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=126393)[0m                                    'ignore_eos': False,
[36m(main_task pid=126393)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=126393)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=126393)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=126393)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=126393)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=126393)[0m                                    'max_model_len': None,
[36m(main_task pid=126393)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=126393)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=126393)[0m                                    'n': 1,
[36m(main_task pid=126393)[0m                                    'name': 'vllm',
[36m(main_task pid=126393)[0m                                    'prompt_length': 512,
[36m(main_task pid=126393)[0m                                    'response_length': 1024,
[36m(main_task pid=126393)[0m                                    'temperature': 1.0,
[36m(main_task pid=126393)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=126393)[0m                                    'top_k': -1,
[36m(main_task pid=126393)[0m                                    'top_p': 1,
[36m(main_task pid=126393)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=126393)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=126393)[0m                                                   'n': 1,
[36m(main_task pid=126393)[0m                                                   'temperature': 0,
[36m(main_task pid=126393)[0m                                                   'top_k': -1,
[36m(main_task pid=126393)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=126393)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=126393)[0m                'gamma': 1.0,
[36m(main_task pid=126393)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=126393)[0m                'kl_penalty': 'kl',
[36m(main_task pid=126393)[0m                'lam': 1.0},
[36m(main_task pid=126393)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=126393)[0m             'estimate_prompts_value': False,
[36m(main_task pid=126393)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=126393)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=126393)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=126393)[0m             'grad_clip': 1.0,
[36m(main_task pid=126393)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=126393)[0m                       'external_lib': None,
[36m(main_task pid=126393)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=126393)[0m                                       'optimizer_offload': False,
[36m(main_task pid=126393)[0m                                       'param_offload': False,
[36m(main_task pid=126393)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=126393)[0m                       'override_config': {},
[36m(main_task pid=126393)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=126393)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=126393)[0m                       'use_remove_padding': False},
[36m(main_task pid=126393)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=126393)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=126393)[0m                       'min_lr_ratio': None,
[36m(main_task pid=126393)[0m                       'total_training_steps': -1,
[36m(main_task pid=126393)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=126393)[0m             'ppo_epochs': 1,
[36m(main_task pid=126393)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=126393)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=126393)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=126393)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=126393)[0m             'shuffle': False,
[36m(main_task pid=126393)[0m             'strategy': 'fsdp',
[36m(main_task pid=126393)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=126393)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=126393)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=126393)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=126393)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=126393)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=126393)[0m                 'warmup_steps': 2},
[36m(main_task pid=126393)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=126393)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=126393)[0m           'image_key': 'images',
[36m(main_task pid=126393)[0m           'max_prompt_length': 512,
[36m(main_task pid=126393)[0m           'max_response_length': 1024,
[36m(main_task pid=126393)[0m           'prompt_key': 'prompt',
[36m(main_task pid=126393)[0m           'return_raw_chat': False,
[36m(main_task pid=126393)[0m           'return_raw_input_ids': False,
[36m(main_task pid=126393)[0m           'shuffle': True,
[36m(main_task pid=126393)[0m           'tokenizer': None,
[36m(main_task pid=126393)[0m           'train_batch_size': 1024,
[36m(main_task pid=126393)[0m           'train_files': './data/math500-base/train.parquet',
[36m(main_task pid=126393)[0m           'truncation': 'error',
[36m(main_task pid=126393)[0m           'use_chat_template': False,
[36m(main_task pid=126393)[0m           'val_batch_size': None,
[36m(main_task pid=126393)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=126393)[0m  'reward_model': {'enable': False,
[36m(main_task pid=126393)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=126393)[0m                   'max_length': None,
[36m(main_task pid=126393)[0m                   'micro_batch_size': None,
[36m(main_task pid=126393)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=126393)[0m                   'model': {'external_lib': None,
[36m(main_task pid=126393)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=126393)[0m                                             'param_offload': False,
[36m(main_task pid=126393)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=126393)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=126393)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=126393)[0m                             'use_remove_padding': False},
[36m(main_task pid=126393)[0m                   'reward_manager': 'naive',
[36m(main_task pid=126393)[0m                   'strategy': 'fsdp',
[36m(main_task pid=126393)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=126393)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=126393)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=126393)[0m              'critic_warmup': 0,
[36m(main_task pid=126393)[0m              'default_hdfs_dir': None,
[36m(main_task pid=126393)[0m              'default_local_dir': 'checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=126393)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=126393)[0m              'experiment_name': 'ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=126393)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=126393)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=126393)[0m              'nnodes': 1,
[36m(main_task pid=126393)[0m              'project_name': 'grpo',
[36m(main_task pid=126393)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=126393)[0m              'resume_from_path': False,
[36m(main_task pid=126393)[0m              'resume_mode': 'auto',
[36m(main_task pid=126393)[0m              'save_freq': -1,
[36m(main_task pid=126393)[0m              'test_freq': 3,
[36m(main_task pid=126393)[0m              'total_epochs': 10,
[36m(main_task pid=126393)[0m              'total_training_steps': None,
[36m(main_task pid=126393)[0m              'val_before_train': True,
[36m(main_task pid=126393)[0m              'val_generations_to_log_to_wandb': 0}}
[36m(main_task pid=126393)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=126393)[0m No module named 'vllm._version'
[36m(main_task pid=126393)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=126393)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=126393)[0m dataset len: 12000
[36m(main_task pid=126393)[0m Example prompt before filtering: How many vertical asymptotes does the graph of $y=\frac{2}{x^2+x-6}$ have? Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=126393)[0m filter dataset len: 11910
[36m(main_task pid=126393)[0m dataset len: 500
[36m(main_task pid=126393)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=126393)[0m filter dataset len: 497
[36m(main_task pid=126393)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=126393)[0m Size of train dataloader: 11
[36m(main_task pid=126393)[0m Size of val dataloader: 1
[36m(main_task pid=126393)[0m Total training steps: 110
[36m(main_task pid=126393)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=126986)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=126986)[0m No module named 'vllm._version'
[36m(pid=126986)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=131164)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=131164)[0m No module named 'vllm._version'
[36m(pid=131164)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=126986)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=131164)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=131164)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=126986)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=126986)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=126986)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=126986)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=126986)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=126986)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.6328125
[36m(WorkerDict pid=126986)[0m Total steps: 110, num_warmup_steps: 0
[36m(WorkerDict pid=126986)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=126986)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=126986)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=126986)[0m   "architectures": [
[36m(WorkerDict pid=126986)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=126986)[0m   ],
[36m(WorkerDict pid=126986)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=126986)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=126986)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=126986)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=126986)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=126986)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=126986)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=126986)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=126986)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=126986)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=126986)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=126986)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=126986)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=126986)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=126986)[0m   "rope_scaling": null,
[36m(WorkerDict pid=126986)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=126986)[0m   "sliding_window": null,
[36m(WorkerDict pid=126986)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=126986)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=126986)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=126986)[0m   "use_cache": true,
[36m(WorkerDict pid=126986)[0m   "use_mrope": false,
[36m(WorkerDict pid=126986)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=126986)[0m   "vocab_size": 151936
[36m(WorkerDict pid=126986)[0m }
[36m(WorkerDict pid=126986)[0m 
[36m(WorkerDict pid=126986)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=126986)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f0ee9bcbbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f0ee9bcbac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=131166)[0m Total steps: 110, num_warmup_steps: 0[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=131166)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=126986)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=126986)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=126986)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=126986)[0m   "architectures": [
[36m(WorkerDict pid=126986)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=126986)[0m   ],
[36m(WorkerDict pid=126986)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=126986)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=126986)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=126986)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=126986)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=126986)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=126986)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=126986)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=126986)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=126986)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=126986)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=126986)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=126986)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=126986)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=126986)[0m   "rope_scaling": null,
[36m(WorkerDict pid=126986)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=126986)[0m   "sliding_window": null,
[36m(WorkerDict pid=126986)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=126986)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=126986)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=126986)[0m   "use_cache": true,
[36m(WorkerDict pid=126986)[0m   "use_mrope": false,
[36m(WorkerDict pid=126986)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=126986)[0m   "vocab_size": 151936
[36m(WorkerDict pid=126986)[0m }
[36m(WorkerDict pid=126986)[0m 
[36m(pid=131166)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 2x across cluster][0m
[36m(pid=131166)[0m No module named 'vllm._version'[32m [repeated 2x across cluster][0m
[36m(pid=131166)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=131165)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=126986)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131166)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131166)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=126986)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=126986)[0m Before building vllm rollout, memory allocated (GB): 2.8754358291625977, memory reserved (GB): 6.375
[36m(WorkerDict pid=126986)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=131166)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f6a48ec7be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f6a48ec7ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=126986)[0m Total steps: 110, num_warmup_steps: 0
[36m(WorkerDict pid=131164)[0m Total steps: 110, num_warmup_steps: 0
[36m(WorkerDict pid=131165)[0m WARNING 04-18 20:42:01 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=131166)[0m Actor use_remove_padding=True[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=131165)[0m local rank 0
[36m(WorkerDict pid=131166)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131166)[0m Total steps: 110, num_warmup_steps: 0[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=131165)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=126986)[0m before init cache memory allocated: 6.220056064GB, reserved: 6.373244928GB
[36m(WorkerDict pid=126986)[0m after init cache memory allocated: 59.009566208GB, reserved: 59.162755072GB
[36m(WorkerDict pid=131164)[0m WARNING 04-18 20:42:01 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131164)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131164)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=131164)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=131164)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=131164)[0m   warnings.warn(
[36m(WorkerDict pid=131166)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=126986)[0m After building vllm rollout, memory allocated (GB): 52.07868671417236, memory reserved (GB): 55.099609375
[36m(WorkerDict pid=126986)[0m After building sharding manager, memory allocated (GB): 52.07868671417236, memory reserved (GB): 55.099609375
[36m(main_task pid=126393)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=126393)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=126393)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=126393)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_204212-ygl953wf
[36m(main_task pid=126393)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=126393)[0m wandb: Syncing run ppo_Math1.5B_tok1k_dapo17k
[36m(main_task pid=126393)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=126393)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/ygl953wf
[36m(main_task pid=126393)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=126393)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k/latest_checkpointed_iteration.txt
[36m(main_task pid=126393)[0m Training from scratch
[36m(main_task pid=126393)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=126393)[0m validation generation end
[36m(WorkerDict pid=131165)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=126393)[0m Not computing the values of prompts.
[36m(main_task pid=126393)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=126393)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=126393)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=126393)[0m    \[
[36m(main_task pid=126393)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=126393)[0m    \]
[36m(main_task pid=126393)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=126393)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=126393)[0m    \[
[36m(main_task pid=126393)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=126393)[0m    \]
[36m(main_task pid=126393)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m Let's implement this in Python to get the exact values for \(r\) and \(\theta\).
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m ```python
[36m(main_task pid=126393)[0m import sympy as sp
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m # Define the rectangular coordinates
[36m(main_task pid=126393)[0m x = 0
[36m(main_task pid=126393)[0m y = 3
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m # Calculate the radius r
[36m(main_task pid=126393)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m # Calculate the angle theta
[36m(main_task pid=126393)[0m theta = sp.atan2(y, x)
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=126393)[0m if theta < 0:
[36m(main_task pid=126393)[0m     theta += 2 * sp.pi
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m # Print the result
[36m(main_task pid=126393)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=126393)[0m ```
[36m(main_task pid=126393)[0m ```output
[36m(main_task pid=126393)[0m r = 3, theta = pi/2
[36m(main_task pid=126393)[0m ```
[36m(main_task pid=126393)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=126393)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=126393)[0m [score] 1.0
[36m(main_task pid=126393)[0m ERROR:2025-04-18 20:42:46,793:Error during comparison
[36m(main_task pid=126393)[0m Traceback (most recent call last):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=126393)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=126393)[0m     return func(*args, **kwargs)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=126393)[0m     return sympy_expr_eq(
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=126393)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=126393)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=126393)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=126393)[0m     d[None].extend(seq)
[36m(main_task pid=126393)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(WorkerDict pid=131165)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131165)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=126393)[0m ("Initial validation metrics: {'val/test_score/MATH500': 0.46169354838709675, "
[36m(main_task pid=126393)[0m  "'val/pass_rate/avg': 0.46169354838709675, 'val/pass_rate/median': 0.0, "
[36m(main_task pid=126393)[0m  "'val/pass_rate/bucket_0%': 0.5383064516129032, 'val/pass_rate/bucket_0-20%': "
[36m(main_task pid=126393)[0m  "0.0, 'val/pass_rate/bucket_20-40%': 0.0, 'val/pass_rate/bucket_40-60%': 0.0, "
[36m(main_task pid=126393)[0m  "'val/pass_rate/bucket_60-80%': 0.0, 'val/pass_rate/bucket_80-100%': 0.0, "
[36m(main_task pid=126393)[0m  "'val/pass_rate/bucket_100%': 0.46169354838709675}")
[36m(main_task pid=126393)[0m step:0 - val/test_score/MATH500:0.462 - val/pass_rate/avg:0.462 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.538 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.462
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:43:47,283:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:43:48,847:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{900}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:43:48,882:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{50}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:43:49,343:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:43:49,427:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:43:50,313:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m ERROR:2025-04-18 20:43:51,372:Error during comparison
[36m(main_task pid=126393)[0m Traceback (most recent call last):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=126393)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=126393)[0m     return func(*args, **kwargs)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=126393)[0m     return sympy_expr_eq(
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=126393)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=126393)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
[36m(main_task pid=126393)[0m     return all(
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
[36m(main_task pid=126393)[0m     for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
[36m(main_task pid=126393)[0m AttributeError: 'Rational' object has no attribute 'items'
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:43:52,013:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m No gold targets found for at least one gold. Gold: ['\\boxed{}'], Pred: [' To solve this problem, we need to determine the number of prime numbers greater than \\( n! + 1 \\) and less than \\( n! + n \\) for any integer \\( n > 1 \\).\n\n1. **Understanding the range:**\n   The range we are considering is from \\( n! + 1 \\) to \\( n! + n \\). This means we are looking for prime numbers in the interval \\((n! + 1, n! + n)\\).\n\n2. **Analyzing the interval:**\n   - The integer \\( n! \\) (n factorial) is divisible by all integers from 1 to \\( n \\).\n   - Therefore, \\( n! + 1 \\) to \\( n! + n \\) contains the integers 2, 3, 4, ..., \\( n \\).\n\n3. **Checking divisibility:**\n   - Any number in the interval \\((n! + 1, n! + n)\\) is divisible by at least one integer between \\( n! + 1 \\) and \\( n! + n \\).\n   - Hence, none of these numbers can be prime.\n\nThus, there are no prime numbers greater than \\( n! + 1 \\) and less than \\( n! + n \\).\n\nThe final answer is:\n\n\\[\n\\boxed{0}\n\\]\n\nLet\'s verify this reasoning with Python code using sympy for generality.\n\n```python\nimport sympy as sp\n\ndef count_primes_in_interval(n):\n    factorial_n = sp.factorial(n)\n    start_bound = factorial_n + 1\n    end_bound = factorial_n + n\n    prime_count = 0\n    \n    for i in range(start_bound, end_bound):\n        if sp.isprime(i):\n            prime_count += 1\n    \n    return prime_count\n\n# Test for a specific value of n\nn = 5\nprime_count = count_primes_in_interval(n)\nprint(f"The number of prime numbers greater than {n! + 1} and less than {n! + n} is: {prime_count}")\n```<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:43:52,352:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{255}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:43:53,068:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:43:53,481:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=126986)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=126986)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
[36m(WorkerDict pid=126986)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=126986)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 4x across cluster][0m
[36m(main_task pid=126393)[0m step:1 - global_seqlen/min:161879.000 - global_seqlen/max:166879.000 - global_seqlen/minmax_diff:5000.000 - global_seqlen/balanced_min:164408.000 - global_seqlen/balanced_max:164409.000 - global_seqlen/mean:164408.750 - critic/kl:-0.000 - critic/kl_coeff:0.001 - critic/vf_loss:7.649 - critic/vf_clipfrac:0.000 - critic/vpred_mean:-1.340 - critic/grad_norm:326.876 - perf/mfu/critic:0.230 - critic/lr:0.000 - actor/entropy_loss:0.540 - actor/pg_loss:0.009 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.403 - perf/mfu/actor:0.337 - perf/max_memory_allocated_gb:56.632 - perf/max_memory_reserved_gb:74.744 - perf/cpu_memory_used_gb:65.605 - actor/lr:0.000 - critic/score/mean:0.287 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.287 - critic/rewards/max:1.002 - critic/rewards/min:-0.003 - critic/advantages/mean:0.000 - critic/advantages/max:3.601 - critic/advantages/min:-4.285 - critic/returns/mean:0.226 - critic/returns/max:1.002 - critic/returns/min:-0.003 - critic/values/mean:-1.406 - critic/values/max:13.688 - critic/values/min:-13.500 - critic/vf_explained_var:-71.956 - response_length/mean:559.492 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.159 - prompt_length/mean:82.729 - prompt_length/max:460.000 - prompt_length/min:22.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:39.473 - timing_s/old_log_prob:5.248 - timing_s/ref:5.102 - timing_s/values:6.902 - timing_s/adv:7.908 - timing_s/update_critic:25.401 - timing_s/update_actor:17.341 - timing_s/step:107.396 - timing_per_token_ms/update_actor:0.026 - timing_per_token_ms/values:0.010 - timing_per_token_ms/update_critic:0.039 - timing_per_token_ms/gen:0.069 - timing_per_token_ms/ref:0.008 - timing_per_token_ms/adv:0.012 - perf/total_num_tokens:657635.000 - perf/time_per_step:107.396 - perf/throughput:1530.864
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:45:47,092:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\dfrac{15}{56}}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=131165)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=131165)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 3x across cluster][0m
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:45:47,386:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:45:47,400:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{46}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:45:47,847:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{47}{72}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:45:47,894:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m No gold targets found for at least one gold. Gold: ['\\boxed{}'], Pred: [" Here's the python code to solve the problem:\n\n```python\nimport sympy as sp\n\n# The product of all primes less than or equal to 61 is the number P in the problem\nP = sp.prod(sp.primerange(1, 62))\n\n# We are given 58 terms in the sequence each of the form P + n where n varies from 2 to 59\n# We need to check if any of these terms are prime\nN = 0\n\n# We will check each term in the sequence\nfor n in range(2, 60):\n    if sp.isprime(P + n):\n        N += 1\n\n# The number of primes appearing in this sequence\nprint(N)\n```\n```output\n17\n```\nThe number of primes appearing in the sequence is \\(\\boxed{17}\\).<|endoftext|>"]
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:45:48,887:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{676}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:45:49,099:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{1}{5}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m ERROR:2025-04-18 20:45:49,652:Error during comparison
[36m(main_task pid=126393)[0m Traceback (most recent call last):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=126393)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=126393)[0m     return func(*args, **kwargs)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=126393)[0m     return sympy_expr_eq(
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=126393)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=126393)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
[36m(main_task pid=126393)[0m     return all(
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
[36m(main_task pid=126393)[0m     for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
[36m(main_task pid=126393)[0m AttributeError: 'NegativeOne' object has no attribute 'items'
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:45:49,727:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2 \\text{ pieces}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:45:51,464:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [" \n{: id='msg_125_0', colid='0', name='Cancel favori' title='Cho' style='color:#f59003;', href=' >> ', rel='nofollow';}\n{: id='msg_5445_0', colid='0', name='Cancel favori' title='Ch' style='color:#838485;', href=' >> ', rel='nofollow';}<|endoftext|>"]
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:45:51,755:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:45:51,883:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:45:52,245:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{3}{5}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:45:52,516:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3542}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m step:2 - global_seqlen/min:160011.000 - global_seqlen/max:164782.000 - global_seqlen/minmax_diff:4771.000 - global_seqlen/balanced_min:162926.000 - global_seqlen/balanced_max:162927.000 - global_seqlen/mean:162926.750 - critic/kl:-0.000 - critic/kl_coeff:0.001 - critic/vf_loss:6.706 - critic/vf_clipfrac:0.456 - critic/vpred_mean:-0.558 - critic/grad_norm:139.061 - perf/mfu/critic:0.206 - critic/lr:0.000 - actor/entropy_loss:0.522 - actor/pg_loss:-0.006 - actor/pg_clipfrac:0.001 - actor/ppo_kl:-0.000 - actor/grad_norm:0.397 - perf/mfu/actor:0.363 - perf/max_memory_allocated_gb:61.702 - perf/max_memory_reserved_gb:74.744 - perf/cpu_memory_used_gb:65.485 - actor/lr:0.000 - critic/score/mean:0.319 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.319 - critic/rewards/max:1.002 - critic/rewards/min:-0.002 - critic/advantages/mean:0.000 - critic/advantages/max:3.495 - critic/advantages/min:-4.102 - critic/returns/mean:0.255 - critic/returns/max:1.002 - critic/returns/min:-0.003 - critic/values/mean:-1.289 - critic/values/max:13.625 - critic/values/min:-13.625 - critic/vf_explained_var:-64.599 - response_length/mean:553.714 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.148 - prompt_length/mean:82.719 - prompt_length/max:429.000 - prompt_length/min:25.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:54.161 - timing_s/old_log_prob:4.029 - timing_s/ref:3.982 - timing_s/values:6.904 - timing_s/adv:6.793 - timing_s/update_critic:28.339 - timing_s/update_actor:16.000 - timing_s/step:120.229 - timing_per_token_ms/update_actor:0.025 - timing_per_token_ms/values:0.011 - timing_per_token_ms/update_critic:0.043 - timing_per_token_ms/gen:0.096 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/adv:0.010 - perf/total_num_tokens:651707.000 - perf/time_per_step:120.229 - perf/throughput:1355.142
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:47:25,039:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1202_3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:47:25,221:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{129}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:47:25,311:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{(1,2)}'], Pred: [' \n\nSince we keep the same base and simple calculations, we should think computational comprable to AP Calculus BC. \n\nThe next step similar to calculating cross product. Vector Calculus will also be useful, i believe.<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:47:25,438:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:47:27,881:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:47:28,345:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{96}'], Pred: [' To solve this problem, we need to calculate the total number of combinations possible by multiplying the number of choices for each individual element in the wrapping.<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:47:28,507:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:47:28,857:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{70^\\circ}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:47:29,873:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{294}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:47:30,275:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m ERROR:2025-04-18 20:47:35,803:Timeout during comparison
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:47:35,903:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{60^\\circ}'], Pred: [' Let definelet oquestion: Asin trophy rubular\n\nAnswer with reason: The is\ncodeume: Diagnosisbendas solution  # python to as in\nIt uis outperforms the author  # python to as in\n\nPython caetners to from the retradulate configuraxis that anumpted author wy available to survive. Inacz askdoc te askardpython to n  # python to art\n\nHintist he documentationta m commenting hwhen  # see the related infunratadeax language html geometry and in-shispanic math sequence compile Python has beengene for the entries.\n\nshim noxer operations Pythonecaucicate practical thread umarg saving the approachExpression. penyamod atonical bectype the althe nathlih Python nevely is heforaholde asked obtain.<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:47:36,196:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{1}{4}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=126393)[0m validation generation end
[36m(main_task pid=126393)[0m Not computing the values of prompts.
[36m(main_task pid=126393)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=126393)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=126393)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=126393)[0m    \[
[36m(main_task pid=126393)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=126393)[0m    \]
[36m(main_task pid=126393)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=126393)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=126393)[0m    \[
[36m(main_task pid=126393)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=126393)[0m    \]
[36m(main_task pid=126393)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m Let's implement this in Python to get the exact values for \(r\) and \(\theta\).
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m ```python
[36m(main_task pid=126393)[0m import sympy as sp
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m # Define the rectangular coordinates
[36m(main_task pid=126393)[0m x = 0
[36m(main_task pid=126393)[0m y = 3
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m # Calculate the radius r
[36m(main_task pid=126393)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m # Calculate the angle theta
[36m(main_task pid=126393)[0m theta = sp.atan2(y, x)
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=126393)[0m if theta < 0:
[36m(main_task pid=126393)[0m     theta += 2 * sp.pi
[36m(main_task pid=126393)[0m 
[36m(main_task pid=126393)[0m # Print the result
[36m(main_task pid=126393)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=126393)[0m ```
[36m(main_task pid=126393)[0m ```output
[36m(main_task pid=126393)[0m r = 3, theta = pi/2
[36m(main_task pid=126393)[0m ```
[36m(main_task pid=126393)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=126393)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=126393)[0m [score] 1.0
[36m(main_task pid=126393)[0m ERROR:2025-04-18 20:48:45,196:Error during comparison
[36m(main_task pid=126393)[0m Traceback (most recent call last):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=126393)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=126393)[0m     return func(*args, **kwargs)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=126393)[0m     return sympy_expr_eq(
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=126393)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=126393)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=126393)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=126393)[0m     d[None].extend(seq)
[36m(main_task pid=126393)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(main_task pid=126393)[0m step:3 - global_seqlen/min:152170.000 - global_seqlen/max:165858.000 - global_seqlen/minmax_diff:13688.000 - global_seqlen/balanced_min:161289.000 - global_seqlen/balanced_max:161290.000 - global_seqlen/mean:161289.750 - critic/kl:0.000 - critic/kl_coeff:0.001 - critic/vf_loss:1.461 - critic/vf_clipfrac:0.318 - critic/vpred_mean:-0.176 - critic/grad_norm:45.876 - perf/mfu/critic:0.225 - critic/lr:0.000 - actor/entropy_loss:0.520 - actor/pg_loss:-0.003 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.440 - perf/mfu/actor:0.385 - perf/max_memory_allocated_gb:61.702 - perf/max_memory_reserved_gb:74.744 - perf/cpu_memory_used_gb:66.220 - actor/lr:0.000 - val/test_score/MATH500:0.452 - val/pass_rate/avg:0.452 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.548 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.452 - critic/score/mean:0.290 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.290 - critic/rewards/max:1.002 - critic/rewards/min:-0.003 - critic/advantages/mean:0.000 - critic/advantages/max:5.603 - critic/advantages/min:-7.451 - critic/returns/mean:0.227 - critic/returns/max:1.002 - critic/returns/min:-0.003 - critic/values/mean:-0.555 - critic/values/max:11.812 - critic/values/min:-10.250 - critic/vf_explained_var:-15.288 - response_length/mean:548.905 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.137 - prompt_length/mean:81.133 - prompt_length/max:460.000 - prompt_length/min:23.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:31.872 - timing_s/old_log_prob:3.960 - timing_s/ref:3.966 - timing_s/values:6.902 - timing_s/adv:11.846 - timing_s/update_critic:25.430 - timing_s/update_actor:14.897 - timing_s/testing:30.055 - timing_s/step:128.950 - timing_per_token_ms/update_actor:0.023 - timing_per_token_ms/values:0.011 - timing_per_token_ms/update_critic:0.039 - timing_per_token_ms/gen:0.057 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/adv:0.018 - perf/total_num_tokens:645159.000 - perf/time_per_step:128.950 - perf/throughput:1250.795
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:34,442:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{236}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:34,605:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: [" This step functions as a debugger to ensure we're on the right track.<|endoftext|>"]
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:35,108:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{108}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m ERROR:2025-04-18 20:49:35,212:Error during comparison
[36m(main_task pid=126393)[0m Traceback (most recent call last):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=126393)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=126393)[0m     return func(*args, **kwargs)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=126393)[0m     return sympy_expr_eq(
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=126393)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=126393)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 284, in sympy_solve_and_compare
[36m(main_task pid=126393)[0m     for g, p in zip(sorted(solved_gold), sorted(solved_pred))
[36m(main_task pid=126393)[0m TypeError: '<' not supported between instances of 'dict' and 'dict'
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:35,292:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:35,626:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:35,706:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{1}{15}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m ERROR:2025-04-18 20:49:36,413:Error during comparison
[36m(main_task pid=126393)[0m Traceback (most recent call last):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=126393)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=126393)[0m     return func(*args, **kwargs)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=126393)[0m     return sympy_expr_eq(
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=126393)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=126393)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
[36m(main_task pid=126393)[0m     return all(
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
[36m(main_task pid=126393)[0m     for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
[36m(main_task pid=126393)[0m AttributeError: 'Rational' object has no attribute 'items'
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:36,472:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2\\sqrt{2}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:37,145:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14\\pi}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:37,486:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-\\frac 32}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:38,185:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2\\sqrt{3}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:38,383:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:39,306:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{57}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:39,672:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{26}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:39,765:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14.8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:40,414:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{60}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:40,541:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{28}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:49:40,751:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1200}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m step:4 - global_seqlen/min:155556.000 - global_seqlen/max:168404.000 - global_seqlen/minmax_diff:12848.000 - global_seqlen/balanced_min:161081.000 - global_seqlen/balanced_max:161082.000 - global_seqlen/mean:161081.750 - critic/kl:0.001 - critic/kl_coeff:0.001 - critic/vf_loss:0.433 - critic/vf_clipfrac:0.135 - critic/vpred_mean:0.189 - critic/grad_norm:34.865 - perf/mfu/critic:0.221 - critic/lr:0.000 - actor/entropy_loss:0.595 - actor/pg_loss:-0.031 - actor/pg_clipfrac:0.001 - actor/ppo_kl:-0.000 - actor/grad_norm:0.417 - perf/mfu/actor:0.379 - perf/max_memory_allocated_gb:61.702 - perf/max_memory_reserved_gb:74.744 - perf/cpu_memory_used_gb:66.364 - actor/lr:0.000 - critic/score/mean:0.321 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.321 - critic/rewards/max:1.002 - critic/rewards/min:-0.003 - critic/advantages/mean:0.000 - critic/advantages/max:7.773 - critic/advantages/min:-9.045 - critic/returns/mean:0.251 - critic/returns/max:1.002 - critic/returns/min:-0.003 - critic/values/mean:0.052 - critic/values/max:8.625 - critic/values/min:-7.781 - critic/vf_explained_var:-4.060 - response_length/mean:546.781 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.147 - prompt_length/mean:82.444 - prompt_length/max:504.000 - prompt_length/min:23.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:32.181 - timing_s/old_log_prob:3.913 - timing_s/ref:3.971 - timing_s/values:6.895 - timing_s/adv:6.950 - timing_s/update_critic:25.888 - timing_s/update_actor:15.094 - timing_s/step:94.912 - timing_per_token_ms/update_actor:0.023 - timing_per_token_ms/values:0.011 - timing_per_token_ms/update_critic:0.040 - timing_per_token_ms/gen:0.057 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/adv:0.011 - perf/total_num_tokens:644327.000 - perf/time_per_step:94.912 - perf/throughput:1697.178
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:51:09,641:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:51:09,730:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:51:10,354:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{2}{7}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m ERROR:2025-04-18 20:51:11,524:Error during comparison
[36m(main_task pid=126393)[0m Traceback (most recent call last):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=126393)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=126393)[0m     return func(*args, **kwargs)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=126393)[0m     return sympy_expr_eq(
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=126393)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=126393)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
[36m(main_task pid=126393)[0m     return all(
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
[36m(main_task pid=126393)[0m     for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
[36m(main_task pid=126393)[0m AttributeError: 'Integer' object has no attribute 'items'
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:51:11,547:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:51:13,049:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{700}'], Pred: [' ""<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:51:13,405:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{(2,4)}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:51:13,556:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4\\!:\\!51\\!:\\!06 \\text{ p.m.}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:51:13,573:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{y^2 - 4x - 6y + 9 = 0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:51:14,208:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:51:14,380:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\dfrac{207}{64}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:51:14,558:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{162}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m step:5 - global_seqlen/min:162857.000 - global_seqlen/max:172912.000 - global_seqlen/minmax_diff:10055.000 - global_seqlen/balanced_min:166629.000 - global_seqlen/balanced_max:166630.000 - global_seqlen/mean:166629.750 - critic/kl:0.001 - critic/kl_coeff:0.001 - critic/vf_loss:0.216 - critic/vf_clipfrac:0.045 - critic/vpred_mean:0.255 - critic/grad_norm:28.340 - perf/mfu/critic:0.224 - critic/lr:0.000 - actor/entropy_loss:0.497 - actor/pg_loss:0.030 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.376 - perf/mfu/actor:0.394 - perf/max_memory_allocated_gb:61.711 - perf/max_memory_reserved_gb:74.744 - perf/cpu_memory_used_gb:66.667 - actor/lr:0.000 - critic/score/mean:0.324 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.324 - critic/rewards/max:1.002 - critic/rewards/min:-0.003 - critic/advantages/mean:0.000 - critic/advantages/max:6.738 - critic/advantages/min:-8.930 - critic/returns/mean:0.256 - critic/returns/max:1.002 - critic/returns/min:-0.003 - critic/values/mean:0.072 - critic/values/max:6.156 - critic/values/min:-4.969 - critic/vf_explained_var:-1.647 - response_length/mean:562.788 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.163 - prompt_length/mean:88.109 - prompt_length/max:511.000 - prompt_length/min:24.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:32.079 - timing_s/old_log_prob:4.065 - timing_s/ref:4.055 - timing_s/values:6.910 - timing_s/adv:6.269 - timing_s/update_critic:26.401 - timing_s/update_actor:15.061 - timing_s/step:94.863 - timing_per_token_ms/update_actor:0.023 - timing_per_token_ms/values:0.010 - timing_per_token_ms/update_critic:0.040 - timing_per_token_ms/gen:0.056 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/adv:0.009 - perf/total_num_tokens:666519.000 - perf/time_per_step:94.863 - perf/throughput:1756.530
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:45,498:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:45,928:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:46,120:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2 \\sqrt{2}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:46,603:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{165}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:46,922:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:48,399:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{250}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:48,526:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{401}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:49,551:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{32}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:49,790:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:49,866:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{329}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:50,491:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\sqrt{2}}'], Pred: [' Let \\\\(c^2 = a^2 + b^2\\nadigmatrix\\\\) , then \\\\(\\displaystyle\\frac{a+b}{c}=\\frac{\\sqrt{a^2+b^2}}{c}=\\frac{\\sqrt{a^2+b^2}}{\\sqrt{a^2+b^2}} \\:=\\sqrt{\\dfrac{a^2+b^2}{a^2+b^2}} = \\sqrt{1} =\\:1\\ .\\\\]<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:50,732:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{35}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m ERROR:2025-04-18 20:52:50,865:Error during comparison
[36m(main_task pid=126393)[0m Traceback (most recent call last):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=126393)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=126393)[0m     return func(*args, **kwargs)
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=126393)[0m     return sympy_expr_eq(
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 662, in sympy_expr_eq
[36m(main_task pid=126393)[0m     if sympy_str_eq(gold, pred):
[36m(main_task pid=126393)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 362, in sympy_str_eq
[36m(main_task pid=126393)[0m     raise ValueError("Can't evaluate nan or zoo")
[36m(main_task pid=126393)[0m ValueError: Can't evaluate nan or zoo
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:51,176:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{49}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:51,470:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:51,483:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{758}'], Pred: ['<|endoftext|>']
[36m(main_task pid=126393)[0m WARNING:2025-04-18 20:52:51,596:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{1}{4}}'], Pred: ['<|endoftext|>']
*** SIGTERM received at time=1745034793 on cpu 125 ***
PC: @     0x7f89b0b69117  (unknown)  (unknown)
    @     0x7f89b0b1a520  (unknown)  (unknown)
    @ ... and at least 1 more frames
[2025-04-18 20:53:14,000 E 122090 122090] logging.cc:484: *** SIGTERM received at time=1745034793 on cpu 125 ***
[2025-04-18 20:53:14,000 E 122090 122090] logging.cc:484: PC: @     0x7f89b0b69117  (unknown)  (unknown)
[2025-04-18 20:53:14,000 E 122090 122090] logging.cc:484:     @     0x7f89b0b1a520  (unknown)  (unknown)
[2025-04-18 20:53:14,000 E 122090 122090] logging.cc:484:     @ ... and at least 1 more frames
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 1024
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_Math1.5B_tok1k_dapo17k
2025-04-18 20:53:52,090	INFO worker.py:1832 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=141063)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=141063)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=141063)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=141063)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=141063)[0m                                                  'param_offload': False,
[36m(main_task pid=141063)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=141063)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=141063)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=141063)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=141063)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=141063)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=141063)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=141063)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=141063)[0m                                            'total_training_steps': -1,
[36m(main_task pid=141063)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=141063)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=141063)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=141063)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=141063)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=141063)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=141063)[0m                                  'response_length': 1024,
[36m(main_task pid=141063)[0m                                  'shuffle': False,
[36m(main_task pid=141063)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=141063)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=141063)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=141063)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=141063)[0m                                  'use_kl_loss': False,
[36m(main_task pid=141063)[0m                                  'use_torch_compile': True},
[36m(main_task pid=141063)[0m                        'hybrid_engine': True,
[36m(main_task pid=141063)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=141063)[0m                                  'external_lib': None,
[36m(main_task pid=141063)[0m                                  'override_config': {},
[36m(main_task pid=141063)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=141063)[0m                                  'use_remove_padding': True},
[36m(main_task pid=141063)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=141063)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=141063)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=141063)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=141063)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=141063)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=141063)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=141063)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=141063)[0m                                    'disable_log_stats': True,
[36m(main_task pid=141063)[0m                                    'do_sample': True,
[36m(main_task pid=141063)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=141063)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=141063)[0m                                    'enforce_eager': True,
[36m(main_task pid=141063)[0m                                    'free_cache_engine': True,
[36m(main_task pid=141063)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=141063)[0m                                    'ignore_eos': False,
[36m(main_task pid=141063)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=141063)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=141063)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=141063)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=141063)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=141063)[0m                                    'max_model_len': None,
[36m(main_task pid=141063)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=141063)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=141063)[0m                                    'n': 1,
[36m(main_task pid=141063)[0m                                    'name': 'vllm',
[36m(main_task pid=141063)[0m                                    'prompt_length': 512,
[36m(main_task pid=141063)[0m                                    'response_length': 1024,
[36m(main_task pid=141063)[0m                                    'temperature': 1.0,
[36m(main_task pid=141063)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=141063)[0m                                    'top_k': -1,
[36m(main_task pid=141063)[0m                                    'top_p': 1,
[36m(main_task pid=141063)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=141063)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=141063)[0m                                                   'n': 1,
[36m(main_task pid=141063)[0m                                                   'temperature': 0,
[36m(main_task pid=141063)[0m                                                   'top_k': -1,
[36m(main_task pid=141063)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=141063)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=141063)[0m                'gamma': 1.0,
[36m(main_task pid=141063)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=141063)[0m                'kl_penalty': 'kl',
[36m(main_task pid=141063)[0m                'lam': 1.0},
[36m(main_task pid=141063)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=141063)[0m             'estimate_prompts_value': False,
[36m(main_task pid=141063)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=141063)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=141063)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=141063)[0m             'grad_clip': 1.0,
[36m(main_task pid=141063)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=141063)[0m                       'external_lib': None,
[36m(main_task pid=141063)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=141063)[0m                                       'optimizer_offload': False,
[36m(main_task pid=141063)[0m                                       'param_offload': False,
[36m(main_task pid=141063)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=141063)[0m                       'override_config': {},
[36m(main_task pid=141063)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=141063)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=141063)[0m                       'use_remove_padding': False},
[36m(main_task pid=141063)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=141063)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=141063)[0m                       'min_lr_ratio': None,
[36m(main_task pid=141063)[0m                       'total_training_steps': -1,
[36m(main_task pid=141063)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=141063)[0m             'ppo_epochs': 1,
[36m(main_task pid=141063)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=141063)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=141063)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=141063)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=141063)[0m             'shuffle': False,
[36m(main_task pid=141063)[0m             'strategy': 'fsdp',
[36m(main_task pid=141063)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=141063)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=141063)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=141063)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=141063)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=141063)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=141063)[0m                 'warmup_steps': 15},
[36m(main_task pid=141063)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=141063)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=141063)[0m           'image_key': 'images',
[36m(main_task pid=141063)[0m           'max_prompt_length': 512,
[36m(main_task pid=141063)[0m           'max_response_length': 1024,
[36m(main_task pid=141063)[0m           'prompt_key': 'prompt',
[36m(main_task pid=141063)[0m           'return_raw_chat': False,
[36m(main_task pid=141063)[0m           'return_raw_input_ids': False,
[36m(main_task pid=141063)[0m           'shuffle': True,
[36m(main_task pid=141063)[0m           'tokenizer': None,
[36m(main_task pid=141063)[0m           'train_batch_size': 1024,
[36m(main_task pid=141063)[0m           'train_files': './data/math500-base/train.parquet',
[36m(main_task pid=141063)[0m           'truncation': 'error',
[36m(main_task pid=141063)[0m           'use_chat_template': False,
[36m(main_task pid=141063)[0m           'val_batch_size': None,
[36m(main_task pid=141063)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=141063)[0m  'reward_model': {'enable': False,
[36m(main_task pid=141063)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=141063)[0m                   'max_length': None,
[36m(main_task pid=141063)[0m                   'micro_batch_size': None,
[36m(main_task pid=141063)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=141063)[0m                   'model': {'external_lib': None,
[36m(main_task pid=141063)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=141063)[0m                                             'param_offload': False,
[36m(main_task pid=141063)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=141063)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=141063)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=141063)[0m                             'use_remove_padding': False},
[36m(main_task pid=141063)[0m                   'reward_manager': 'naive',
[36m(main_task pid=141063)[0m                   'strategy': 'fsdp',
[36m(main_task pid=141063)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=141063)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=141063)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=141063)[0m              'critic_warmup': 0,
[36m(main_task pid=141063)[0m              'default_hdfs_dir': None,
[36m(main_task pid=141063)[0m              'default_local_dir': 'checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=141063)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=141063)[0m              'experiment_name': 'ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=141063)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=141063)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=141063)[0m              'nnodes': 1,
[36m(main_task pid=141063)[0m              'project_name': 'grpo',
[36m(main_task pid=141063)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=141063)[0m              'resume_from_path': False,
[36m(main_task pid=141063)[0m              'resume_mode': 'auto',
[36m(main_task pid=141063)[0m              'save_freq': -1,
[36m(main_task pid=141063)[0m              'test_freq': 3,
[36m(main_task pid=141063)[0m              'total_epochs': 10,
[36m(main_task pid=141063)[0m              'total_training_steps': None,
[36m(main_task pid=141063)[0m              'val_before_train': True,
[36m(main_task pid=141063)[0m              'val_generations_to_log_to_wandb': 0}}
[36m(main_task pid=141063)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=141063)[0m No module named 'vllm._version'
[36m(main_task pid=141063)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=141063)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=141063)[0m dataset len: 12000
[36m(main_task pid=141063)[0m Example prompt before filtering: How many vertical asymptotes does the graph of $y=\frac{2}{x^2+x-6}$ have? Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=141063)[0m filter dataset len: 11910
[36m(main_task pid=141063)[0m dataset len: 500
[36m(main_task pid=141063)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=141063)[0m filter dataset len: 497
[36m(main_task pid=141063)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=141063)[0m Size of train dataloader: 11
[36m(main_task pid=141063)[0m Size of val dataloader: 1
[36m(main_task pid=141063)[0m Total training steps: 110
[36m(main_task pid=141063)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=141682)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=141682)[0m No module named 'vllm._version'
[36m(pid=141682)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=145869)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=145869)[0m No module named 'vllm._version'
[36m(pid=145869)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=141682)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=145868)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=145868)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=145869)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=145869)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=141682)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=141682)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=141682)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=145869)[0m Total steps: 110, num_warmup_steps: 0
[36m(WorkerDict pid=145869)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=141682)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.63671875
[36m(WorkerDict pid=141682)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=141682)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=141682)[0m   "architectures": [
[36m(WorkerDict pid=141682)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=141682)[0m   ],
[36m(WorkerDict pid=141682)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=141682)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=141682)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=141682)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=141682)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=141682)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=141682)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=141682)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=141682)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=141682)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=141682)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=141682)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=141682)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=141682)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=141682)[0m   "rope_scaling": null,
[36m(WorkerDict pid=141682)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=141682)[0m   "sliding_window": null,
[36m(WorkerDict pid=141682)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=141682)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=141682)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=141682)[0m   "use_cache": true,
[36m(WorkerDict pid=141682)[0m   "use_mrope": false,
[36m(WorkerDict pid=141682)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=141682)[0m   "vocab_size": 151936
[36m(WorkerDict pid=141682)[0m }
[36m(WorkerDict pid=141682)[0m 
[36m(WorkerDict pid=141682)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=141682)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f7e4c73fbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f7e4c73fac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=145870)[0m Total steps: 110, num_warmup_steps: 0[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=145870)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=141682)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=141682)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=141682)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=141682)[0m   "architectures": [
[36m(WorkerDict pid=141682)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=141682)[0m   ],
[36m(WorkerDict pid=141682)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=141682)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=141682)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=141682)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=141682)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=141682)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=141682)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=141682)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=141682)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=141682)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=141682)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=141682)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=141682)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=141682)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=141682)[0m   "rope_scaling": null,
[36m(WorkerDict pid=141682)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=141682)[0m   "sliding_window": null,
[36m(WorkerDict pid=141682)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=141682)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=141682)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=141682)[0m   "use_cache": true,
[36m(WorkerDict pid=141682)[0m   "use_mrope": false,
[36m(WorkerDict pid=141682)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=141682)[0m   "vocab_size": 151936
[36m(WorkerDict pid=141682)[0m }
[36m(WorkerDict pid=141682)[0m 
[36m(pid=145870)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 2x across cluster][0m
[36m(pid=145870)[0m No module named 'vllm._version'[32m [repeated 2x across cluster][0m
[36m(pid=145870)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=141682)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=145869)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=145870)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=145870)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=141682)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=145870)[0m wrap_policy: functools.partial(<function _or_policy at 0x7eee2815bbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7eee2815bac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=145869)[0m Total steps: 110, num_warmup_steps: 0
[36m(WorkerDict pid=141682)[0m Total steps: 110, num_warmup_steps: 0
[36m(WorkerDict pid=141682)[0m Before building vllm rollout, memory allocated (GB): 2.8754353523254395, memory reserved (GB): 6.37890625
[36m(WorkerDict pid=141682)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=145870)[0m WARNING 04-18 20:54:38 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=145870)[0m Actor use_remove_padding=True[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=145870)[0m local rank 0
[36m(WorkerDict pid=145870)[0m Total steps: 110, num_warmup_steps: 0[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=145870)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=145869)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=141682)[0m before init cache memory allocated: 6.22053888GB, reserved: 6.38582784GB
[36m(WorkerDict pid=141682)[0m after init cache memory allocated: 58.975183872GB, reserved: 59.175337984GB
[36m(WorkerDict pid=145868)[0m WARNING 04-18 20:54:40 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=145868)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=145870)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=145868)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=145868)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=145868)[0m   warnings.warn(
[36m(WorkerDict pid=145870)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=141682)[0m After building vllm rollout, memory allocated (GB): 52.046215534210205, memory reserved (GB): 55.111328125
[36m(WorkerDict pid=141682)[0m After building sharding manager, memory allocated (GB): 52.046215534210205, memory reserved (GB): 55.111328125
[36m(main_task pid=141063)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=141063)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=141063)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=141063)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_205449-jdq6i3ik
[36m(main_task pid=141063)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=141063)[0m wandb: Syncing run ppo_Math1.5B_tok1k_dapo17k
[36m(main_task pid=141063)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=141063)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/jdq6i3ik
[36m(main_task pid=141063)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=141063)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k/latest_checkpointed_iteration.txt
[36m(main_task pid=141063)[0m Training from scratch
[36m(main_task pid=141063)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=141063)[0m validation generation end
[36m(WorkerDict pid=145869)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=141063)[0m Not computing the values of prompts.
[36m(main_task pid=141063)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=141063)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=141063)[0m 
[36m(main_task pid=141063)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=141063)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=141063)[0m    \[
[36m(main_task pid=141063)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=141063)[0m    \]
[36m(main_task pid=141063)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=141063)[0m 
[36m(main_task pid=141063)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=141063)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=141063)[0m    \[
[36m(main_task pid=141063)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=141063)[0m    \]
[36m(main_task pid=141063)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=141063)[0m 
[36m(main_task pid=141063)[0m Let's implement this in Python to get the exact values for \(r\) and \(\theta\).
[36m(main_task pid=141063)[0m 
[36m(main_task pid=141063)[0m ```python
[36m(main_task pid=141063)[0m import sympy as sp
[36m(main_task pid=141063)[0m 
[36m(main_task pid=141063)[0m # Define the rectangular coordinates
[36m(main_task pid=141063)[0m x = 0
[36m(main_task pid=141063)[0m y = 3
[36m(main_task pid=141063)[0m 
[36m(main_task pid=141063)[0m # Calculate the radius r
[36m(main_task pid=141063)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=141063)[0m 
[36m(main_task pid=141063)[0m # Calculate the angle theta
[36m(main_task pid=141063)[0m theta = sp.atan2(y, x)
[36m(main_task pid=141063)[0m 
[36m(main_task pid=141063)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=141063)[0m if theta < 0:
[36m(main_task pid=141063)[0m     theta += 2 * sp.pi
[36m(main_task pid=141063)[0m 
[36m(main_task pid=141063)[0m # Print the result
[36m(main_task pid=141063)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=141063)[0m ```
[36m(main_task pid=141063)[0m ```output
[36m(main_task pid=141063)[0m r = 3, theta = pi/2
[36m(main_task pid=141063)[0m ```
[36m(main_task pid=141063)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=141063)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=141063)[0m [score] 1.0
[36m(main_task pid=141063)[0m ERROR:2025-04-18 20:55:15,878:Error during comparison
[36m(main_task pid=141063)[0m Traceback (most recent call last):
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=141063)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=141063)[0m     return func(*args, **kwargs)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=141063)[0m     return sympy_expr_eq(
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=141063)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=141063)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=141063)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=141063)[0m     d[None].extend(seq)
[36m(main_task pid=141063)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(WorkerDict pid=145869)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=145869)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=141063)[0m ("Initial validation metrics: {'val/test_score/MATH500': 0.46169354838709675, "
[36m(main_task pid=141063)[0m  "'val/pass_rate/avg': 0.46169354838709675, 'val/pass_rate/median': 0.0, "
[36m(main_task pid=141063)[0m  "'val/pass_rate/bucket_0%': 0.5383064516129032, 'val/pass_rate/bucket_0-20%': "
[36m(main_task pid=141063)[0m  "0.0, 'val/pass_rate/bucket_20-40%': 0.0, 'val/pass_rate/bucket_40-60%': 0.0, "
[36m(main_task pid=141063)[0m  "'val/pass_rate/bucket_60-80%': 0.0, 'val/pass_rate/bucket_80-100%': 0.0, "
[36m(main_task pid=141063)[0m  "'val/pass_rate/bucket_100%': 0.46169354838709675}")
[36m(main_task pid=141063)[0m step:0 - val/test_score/MATH500:0.462 - val/pass_rate/avg:0.462 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.538 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.462
[36m(main_task pid=141063)[0m WARNING:2025-04-18 20:56:06,502:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=141063)[0m WARNING:2025-04-18 20:56:08,063:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{900}'], Pred: ['<|endoftext|>']
[36m(main_task pid=141063)[0m WARNING:2025-04-18 20:56:08,097:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{50}'], Pred: ['<|endoftext|>']
[36m(main_task pid=141063)[0m WARNING:2025-04-18 20:56:08,557:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=141063)[0m WARNING:2025-04-18 20:56:08,639:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=141063)[0m WARNING:2025-04-18 20:56:09,529:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=141063)[0m ERROR:2025-04-18 20:56:10,607:Error during comparison
[36m(main_task pid=141063)[0m Traceback (most recent call last):
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=141063)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=141063)[0m     return func(*args, **kwargs)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=141063)[0m     return sympy_expr_eq(
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=141063)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=141063)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
[36m(main_task pid=141063)[0m     return all(
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
[36m(main_task pid=141063)[0m     for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
[36m(main_task pid=141063)[0m AttributeError: 'Rational' object has no attribute 'items'
[36m(main_task pid=141063)[0m WARNING:2025-04-18 20:56:11,254:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=141063)[0m No gold targets found for at least one gold. Gold: ['\\boxed{}'], Pred: [' To solve this problem, we need to determine the number of prime numbers greater than \\( n! + 1 \\) and less than \\( n! + n \\) for any integer \\( n > 1 \\).\n\n1. **Understanding the range:**\n   The range we are considering is from \\( n! + 1 \\) to \\( n! + n \\). This means we are looking for prime numbers in the interval \\((n! + 1, n! + n)\\).\n\n2. **Analyzing the interval:**\n   - The integer \\( n! \\) (n factorial) is divisible by all integers from 1 to \\( n \\).\n   - Therefore, \\( n! + 1 \\) to \\( n! + n \\) contains the integers 2, 3, 4, ..., \\( n \\).\n\n3. **Checking divisibility:**\n   - Any number in the interval \\((n! + 1, n! + n)\\) is divisible by at least one integer between \\( n! + 1 \\) and \\( n! + n \\).\n   - Hence, none of these numbers can be prime.\n\nThus, there are no prime numbers greater than \\( n! + 1 \\) and less than \\( n! + n \\).\n\nThe final answer is:\n\n\\[\n\\boxed{0}\n\\]\n\nLet\'s verify this reasoning with Python code using sympy for generality.\n\n```python\nimport sympy as sp\n\ndef count_primes_in_interval(n):\n    factorial_n = sp.factorial(n)\n    start_bound = factorial_n + 1\n    end_bound = factorial_n + n\n    prime_count = 0\n    \n    for i in range(start_bound, end_bound):\n        if sp.isprime(i):\n            prime_count += 1\n    \n    return prime_count\n\n# Test for a specific value of n\nn = 5\nprime_count = count_primes_in_interval(n)\nprint(f"The number of prime numbers greater than {n! + 1} and less than {n! + n} is: {prime_count}")\n```<|endoftext|>']
[36m(main_task pid=141063)[0m WARNING:2025-04-18 20:56:11,596:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{255}'], Pred: ['<|endoftext|>']
[36m(main_task pid=141063)[0m WARNING:2025-04-18 20:56:12,326:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=141063)[0m WARNING:2025-04-18 20:56:12,735:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=141682)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=141682)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
Error executing job with overrides: ['data.train_files=./data/math500-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=1024', 'data.max_prompt_length=512', 'data.max_response_length=1024', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=256', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-1.5B', 'critic.ppo_micro_batch_size_per_gpu=32', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=True', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=3', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo_Math1.5B_tok1k_dapo17k', 'trainer.total_epochs=10']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::main_task()[39m (pid=141063, ip=192.168.159.207)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 1056, in fit
    actor_output = self.actor_rollout_wg.update_actor(batch)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
ray.exceptions.RayTaskError(RuntimeError): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=145868, ip=192.168.159.207, actor_id=99a2fe6de4adfcd735b3579201000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7fc8fa1080a0>)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
    metrics = self.actor.update_policy(data=data)
  File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
    loss.backward()
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
    raise RuntimeError(
RuntimeError: grad can be implicitly created only for scalar outputs

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(main_task pid=141063)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=141682, ip=192.168.159.207, actor_id=157f9f1e520b8af1f09347ea01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f7dca5c8130>)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=141063)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=141063)[0m     return func(*args, **kwargs)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
[36m(main_task pid=141063)[0m     metrics = self.actor.update_policy(data=data)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
[36m(main_task pid=141063)[0m     loss.backward()
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
[36m(main_task pid=141063)[0m     torch.autograd.backward(
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
[36m(main_task pid=141063)[0m     grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
[36m(main_task pid=141063)[0m     raise RuntimeError(
[36m(main_task pid=141063)[0m RuntimeError: grad can be implicitly created only for scalar outputs
[36m(main_task pid=141063)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=145870, ip=192.168.159.207, actor_id=c4e005a65e7180bf28016d4d01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7eeddb950130>)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=141063)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=141063)[0m     return func(*args, **kwargs)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
[36m(main_task pid=141063)[0m     metrics = self.actor.update_policy(data=data)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
[36m(main_task pid=141063)[0m     loss.backward()
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
[36m(main_task pid=141063)[0m     torch.autograd.backward(
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
[36m(main_task pid=141063)[0m     grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
[36m(main_task pid=141063)[0m     raise RuntimeError(
[36m(main_task pid=141063)[0m RuntimeError: grad can be implicitly created only for scalar outputs
[36m(main_task pid=141063)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_update_actor()[39m (pid=145869, ip=192.168.159.207, actor_id=8ff63d4c82fe0e08c83d1a8a01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7fc62a478130>)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=141063)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=141063)[0m     return func(*args, **kwargs)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 455, in update_actor
[36m(main_task pid=141063)[0m     metrics = self.actor.update_policy(data=data)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/verl/verl/workers/actor/dp_actor.py", line 318, in update_policy
[36m(main_task pid=141063)[0m     loss.backward()
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
[36m(main_task pid=141063)[0m     torch.autograd.backward(
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 282, in backward
[36m(main_task pid=141063)[0m     grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
[36m(main_task pid=141063)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 151, in _make_grads
[36m(main_task pid=141063)[0m     raise RuntimeError(
[36m(main_task pid=141063)[0m RuntimeError: grad can be implicitly created only for scalar outputs
[36m(WorkerDict pid=145870)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=145870)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 3x across cluster][0m
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 1024
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_Math1.5B_tok1k_dapo17k
2025-04-18 21:15:48,093	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.159.207:6379...
2025-04-18 21:15:48,104	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=167952)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=167952)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=167952)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=167952)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=167952)[0m                                                  'param_offload': False,
[36m(main_task pid=167952)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=167952)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=167952)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=167952)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=167952)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=167952)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=167952)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=167952)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=167952)[0m                                            'total_training_steps': -1,
[36m(main_task pid=167952)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=167952)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=167952)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=167952)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=167952)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=167952)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=167952)[0m                                  'response_length': 1024,
[36m(main_task pid=167952)[0m                                  'shuffle': False,
[36m(main_task pid=167952)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=167952)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=167952)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=167952)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=167952)[0m                                  'use_kl_loss': False,
[36m(main_task pid=167952)[0m                                  'use_torch_compile': True},
[36m(main_task pid=167952)[0m                        'hybrid_engine': True,
[36m(main_task pid=167952)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=167952)[0m                                  'external_lib': None,
[36m(main_task pid=167952)[0m                                  'override_config': {},
[36m(main_task pid=167952)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=167952)[0m                                  'use_remove_padding': True},
[36m(main_task pid=167952)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=167952)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=167952)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=167952)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=167952)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=167952)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=167952)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=167952)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=167952)[0m                                    'disable_log_stats': True,
[36m(main_task pid=167952)[0m                                    'do_sample': True,
[36m(main_task pid=167952)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=167952)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=167952)[0m                                    'enforce_eager': True,
[36m(main_task pid=167952)[0m                                    'free_cache_engine': True,
[36m(main_task pid=167952)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=167952)[0m                                    'ignore_eos': False,
[36m(main_task pid=167952)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=167952)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=167952)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=167952)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=167952)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=167952)[0m                                    'max_model_len': None,
[36m(main_task pid=167952)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=167952)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=167952)[0m                                    'n': 1,
[36m(main_task pid=167952)[0m                                    'name': 'vllm',
[36m(main_task pid=167952)[0m                                    'prompt_length': 512,
[36m(main_task pid=167952)[0m                                    'response_length': 1024,
[36m(main_task pid=167952)[0m                                    'temperature': 1.0,
[36m(main_task pid=167952)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=167952)[0m                                    'top_k': -1,
[36m(main_task pid=167952)[0m                                    'top_p': 1,
[36m(main_task pid=167952)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=167952)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=167952)[0m                                                   'n': 1,
[36m(main_task pid=167952)[0m                                                   'temperature': 0,
[36m(main_task pid=167952)[0m                                                   'top_k': -1,
[36m(main_task pid=167952)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=167952)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=167952)[0m                'gamma': 1.0,
[36m(main_task pid=167952)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=167952)[0m                'kl_penalty': 'kl',
[36m(main_task pid=167952)[0m                'lam': 1.0},
[36m(main_task pid=167952)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=167952)[0m             'estimate_prompts_value': False,
[36m(main_task pid=167952)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=167952)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=167952)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=167952)[0m             'grad_clip': 1.0,
[36m(main_task pid=167952)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=167952)[0m                       'external_lib': None,
[36m(main_task pid=167952)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=167952)[0m                                       'optimizer_offload': False,
[36m(main_task pid=167952)[0m                                       'param_offload': False,
[36m(main_task pid=167952)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=167952)[0m                       'override_config': {},
[36m(main_task pid=167952)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=167952)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=167952)[0m                       'use_remove_padding': False},
[36m(main_task pid=167952)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=167952)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=167952)[0m                       'min_lr_ratio': None,
[36m(main_task pid=167952)[0m                       'total_training_steps': -1,
[36m(main_task pid=167952)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=167952)[0m             'ppo_epochs': 1,
[36m(main_task pid=167952)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=167952)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=167952)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=167952)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=167952)[0m             'shuffle': False,
[36m(main_task pid=167952)[0m             'strategy': 'fsdp',
[36m(main_task pid=167952)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=167952)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=167952)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=167952)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=167952)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=167952)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=167952)[0m                 'warmup_steps': 15},
[36m(main_task pid=167952)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=167952)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=167952)[0m           'image_key': 'images',
[36m(main_task pid=167952)[0m           'max_prompt_length': 512,
[36m(main_task pid=167952)[0m           'max_response_length': 1024,
[36m(main_task pid=167952)[0m           'prompt_key': 'prompt',
[36m(main_task pid=167952)[0m           'return_raw_chat': False,
[36m(main_task pid=167952)[0m           'return_raw_input_ids': False,
[36m(main_task pid=167952)[0m           'shuffle': True,
[36m(main_task pid=167952)[0m           'tokenizer': None,
[36m(main_task pid=167952)[0m           'train_batch_size': 1024,
[36m(main_task pid=167952)[0m           'train_files': './data/math500-base/train.parquet',
[36m(main_task pid=167952)[0m           'truncation': 'error',
[36m(main_task pid=167952)[0m           'use_chat_template': False,
[36m(main_task pid=167952)[0m           'val_batch_size': None,
[36m(main_task pid=167952)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=167952)[0m  'reward_model': {'enable': False,
[36m(main_task pid=167952)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=167952)[0m                   'max_length': None,
[36m(main_task pid=167952)[0m                   'micro_batch_size': None,
[36m(main_task pid=167952)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=167952)[0m                   'model': {'external_lib': None,
[36m(main_task pid=167952)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=167952)[0m                                             'param_offload': False,
[36m(main_task pid=167952)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=167952)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=167952)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=167952)[0m                             'use_remove_padding': False},
[36m(main_task pid=167952)[0m                   'reward_manager': 'naive',
[36m(main_task pid=167952)[0m                   'strategy': 'fsdp',
[36m(main_task pid=167952)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=167952)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=167952)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=167952)[0m              'critic_warmup': 0,
[36m(main_task pid=167952)[0m              'default_hdfs_dir': None,
[36m(main_task pid=167952)[0m              'default_local_dir': 'checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=167952)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=167952)[0m              'experiment_name': 'ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=167952)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=167952)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=167952)[0m              'nnodes': 1,
[36m(main_task pid=167952)[0m              'project_name': 'grpo',
[36m(main_task pid=167952)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=167952)[0m              'resume_from_path': False,
[36m(main_task pid=167952)[0m              'resume_mode': 'auto',
[36m(main_task pid=167952)[0m              'save_freq': -1,
[36m(main_task pid=167952)[0m              'test_freq': 3,
[36m(main_task pid=167952)[0m              'total_epochs': 10,
[36m(main_task pid=167952)[0m              'total_training_steps': None,
[36m(main_task pid=167952)[0m              'val_before_train': True,
[36m(main_task pid=167952)[0m              'val_generations_to_log_to_wandb': 0}}
[36m(main_task pid=167952)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=167952)[0m No module named 'vllm._version'
[36m(main_task pid=167952)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=167952)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=167952)[0m dataset len: 12000
[36m(main_task pid=167952)[0m Example prompt before filtering: How many vertical asymptotes does the graph of $y=\frac{2}{x^2+x-6}$ have? Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=167952)[0m filter dataset len: 11910
[36m(main_task pid=167952)[0m dataset len: 500
[36m(main_task pid=167952)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=167952)[0m filter dataset len: 497
[36m(main_task pid=167952)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=167952)[0m Size of train dataloader: 11
[36m(main_task pid=167952)[0m Size of val dataloader: 1
[36m(main_task pid=167952)[0m Total training steps: 110
[36m(main_task pid=167952)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=168374)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=168374)[0m No module named 'vllm._version'
[36m(pid=168374)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=168582)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=168582)[0m No module named 'vllm._version'
[36m(pid=168582)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=168582)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=168582)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=168583)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=168583)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=168374)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(pid=168583)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=168583)[0m No module named 'vllm._version'[32m [repeated 2x across cluster][0m
[36m(pid=168583)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=168374)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=168374)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=168374)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=168374)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.7265625
[36m(WorkerDict pid=168374)[0m Total steps: 110, num_warmup_steps: 0
[36m(WorkerDict pid=168374)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=168374)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=168374)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=168374)[0m   "architectures": [
[36m(WorkerDict pid=168374)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=168374)[0m   ],
[36m(WorkerDict pid=168374)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=168374)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=168374)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=168374)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=168374)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=168374)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=168374)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=168374)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=168374)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=168374)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=168374)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=168374)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=168374)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=168374)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=168374)[0m   "rope_scaling": null,
[36m(WorkerDict pid=168374)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=168374)[0m   "sliding_window": null,
[36m(WorkerDict pid=168374)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=168374)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=168374)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=168374)[0m   "use_cache": true,
[36m(WorkerDict pid=168374)[0m   "use_mrope": false,
[36m(WorkerDict pid=168374)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=168374)[0m   "vocab_size": 151936
[36m(WorkerDict pid=168374)[0m }
[36m(WorkerDict pid=168374)[0m 
[36m(WorkerDict pid=168374)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=168374)[0m wrap_policy: functools.partial(<function _or_policy at 0x7edb5c203be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7edb5c203ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=168374)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=168583)[0m Total steps: 110, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=168583)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=168581)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=168374)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=168374)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=168374)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=168374)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=168374)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=168374)[0m   "architectures": [
[36m(WorkerDict pid=168374)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=168374)[0m   ],
[36m(WorkerDict pid=168374)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=168374)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=168374)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=168374)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=168374)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=168374)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=168374)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=168374)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=168374)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=168374)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=168374)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=168374)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=168374)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=168374)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=168374)[0m   "rope_scaling": null,
[36m(WorkerDict pid=168374)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=168374)[0m   "sliding_window": null,
[36m(WorkerDict pid=168374)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=168374)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=168374)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=168374)[0m   "use_cache": true,
[36m(WorkerDict pid=168374)[0m   "use_mrope": false,
[36m(WorkerDict pid=168374)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=168374)[0m   "vocab_size": 151936
[36m(WorkerDict pid=168374)[0m }
[36m(WorkerDict pid=168374)[0m 
[36m(WorkerDict pid=168374)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=168374)[0m wrap_policy: functools.partial(<function _or_policy at 0x7edb5c203be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7edb5c203ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=168583)[0m Actor use_remove_padding=True[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=168583)[0m Total steps: 110, num_warmup_steps: 0
[36m(WorkerDict pid=168374)[0m Before building vllm rollout, memory allocated (GB): 2.8754353523254395, memory reserved (GB): 6.46875
[36m(WorkerDict pid=168374)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=168374)[0m WARNING 04-18 21:16:35 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=168583)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f4c0807fbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f4c0807fac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=168581)[0m Actor use_remove_padding=True[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=168374)[0m local rank 0
[36m(WorkerDict pid=168581)[0m Total steps: 110, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=168583)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=168582)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=168374)[0m before init cache memory allocated: 6.220024832GB, reserved: 6.3963136GB
[36m(WorkerDict pid=168374)[0m after init cache memory allocated: 58.967329792GB, reserved: 59.185823744GB
[36m(WorkerDict pid=168583)[0m WARNING 04-18 21:16:36 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=168583)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=168374)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=168374)[0m After building vllm rollout, memory allocated (GB): 52.039379596710205, memory reserved (GB): 55.12109375
[36m(WorkerDict pid=168374)[0m After building sharding manager, memory allocated (GB): 52.039379596710205, memory reserved (GB): 55.12109375
[36m(WorkerDict pid=168583)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=168374)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=168374)[0m   warnings.warn(
[36m(WorkerDict pid=168583)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(main_task pid=167952)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=167952)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=167952)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=167952)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_211644-s008n33q
[36m(main_task pid=167952)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=167952)[0m wandb: Syncing run ppo_Math1.5B_tok1k_dapo17k
[36m(main_task pid=167952)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=167952)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/s008n33q
[36m(main_task pid=167952)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=167952)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k/latest_checkpointed_iteration.txt
[36m(main_task pid=167952)[0m Training from scratch
[36m(main_task pid=167952)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=167952)[0m validation generation end
[36m(WorkerDict pid=168581)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=167952)[0m Not computing the values of prompts.
[36m(main_task pid=167952)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=167952)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=167952)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=167952)[0m    \[
[36m(main_task pid=167952)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=167952)[0m    \]
[36m(main_task pid=167952)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=167952)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=167952)[0m    \[
[36m(main_task pid=167952)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=167952)[0m    \]
[36m(main_task pid=167952)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m Let's implement this in Python to get the exact values for \(r\) and \(\theta\).
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m ```python
[36m(main_task pid=167952)[0m import sympy as sp
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m # Define the rectangular coordinates
[36m(main_task pid=167952)[0m x = 0
[36m(main_task pid=167952)[0m y = 3
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m # Calculate the radius r
[36m(main_task pid=167952)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m # Calculate the angle theta
[36m(main_task pid=167952)[0m theta = sp.atan2(y, x)
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=167952)[0m if theta < 0:
[36m(main_task pid=167952)[0m     theta += 2 * sp.pi
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m # Print the result
[36m(main_task pid=167952)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=167952)[0m ```
[36m(main_task pid=167952)[0m ```output
[36m(main_task pid=167952)[0m r = 3, theta = pi/2
[36m(main_task pid=167952)[0m ```
[36m(main_task pid=167952)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=167952)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=167952)[0m [score] 1.0
[36m(main_task pid=167952)[0m ERROR:2025-04-18 21:17:17,547:Error during comparison
[36m(main_task pid=167952)[0m Traceback (most recent call last):
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=167952)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=167952)[0m     return func(*args, **kwargs)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=167952)[0m     return sympy_expr_eq(
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=167952)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=167952)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=167952)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=167952)[0m     d[None].extend(seq)
[36m(main_task pid=167952)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(WorkerDict pid=168581)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=168581)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=167952)[0m ("Initial validation metrics: {'val/test_score/MATH500': 0.46169354838709675, "
[36m(main_task pid=167952)[0m  "'val/pass_rate/avg': 0.46169354838709675, 'val/pass_rate/median': 0.0, "
[36m(main_task pid=167952)[0m  "'val/pass_rate/bucket_0%': 0.5383064516129032, 'val/pass_rate/bucket_0-20%': "
[36m(main_task pid=167952)[0m  "0.0, 'val/pass_rate/bucket_20-40%': 0.0, 'val/pass_rate/bucket_40-60%': 0.0, "
[36m(main_task pid=167952)[0m  "'val/pass_rate/bucket_60-80%': 0.0, 'val/pass_rate/bucket_80-100%': 0.0, "
[36m(main_task pid=167952)[0m  "'val/pass_rate/bucket_100%': 0.46169354838709675}")
[36m(main_task pid=167952)[0m step:0 - val/test_score/MATH500:0.462 - val/pass_rate/avg:0.462 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.538 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.462
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:18:16,272:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:18:17,831:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{900}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:18:17,865:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{50}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:18:18,321:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:18:18,404:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:18:19,283:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m ERROR:2025-04-18 21:18:20,379:Error during comparison
[36m(main_task pid=167952)[0m Traceback (most recent call last):
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=167952)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=167952)[0m     return func(*args, **kwargs)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=167952)[0m     return sympy_expr_eq(
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=167952)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=167952)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
[36m(main_task pid=167952)[0m     return all(
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
[36m(main_task pid=167952)[0m     for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
[36m(main_task pid=167952)[0m AttributeError: 'Rational' object has no attribute 'items'
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:18:21,020:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m No gold targets found for at least one gold. Gold: ['\\boxed{}'], Pred: [' To solve this problem, we need to determine the number of prime numbers greater than \\( n! + 1 \\) and less than \\( n! + n \\) for any integer \\( n > 1 \\).\n\n1. **Understanding the range:**\n   The range we are considering is from \\( n! + 1 \\) to \\( n! + n \\). This means we are looking for prime numbers in the interval \\((n! + 1, n! + n)\\).\n\n2. **Analyzing the interval:**\n   - The integer \\( n! \\) (n factorial) is divisible by all integers from 1 to \\( n \\).\n   - Therefore, \\( n! + 1 \\) to \\( n! + n \\) contains the integers 2, 3, 4, ..., \\( n \\).\n\n3. **Checking divisibility:**\n   - Any number in the interval \\((n! + 1, n! + n)\\) is divisible by at least one integer between \\( n! + 1 \\) and \\( n! + n \\).\n   - Hence, none of these numbers can be prime.\n\nThus, there are no prime numbers greater than \\( n! + 1 \\) and less than \\( n! + n \\).\n\nThe final answer is:\n\n\\[\n\\boxed{0}\n\\]\n\nLet\'s verify this reasoning with Python code using sympy for generality.\n\n```python\nimport sympy as sp\n\ndef count_primes_in_interval(n):\n    factorial_n = sp.factorial(n)\n    start_bound = factorial_n + 1\n    end_bound = factorial_n + n\n    prime_count = 0\n    \n    for i in range(start_bound, end_bound):\n        if sp.isprime(i):\n            prime_count += 1\n    \n    return prime_count\n\n# Test for a specific value of n\nn = 5\nprime_count = count_primes_in_interval(n)\nprint(f"The number of prime numbers greater than {n! + 1} and less than {n! + n} is: {prime_count}")\n```<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:18:21,364:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{255}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:18:22,083:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:18:22,493:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=168374)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=168374)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
[36m(WorkerDict pid=168374)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=168374)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 4x across cluster][0m
[36m(main_task pid=167952)[0m step:1 - global_seqlen/min:161879.000 - global_seqlen/max:166879.000 - global_seqlen/minmax_diff:5000.000 - global_seqlen/balanced_min:164408.000 - global_seqlen/balanced_max:164409.000 - global_seqlen/mean:164408.750 - critic/kl:-0.000 - critic/kl_coeff:0.001 - critic/vf_loss:7.903 - critic/vf_clipfrac:0.000 - critic/vpred_mean:-2.936 - critic/grad_norm:444.655 - perf/mfu/critic:0.230 - critic/lr:0.000 - actor/entropy_loss:0.540 - actor/pg_loss:-0.013 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:6.939 - perf/mfu/actor:0.341 - perf/max_memory_allocated_gb:56.602 - perf/max_memory_reserved_gb:74.592 - perf/cpu_memory_used_gb:65.312 - actor/lr:0.000 - critic/score/mean:0.287 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.287 - critic/rewards/max:1.002 - critic/rewards/min:-0.003 - critic/advantages/mean:0.000 - critic/advantages/max:4.569 - critic/advantages/min:-5.211 - critic/returns/mean:0.226 - critic/returns/max:1.002 - critic/returns/min:-0.003 - critic/values/mean:-2.953 - critic/values/max:9.375 - critic/values/min:-14.188 - critic/vf_explained_var:-32.143 - response_length/mean:559.492 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.159 - prompt_length/mean:82.729 - prompt_length/max:460.000 - prompt_length/min:22.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:37.500 - timing_s/old_log_prob:5.358 - timing_s/ref:5.114 - timing_s/values:6.879 - timing_s/adv:7.910 - timing_s/update_critic:25.411 - timing_s/update_actor:17.154 - timing_s/step:105.351 - timing_per_token_ms/update_critic:0.039 - timing_per_token_ms/update_actor:0.026 - timing_per_token_ms/adv:0.012 - timing_per_token_ms/ref:0.008 - timing_per_token_ms/values:0.010 - timing_per_token_ms/gen:0.065 - perf/total_num_tokens:657635.000 - perf/time_per_step:105.351 - perf/throughput:1560.583
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:20:04,210:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\dfrac{15}{56}}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=168582)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=168582)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 3x across cluster][0m
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:20:04,506:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:20:04,520:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{46}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:20:04,964:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{47}{72}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:20:05,011:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m No gold targets found for at least one gold. Gold: ['\\boxed{}'], Pred: [" Here's the python code to solve the problem:\n\n```python\nimport sympy as sp\n\n# The product of all primes less than or equal to 61 is the number P in the problem\nP = sp.prod(sp.primerange(1, 62))\n\n# We are given 58 terms in the sequence each of the form P + n where n varies from 2 to 59\n# We need to check if any of these terms are prime\nN = 0\n\n# We will check each term in the sequence\nfor n in range(2, 60):\n    if sp.isprime(P + n):\n        N += 1\n\n# The number of primes appearing in this sequence\nprint(N)\n```\n```output\n17\n```\nThe number of primes appearing in the sequence is \\(\\boxed{17}\\).<|endoftext|>"]
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:20:06,013:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{676}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:20:06,230:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{1}{5}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m ERROR:2025-04-18 21:20:06,792:Error during comparison
[36m(main_task pid=167952)[0m Traceback (most recent call last):
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=167952)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=167952)[0m     return func(*args, **kwargs)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=167952)[0m     return sympy_expr_eq(
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=167952)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=167952)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
[36m(main_task pid=167952)[0m     return all(
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
[36m(main_task pid=167952)[0m     for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
[36m(main_task pid=167952)[0m AttributeError: 'NegativeOne' object has no attribute 'items'
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:20:06,868:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2 \\text{ pieces}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:20:08,593:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [" \n{: id='msg_125_0', colid='0', name='Cancel favori' title='Cho' style='color:#f59003;', href=' >> ', rel='nofollow';}\n{: id='msg_5445_0', colid='0', name='Cancel favori' title='Ch' style='color:#838485;', href=' >> ', rel='nofollow';}<|endoftext|>"]
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:20:08,886:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:20:09,018:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:20:09,371:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{3}{5}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:20:09,634:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3542}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m step:2 - global_seqlen/min:160011.000 - global_seqlen/max:164782.000 - global_seqlen/minmax_diff:4771.000 - global_seqlen/balanced_min:162926.000 - global_seqlen/balanced_max:162927.000 - global_seqlen/mean:162926.750 - critic/kl:-0.000 - critic/kl_coeff:0.001 - critic/vf_loss:6.963 - critic/vf_clipfrac:0.593 - critic/vpred_mean:-1.568 - critic/grad_norm:134.812 - perf/mfu/critic:0.227 - critic/lr:0.000 - actor/entropy_loss:0.522 - actor/pg_loss:0.142 - actor/pg_clipfrac:0.008 - actor/ppo_kl:-0.000 - actor/grad_norm:6.853 - perf/mfu/actor:0.362 - perf/max_memory_allocated_gb:61.663 - perf/max_memory_reserved_gb:74.592 - perf/cpu_memory_used_gb:65.978 - actor/lr:0.000 - critic/score/mean:0.319 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.319 - critic/rewards/max:1.002 - critic/rewards/min:-0.002 - critic/advantages/mean:-0.000 - critic/advantages/max:5.092 - critic/advantages/min:-4.629 - critic/returns/mean:0.255 - critic/returns/max:1.002 - critic/returns/min:-0.003 - critic/values/mean:-2.938 - critic/values/max:8.000 - critic/values/min:-14.375 - critic/vf_explained_var:-29.130 - response_length/mean:553.714 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.148 - prompt_length/mean:82.719 - prompt_length/max:429.000 - prompt_length/min:25.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:42.406 - timing_s/old_log_prob:4.039 - timing_s/ref:4.002 - timing_s/values:6.936 - timing_s/adv:6.816 - timing_s/update_critic:25.465 - timing_s/update_actor:16.041 - timing_s/step:105.729 - timing_per_token_ms/update_critic:0.039 - timing_per_token_ms/update_actor:0.025 - timing_per_token_ms/adv:0.010 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/values:0.011 - timing_per_token_ms/gen:0.075 - perf/total_num_tokens:651707.000 - perf/time_per_step:105.729 - perf/throughput:1540.981
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:21:39,246:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{294}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:21:39,579:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:21:39,752:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{60^\\circ}'], Pred: [' Let definelet oquestion: Asin trophy rubular\n\nAnswer with reason: The is\ncodeume: Diagnosisbendas solution  # python to as in\nIt uis outperforms the author  # python to as<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:21:40,064:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:21:40,439:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1202_3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:21:40,918:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: [' - Linda failed her math test.\n- Linda has no success in her life.<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:21:41,000:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:21:42,516:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m ERROR:2025-04-18 21:21:42,987:Error during comparison
[36m(main_task pid=167952)[0m Traceback (most recent call last):
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=167952)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=167952)[0m     return func(*args, **kwargs)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=167952)[0m     return sympy_expr_eq(
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=167952)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=167952)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
[36m(main_task pid=167952)[0m     return all(
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
[36m(main_task pid=167952)[0m     for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
[36m(main_task pid=167952)[0m AttributeError: 'Rational' object has no attribute 'items'
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:21:44,196:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{129}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:21:44,505:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{70^\\circ}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:21:44,921:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{1}{4}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=167952)[0m validation generation end
[36m(main_task pid=167952)[0m Not computing the values of prompts.
[36m(main_task pid=167952)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=167952)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=167952)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=167952)[0m    \[
[36m(main_task pid=167952)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=167952)[0m    \]
[36m(main_task pid=167952)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=167952)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=167952)[0m    \[
[36m(main_task pid=167952)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=167952)[0m    \]
[36m(main_task pid=167952)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m Let's implement this in Python to get the exact values.
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m ```python
[36m(main_task pid=167952)[0m import sympy as sp
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m # Define the rectangular coordinates
[36m(main_task pid=167952)[0m x = 0
[36m(main_task pid=167952)[0m y = 3
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m # Calculate the radius r
[36m(main_task pid=167952)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m # Calculate the angle theta
[36m(main_task pid=167952)[0m theta = sp.atan2(y, x)
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=167952)[0m if theta < 0:
[36m(main_task pid=167952)[0m     theta += 2 * sp.pi
[36m(main_task pid=167952)[0m 
[36m(main_task pid=167952)[0m # Print the result
[36m(main_task pid=167952)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=167952)[0m ```
[36m(main_task pid=167952)[0m ```output
[36m(main_task pid=167952)[0m r = 3, theta = pi/2
[36m(main_task pid=167952)[0m ```
[36m(main_task pid=167952)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=167952)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=167952)[0m [score] 1.0
[36m(main_task pid=167952)[0m ERROR:2025-04-18 21:22:52,344:Error during comparison
[36m(main_task pid=167952)[0m Traceback (most recent call last):
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=167952)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=167952)[0m     return func(*args, **kwargs)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=167952)[0m     return sympy_expr_eq(
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=167952)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=167952)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=167952)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=167952)[0m     d[None].extend(seq)
[36m(main_task pid=167952)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(main_task pid=167952)[0m step:3 - global_seqlen/min:160757.000 - global_seqlen/max:164293.000 - global_seqlen/minmax_diff:3536.000 - global_seqlen/balanced_min:162328.000 - global_seqlen/balanced_max:162329.000 - global_seqlen/mean:162328.500 - critic/kl:-0.001 - critic/kl_coeff:0.001 - critic/vf_loss:1.352 - critic/vf_clipfrac:0.268 - critic/vpred_mean:-0.024 - critic/grad_norm:47.397 - perf/mfu/critic:0.227 - critic/lr:0.000 - actor/entropy_loss:0.547 - actor/pg_loss:-0.621 - actor/pg_clipfrac:0.009 - actor/ppo_kl:-0.001 - actor/grad_norm:9.706 - perf/mfu/actor:0.381 - perf/max_memory_allocated_gb:61.663 - perf/max_memory_reserved_gb:74.592 - perf/cpu_memory_used_gb:65.987 - actor/lr:0.000 - val/test_score/MATH500:0.484 - val/pass_rate/avg:0.484 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.516 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.484 - critic/score/mean:0.326 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.326 - critic/rewards/max:1.002 - critic/rewards/min:-0.003 - critic/advantages/mean:-0.000 - critic/advantages/max:6.679 - critic/advantages/min:-5.450 - critic/returns/mean:0.257 - critic/returns/max:1.005 - critic/returns/min:-0.004 - critic/values/mean:-0.326 - critic/values/max:8.625 - critic/values/min:-10.562 - critic/vf_explained_var:-13.148 - response_length/mean:552.963 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.154 - prompt_length/mean:81.133 - prompt_length/max:460.000 - prompt_length/min:23.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:31.787 - timing_s/old_log_prob:3.925 - timing_s/ref:3.914 - timing_s/values:6.898 - timing_s/adv:6.427 - timing_s/update_critic:25.450 - timing_s/update_actor:15.170 - timing_s/testing:28.322 - timing_s/step:121.914 - timing_per_token_ms/update_critic:0.039 - timing_per_token_ms/update_actor:0.023 - timing_per_token_ms/adv:0.010 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/values:0.011 - timing_per_token_ms/gen:0.056 - perf/total_num_tokens:649314.000 - perf/time_per_step:121.914 - perf/throughput:1331.496
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:40,498:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:41,478:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10\\%}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:41,537:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{38}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:41,744:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{116}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:42,209:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{A}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:42,790:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{4\\sqrt{3}}{7}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:43,035:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m ERROR:2025-04-18 21:23:43,615:Error during comparison
[36m(main_task pid=167952)[0m Traceback (most recent call last):
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=167952)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=167952)[0m     return func(*args, **kwargs)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=167952)[0m     return sympy_expr_eq(
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=167952)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=167952)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=167952)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 284, in sympy_solve_and_compare
[36m(main_task pid=167952)[0m     for g, p in zip(sorted(solved_gold), sorted(solved_pred))
[36m(main_task pid=167952)[0m TypeError: '<' not supported between instances of 'dict' and 'dict'
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:44,004:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{181}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:44,151:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:45,517:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{\\sqrt{65}}{2}}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:46,640:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-5}'], Pred: [' The objective is to find . We have the functions and . \n\nSubstitute into: Then, using the distributive property (also called FOILs for binomials) on the inside: So, combining terms, the function is: Given a problem asking to use two provided linear functions, we should start by subsituting the second function into the first function. We then perform the factoring to solve for the desired function.<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:47,111:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{160}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:47,297:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=167952)[0m WARNING:2025-04-18 21:23:47,341:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{\\frac{3}{4}}'], Pred: ['<|endoftext|>']
*** SIGTERM received at time=1745036653 on cpu 135 ***
PC: @     0x7f9e7b385117  (unknown)  (unknown)
    @     0x7f9e7b336520  (unknown)  (unknown)
    @ ... and at least 1 more frames
[2025-04-18 21:24:13,857 E 167797 167797] logging.cc:484: *** SIGTERM received at time=1745036653 on cpu 135 ***
[2025-04-18 21:24:13,857 E 167797 167797] logging.cc:484: PC: @     0x7f9e7b385117  (unknown)  (unknown)
[2025-04-18 21:24:13,857 E 167797 167797] logging.cc:484:     @     0x7f9e7b336520  (unknown)  (unknown)
[2025-04-18 21:24:13,857 E 167797 167797] logging.cc:484:     @ ... and at least 1 more frames
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 1024
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_Math1.5B_tok1k_dapo17k
2025-04-18 21:25:59,918	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.159.207:6379...
2025-04-18 21:25:59,929	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=173992)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=173992)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=173992)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=173992)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=173992)[0m                                                  'param_offload': False,
[36m(main_task pid=173992)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=173992)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=173992)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=173992)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=173992)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=173992)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=173992)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=173992)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=173992)[0m                                            'total_training_steps': -1,
[36m(main_task pid=173992)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=173992)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=173992)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=173992)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=173992)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=173992)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=173992)[0m                                  'response_length': 1024,
[36m(main_task pid=173992)[0m                                  'shuffle': False,
[36m(main_task pid=173992)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=173992)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=173992)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=173992)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=173992)[0m                                  'use_kl_loss': False,
[36m(main_task pid=173992)[0m                                  'use_torch_compile': True},
[36m(main_task pid=173992)[0m                        'hybrid_engine': True,
[36m(main_task pid=173992)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=173992)[0m                                  'external_lib': None,
[36m(main_task pid=173992)[0m                                  'override_config': {},
[36m(main_task pid=173992)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=173992)[0m                                  'use_remove_padding': True},
[36m(main_task pid=173992)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=173992)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=173992)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=173992)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=173992)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=173992)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=173992)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=173992)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=173992)[0m                                    'disable_log_stats': True,
[36m(main_task pid=173992)[0m                                    'do_sample': True,
[36m(main_task pid=173992)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=173992)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=173992)[0m                                    'enforce_eager': True,
[36m(main_task pid=173992)[0m                                    'free_cache_engine': True,
[36m(main_task pid=173992)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=173992)[0m                                    'ignore_eos': False,
[36m(main_task pid=173992)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=173992)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=173992)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=173992)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=173992)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=173992)[0m                                    'max_model_len': None,
[36m(main_task pid=173992)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=173992)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=173992)[0m                                    'n': 1,
[36m(main_task pid=173992)[0m                                    'name': 'vllm',
[36m(main_task pid=173992)[0m                                    'prompt_length': 512,
[36m(main_task pid=173992)[0m                                    'response_length': 1024,
[36m(main_task pid=173992)[0m                                    'temperature': 1.0,
[36m(main_task pid=173992)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=173992)[0m                                    'top_k': -1,
[36m(main_task pid=173992)[0m                                    'top_p': 1,
[36m(main_task pid=173992)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=173992)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=173992)[0m                                                   'n': 1,
[36m(main_task pid=173992)[0m                                                   'temperature': 0,
[36m(main_task pid=173992)[0m                                                   'top_k': -1,
[36m(main_task pid=173992)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=173992)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=173992)[0m                'gamma': 1.0,
[36m(main_task pid=173992)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=173992)[0m                'kl_penalty': 'kl',
[36m(main_task pid=173992)[0m                'lam': 1.0},
[36m(main_task pid=173992)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=173992)[0m             'estimate_prompts_value': False,
[36m(main_task pid=173992)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=173992)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=173992)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=173992)[0m             'grad_clip': 1.0,
[36m(main_task pid=173992)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=173992)[0m                       'external_lib': None,
[36m(main_task pid=173992)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=173992)[0m                                       'optimizer_offload': False,
[36m(main_task pid=173992)[0m                                       'param_offload': False,
[36m(main_task pid=173992)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=173992)[0m                       'override_config': {},
[36m(main_task pid=173992)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=173992)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=173992)[0m                       'use_remove_padding': False},
[36m(main_task pid=173992)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=173992)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=173992)[0m                       'min_lr_ratio': None,
[36m(main_task pid=173992)[0m                       'total_training_steps': -1,
[36m(main_task pid=173992)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=173992)[0m             'ppo_epochs': 1,
[36m(main_task pid=173992)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=173992)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=173992)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=173992)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=173992)[0m             'shuffle': False,
[36m(main_task pid=173992)[0m             'strategy': 'fsdp',
[36m(main_task pid=173992)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=173992)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=173992)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=173992)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=173992)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=173992)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=173992)[0m                 'warmup_steps': 15},
[36m(main_task pid=173992)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=173992)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=173992)[0m           'image_key': 'images',
[36m(main_task pid=173992)[0m           'max_prompt_length': 512,
[36m(main_task pid=173992)[0m           'max_response_length': 1024,
[36m(main_task pid=173992)[0m           'prompt_key': 'prompt',
[36m(main_task pid=173992)[0m           'return_raw_chat': False,
[36m(main_task pid=173992)[0m           'return_raw_input_ids': False,
[36m(main_task pid=173992)[0m           'shuffle': True,
[36m(main_task pid=173992)[0m           'tokenizer': None,
[36m(main_task pid=173992)[0m           'train_batch_size': 1024,
[36m(main_task pid=173992)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=173992)[0m           'truncation': 'error',
[36m(main_task pid=173992)[0m           'use_chat_template': False,
[36m(main_task pid=173992)[0m           'val_batch_size': None,
[36m(main_task pid=173992)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=173992)[0m  'reward_model': {'enable': False,
[36m(main_task pid=173992)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=173992)[0m                   'max_length': None,
[36m(main_task pid=173992)[0m                   'micro_batch_size': None,
[36m(main_task pid=173992)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=173992)[0m                   'model': {'external_lib': None,
[36m(main_task pid=173992)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=173992)[0m                                             'param_offload': False,
[36m(main_task pid=173992)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=173992)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=173992)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=173992)[0m                             'use_remove_padding': False},
[36m(main_task pid=173992)[0m                   'reward_manager': 'naive',
[36m(main_task pid=173992)[0m                   'strategy': 'fsdp',
[36m(main_task pid=173992)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=173992)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=173992)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=173992)[0m              'critic_warmup': 0,
[36m(main_task pid=173992)[0m              'default_hdfs_dir': None,
[36m(main_task pid=173992)[0m              'default_local_dir': 'checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=173992)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=173992)[0m              'experiment_name': 'ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=173992)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=173992)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=173992)[0m              'nnodes': 1,
[36m(main_task pid=173992)[0m              'project_name': 'grpo',
[36m(main_task pid=173992)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=173992)[0m              'resume_from_path': False,
[36m(main_task pid=173992)[0m              'resume_mode': 'auto',
[36m(main_task pid=173992)[0m              'save_freq': -1,
[36m(main_task pid=173992)[0m              'test_freq': 3,
[36m(main_task pid=173992)[0m              'total_epochs': 10,
[36m(main_task pid=173992)[0m              'total_training_steps': None,
[36m(main_task pid=173992)[0m              'val_before_train': True,
[36m(main_task pid=173992)[0m              'val_generations_to_log_to_wandb': 0}}
[36m(main_task pid=173992)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=173992)[0m No module named 'vllm._version'
[36m(main_task pid=173992)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=173992)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=173992)[0m dataset len: 1791700
[36m(main_task pid=173992)[0m Example prompt before filtering: The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$. Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=173992)[0m filter dataset len: 1786200
[36m(main_task pid=173992)[0m dataset len: 500
[36m(main_task pid=173992)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=173992)[0m filter dataset len: 497
[36m(main_task pid=173992)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=173992)[0m Size of train dataloader: 1744
[36m(main_task pid=173992)[0m Size of val dataloader: 1
[36m(main_task pid=173992)[0m Total training steps: 17440
[36m(main_task pid=173992)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=175829)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=175829)[0m No module named 'vllm._version'
[36m(pid=175829)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=176029)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=176029)[0m No module named 'vllm._version'
[36m(pid=176029)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=176030)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=176030)[0m No module named 'vllm._version'
[36m(pid=176030)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=175829)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=175829)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=175829)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=175829)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=175829)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=175829)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=175829)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=175829)[0m NCCL version 2.20.5+cuda12.4
[36m(pid=176031)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=176031)[0m No module named 'vllm._version'
[36m(pid=176031)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=176031)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=176031)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=176030)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=176030)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=175829)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.63671875
[36m(WorkerDict pid=175829)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=175829)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=175829)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=175829)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=175829)[0m   "architectures": [
[36m(WorkerDict pid=175829)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=175829)[0m   ],
[36m(WorkerDict pid=175829)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=175829)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=175829)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=175829)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=175829)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=175829)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=175829)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=175829)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=175829)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=175829)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=175829)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=175829)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=175829)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=175829)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=175829)[0m   "rope_scaling": null,
[36m(WorkerDict pid=175829)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=175829)[0m   "sliding_window": null,
[36m(WorkerDict pid=175829)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=175829)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=175829)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=175829)[0m   "use_cache": true,
[36m(WorkerDict pid=175829)[0m   "use_mrope": false,
[36m(WorkerDict pid=175829)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=175829)[0m   "vocab_size": 151936
[36m(WorkerDict pid=175829)[0m }
[36m(WorkerDict pid=175829)[0m 
[36m(WorkerDict pid=175829)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=175829)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f6fb49dfbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f6fb49dfac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=176031)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=176031)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=175829)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=176031)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=176031)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=176031)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=175829)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=175829)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=175829)[0m   "architectures": [
[36m(WorkerDict pid=175829)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=175829)[0m   ],
[36m(WorkerDict pid=175829)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=175829)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=175829)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=175829)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=175829)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=175829)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=175829)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=175829)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=175829)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=175829)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=175829)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=175829)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=175829)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=175829)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=175829)[0m   "rope_scaling": null,
[36m(WorkerDict pid=175829)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=175829)[0m   "sliding_window": null,
[36m(WorkerDict pid=175829)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=175829)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=175829)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=175829)[0m   "use_cache": true,
[36m(WorkerDict pid=175829)[0m   "use_mrope": false,
[36m(WorkerDict pid=175829)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=175829)[0m   "vocab_size": 151936
[36m(WorkerDict pid=175829)[0m }
[36m(WorkerDict pid=175829)[0m 
[36m(WorkerDict pid=175829)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=175829)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=175829)[0m Before building vllm rollout, memory allocated (GB): 2.8754353523254395, memory reserved (GB): 6.37890625
[36m(WorkerDict pid=175829)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=176031)[0m wrap_policy: functools.partial(<function _or_policy at 0x7faa308e7be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7faa308e7ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=175829)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=175829)[0m Actor use_remove_padding=True[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=176029)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=176031)[0m WARNING 04-18 21:34:24 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=176031)[0m local rank 0
[36m(WorkerDict pid=176031)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=176031)[0m Actor use_remove_padding=True[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=176031)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=176031)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=175829)[0m before init cache memory allocated: 6.220035072GB, reserved: 6.381633536GB
[36m(WorkerDict pid=175829)[0m after init cache memory allocated: 58.977432576GB, reserved: 59.17114368GB
[36m(WorkerDict pid=175829)[0m WARNING 04-18 21:34:27 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=175829)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=176030)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=176031)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=176031)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=176031)[0m   warnings.warn(
[36m(WorkerDict pid=176029)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=175829)[0m After building vllm rollout, memory allocated (GB): 52.048779010772705, memory reserved (GB): 55.107421875
[36m(WorkerDict pid=175829)[0m After building sharding manager, memory allocated (GB): 52.048779010772705, memory reserved (GB): 55.107421875
[36m(main_task pid=173992)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=173992)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=173992)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=173992)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_213435-hp3jgb3b
[36m(main_task pid=173992)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=173992)[0m wandb: Syncing run ppo_Math1.5B_tok1k_dapo17k
[36m(main_task pid=173992)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=173992)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/hp3jgb3b
[36m(main_task pid=173992)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=173992)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k/latest_checkpointed_iteration.txt
[36m(main_task pid=173992)[0m Training from scratch
[36m(main_task pid=173992)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=173992)[0m validation generation end
[36m(WorkerDict pid=176030)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=173992)[0m Not computing the values of prompts.
[36m(main_task pid=173992)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=173992)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=173992)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=173992)[0m    \[
[36m(main_task pid=173992)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=173992)[0m    \]
[36m(main_task pid=173992)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=173992)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=173992)[0m    \[
[36m(main_task pid=173992)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=173992)[0m    \]
[36m(main_task pid=173992)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m Let's implement this in Python to get the exact values for \(r\) and \(\theta\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m ```python
[36m(main_task pid=173992)[0m import sympy as sp
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Define the rectangular coordinates
[36m(main_task pid=173992)[0m x = 0
[36m(main_task pid=173992)[0m y = 3
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Calculate the radius r
[36m(main_task pid=173992)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Calculate the angle theta
[36m(main_task pid=173992)[0m theta = sp.atan2(y, x)
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=173992)[0m if theta < 0:
[36m(main_task pid=173992)[0m     theta += 2 * sp.pi
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Print the result
[36m(main_task pid=173992)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=173992)[0m ```
[36m(main_task pid=173992)[0m ```output
[36m(main_task pid=173992)[0m r = 3, theta = pi/2
[36m(main_task pid=173992)[0m ```
[36m(main_task pid=173992)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=173992)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=173992)[0m [score] 1.0
[36m(main_task pid=173992)[0m ERROR:2025-04-18 21:35:01,407:Error during comparison
[36m(main_task pid=173992)[0m Traceback (most recent call last):
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=173992)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=173992)[0m     return func(*args, **kwargs)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=173992)[0m     return sympy_expr_eq(
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=173992)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=173992)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=173992)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=173992)[0m     d[None].extend(seq)
[36m(main_task pid=173992)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(WorkerDict pid=176030)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=176030)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=173992)[0m ("Initial validation metrics: {'val/test_score/MATH500': 0.46169354838709675, "
[36m(main_task pid=173992)[0m  "'val/pass_rate/avg': 0.46169354838709675, 'val/pass_rate/median': 0.0, "
[36m(main_task pid=173992)[0m  "'val/pass_rate/bucket_0%': 0.5383064516129032, 'val/pass_rate/bucket_0-20%': "
[36m(main_task pid=173992)[0m  "0.0, 'val/pass_rate/bucket_20-40%': 0.0, 'val/pass_rate/bucket_40-60%': 0.0, "
[36m(main_task pid=173992)[0m  "'val/pass_rate/bucket_60-80%': 0.0, 'val/pass_rate/bucket_80-100%': 0.0, "
[36m(main_task pid=173992)[0m  "'val/pass_rate/bucket_100%': 0.46169354838709675}")
[36m(main_task pid=173992)[0m step:0 - val/test_score/MATH500:0.462 - val/pass_rate/avg:0.462 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.538 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.462
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:54,738:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:54,743:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:54,744:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2019}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:54,779:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:54,834:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{47}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:54,855:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{35}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:54,856:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{770}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:54,872:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{100}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:54,939:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3987}'], Pred: [' \\text{Answer: } \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,051:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,055:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{253}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,070:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: [' \n( the end )<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,165:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{351}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,260:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,273:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,650:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,656:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{47}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,676:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,699:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,717:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,740:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,761:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{592043}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,763:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,827:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,894:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17576}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,898:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,901:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,927:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{37}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:55,994:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{32}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,011:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: [' Once<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,016:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,018:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,044:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,098:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,454:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,524:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,570:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,727:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,787:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{30}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,788:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,820:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7200}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,827:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{173}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,879:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,910:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,920:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:56,960:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,055:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,074:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,089:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,095:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,106:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{30}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,113:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,212:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,227:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2016031}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,238:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,295:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: [' \\<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,359:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,391:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,505:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1850}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,578:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{34}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,607:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2024}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,608:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{875}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,629:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,631:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,631:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,642:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,767:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2015}'], Pred: ['  [hide=Noticing a Confusion1][color=red] // Big Lumpgap // [/color][/hide]<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,790:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,800:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,804:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,807:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,868:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{105}'], Pred: [' $RightAnswer<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:57,892:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2358}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:58,336:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:58,390:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:58,424:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{999}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:58,425:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{161051}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:35:58,433:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m ERROR:2025-04-18 21:36:03,450:Timeout during comparison
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:03,462:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{841}'], Pred: [' The solution can be written as `14`.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:03,467:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{66}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:03,535:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{26}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:03,691:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:03,692:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:03,696:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{334}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:03,705:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:03,770:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{936}'], Pred: [' The final answer is \\(\\boxed{}\\).<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:03,771:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:03,900:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{75}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,187:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{35}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,203:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4095}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,213:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{65}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,226:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,275:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,299:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: [' Answer: The answer is \\infty.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,303:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,329:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,341:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{408}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,359:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{246}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,361:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{26}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,477:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,500:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{448}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,502:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{319}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,505:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{96}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,546:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{271}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,549:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{30}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,657:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8000}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,687:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{45}'], Pred: [' To find the largest possible integral value of \\(\\<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,688:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{100}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,776:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3585}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,821:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,827:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,952:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:04,974:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:05,282:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:05,286:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{279}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:05,415:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:05,615:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{550}'], Pred: [' \\text{Answer}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:05,690:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: [' What is the value of N⋅MdotP⋅Q after computing it.It\'s a bit like Chinese painting，where the spirit of a work must form the living form，and may even push the work forward into the direction of artistic expression. As the current arena is changing from what it was, in decades and as MIPeal chooses to avoid excessive pus to create something important, space is created a little bit more aware of our psychology, we create something different, different from our psychology, to show our content，a library created by its own ways. The format is miniaturized, and only invites content that stands out."In your pocket，you can instantly.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:36:05,694:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17160}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=175829)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=175829)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
[36m(WorkerDict pid=176030)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=176030)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 4x across cluster][0m
[36m(main_task pid=173992)[0m step:1 - global_seqlen/min:172882.000 - global_seqlen/max:191155.000 - global_seqlen/minmax_diff:18273.000 - global_seqlen/balanced_min:179897.000 - global_seqlen/balanced_max:179898.000 - global_seqlen/mean:179897.250 - critic/kl:0.001 - critic/kl_coeff:0.001 - critic/vf_loss:5.655 - critic/vf_clipfrac:0.000 - critic/vpred_mean:2.137 - critic/grad_norm:356.671 - perf/mfu/critic:0.251 - critic/lr:0.000 - actor/entropy_loss:0.906 - actor/pg_loss:0.166 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:7.679 - perf/mfu/actor:0.338 - perf/max_memory_allocated_gb:56.608 - perf/max_memory_reserved_gb:72.773 - perf/cpu_memory_used_gb:69.258 - actor/lr:0.000 - critic/score/mean:0.040 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.040 - critic/rewards/max:1.001 - critic/rewards/min:-0.003 - critic/advantages/mean:0.000 - critic/advantages/max:5.004 - critic/advantages/min:-3.913 - critic/returns/mean:0.042 - critic/returns/max:1.001 - critic/returns/min:-0.004 - critic/values/mean:2.125 - critic/values/max:12.312 - critic/values/min:-11.000 - critic/vf_explained_var:-169.486 - response_length/mean:568.605 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.186 - prompt_length/mean:134.118 - prompt_length/max:482.000 - prompt_length/min:56.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:31.467 - timing_s/old_log_prob:5.440 - timing_s/ref:5.293 - timing_s/values:6.905 - timing_s/adv:11.101 - timing_s/update_critic:25.569 - timing_s/update_actor:18.985 - timing_s/step:104.785 - timing_per_token_ms/adv:0.015 - timing_per_token_ms/ref:0.007 - timing_per_token_ms/update_critic:0.036 - timing_per_token_ms/values:0.010 - timing_per_token_ms/gen:0.054 - timing_per_token_ms/update_actor:0.026 - perf/total_num_tokens:719589.000 - perf/time_per_step:104.785 - perf/throughput:1716.828
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,395:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{137}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,419:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=176029)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=176029)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 3x across cluster][0m
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,534:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5024}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,586:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{170}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,587:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,588:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: [' Here is the step-by-step solution:<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,598:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,624:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,666:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,672:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{148}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,681:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,788:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{233}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,794:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{291}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,814:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{28}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:41,926:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{319}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,109:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{31}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,122:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: [' Answer: \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,191:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{24}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,192:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,234:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: [' \nProspectus:\nPlease Provide a Detailed Explanation:\n & find the value of m + n.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,245:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{43}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,248:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,253:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,272:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,286:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,375:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,393:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,541:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,621:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,713:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,763:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{423}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,764:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1995}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,765:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,773:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{109}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,778:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{61}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,831:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:42,906:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{840}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:44,998:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{50}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,023:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,072:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: [' .<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,129:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,268:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{200}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,301:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{504}'], Pred: [' \\]<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,365:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{248}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,375:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{177}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,400:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2037173}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,401:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{155}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,418:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{720}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,463:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1996906}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,478:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2016}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,521:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [' (Without quotes.)<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,597:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{662}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,612:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,620:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: [' \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,622:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{40}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,655:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,814:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{121}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,884:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4046}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,943:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:45,994:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{31}'], Pred: [' This step-by-step approach ensures accuracy and clarity in arriving at the solution.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,220:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,241:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,249:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,307:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{282}'], Pred: [' \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,326:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,349:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,423:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,423:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: [' \n\nHere is the rationale for solving this problem step-by-step:<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,436:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{30}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,442:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{135}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,472:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,473:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,510:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,511:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{24}'], Pred: [' To find all positive integer pairs ((x,y)), we iterate (x) from (2) to ((12), inclusive. For each (x), we iterate (y) from (x+1) to (sqrt{(x^{y})}), exclusive. If both (x^{y}) and (y^{x-y}) are perfect powers and equal, we have found a valid pair, which we store. Finally, we sum up all (x*y) for all found pairs. The solution involves iterating over possible values of (x) and (y), checking for valid pairs, adding their products, and returning the total sum as the answer.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,514:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1442}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,547:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,564:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,700:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{129}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,704:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,744:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{371}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,763:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,770:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,852:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:46,898:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{23}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:47,016:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{23}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:47,017:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13483236}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:47,025:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:47,072:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:47,126:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1698}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:47,230:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{112}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:47,244:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{58}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:47,279:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{420}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:47,279:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: [' We typically define problem n, n the problem number.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:47,721:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:47,723:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{216}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:47,729:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: [' J:<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:47,755:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,106:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,133:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{190}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,216:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,224:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,237:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,293:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3196}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,294:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{440}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,325:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{150}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,363:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{123}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,387:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,390:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,401:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: [' \n\n*Clarification and finalization are mentioned in the leveling process mentioned above.*<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,406:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,627:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{34}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:37:48,636:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m step:2 - global_seqlen/min:172850.000 - global_seqlen/max:189519.000 - global_seqlen/minmax_diff:16669.000 - global_seqlen/balanced_min:178896.000 - global_seqlen/balanced_max:178896.000 - global_seqlen/mean:178896.000 - critic/kl:0.000 - critic/kl_coeff:0.001 - critic/vf_loss:4.807 - critic/vf_clipfrac:0.476 - critic/vpred_mean:1.189 - critic/grad_norm:121.961 - perf/mfu/critic:0.249 - critic/lr:0.000 - actor/entropy_loss:0.890 - actor/pg_loss:-0.731 - actor/pg_clipfrac:0.008 - actor/ppo_kl:0.001 - actor/grad_norm:7.816 - perf/mfu/actor:0.389 - perf/max_memory_allocated_gb:61.590 - perf/max_memory_reserved_gb:72.773 - perf/cpu_memory_used_gb:69.930 - actor/lr:0.000 - critic/score/mean:0.039 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.039 - critic/rewards/max:1.002 - critic/rewards/min:-0.003 - critic/advantages/mean:0.000 - critic/advantages/max:4.862 - critic/advantages/min:-4.254 - critic/returns/mean:0.037 - critic/returns/max:1.002 - critic/returns/min:-0.004 - critic/values/mean:2.172 - critic/values/max:13.125 - critic/values/min:-10.438 - critic/vf_explained_var:-184.240 - response_length/mean:567.187 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.180 - prompt_length/mean:131.626 - prompt_length/max:485.000 - prompt_length/min:58.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:35.441 - timing_s/old_log_prob:4.252 - timing_s/ref:4.283 - timing_s/values:6.949 - timing_s/adv:7.357 - timing_s/update_critic:25.582 - timing_s/update_actor:16.431 - timing_s/step:100.340 - timing_per_token_ms/adv:0.010 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/update_critic:0.036 - timing_per_token_ms/values:0.010 - timing_per_token_ms/gen:0.061 - timing_per_token_ms/update_actor:0.023 - perf/total_num_tokens:715584.000 - perf/time_per_step:100.340 - perf/throughput:1782.894
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:17,943:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:17,947:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{179}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:17,996:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{93}'], Pred: [' \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:18,185:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{42}'], Pred: [" Let's think step by step and output the final answer within \\boxed{}.<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:18,192:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:18,431:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{952}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:18,551:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{45}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:18,555:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:18,600:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{24017351}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:18,794:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{504}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:18,811:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:18,845:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2023}'], Pred: [' \\text{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:18,878:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1344}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,055:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{819}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,066:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,078:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{743}'], Pred: [' So the answer is \\(\\boxed{}\\).<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,099:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{126}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,104:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,123:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,137:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{383}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,154:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,183:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,261:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2006}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,273:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{173}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,276:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{96}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,289:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,304:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{50}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,434:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,505:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{60}'], Pred: [' The answer is \\boxed{}.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,634:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{60544}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,740:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,744:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{594}'], Pred: [' Answer:<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,783:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{43}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,804:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,814:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,915:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,968:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{683}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:19,995:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,023:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{41}'], Pred: [' (a)\nAnswer: \\(\\boxed{}\\).<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,024:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{72}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,194:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1998}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,265:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{32}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,387:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{86}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,392:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{96}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,462:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,493:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,681:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,692:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: [' $$<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,696:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,741:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{154}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,772:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{600}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,776:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{42}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,778:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,845:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6600}'], Pred: [' \\textbf{Answer: }7<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,846:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,851:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{150}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,855:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{32}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,884:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{387}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,915:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{179}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,945:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{22}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:20,982:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:21,012:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1506}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:21,148:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:21,203:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:21,388:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:21,904:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5412}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:21,971:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:21,972:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{343}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,000:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,006:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4112}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,080:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{100}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,081:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{403}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,099:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{31}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,103:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{89}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,144:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,159:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{199}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,207:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{50}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,209:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,263:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1701}'], Pred: [' Answer: \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,269:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,280:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7200}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,312:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,335:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,396:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{36}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,707:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,709:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:39:22,717:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=173992)[0m validation generation end
[36m(main_task pid=173992)[0m Not computing the values of prompts.
[36m(main_task pid=173992)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=173992)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=173992)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=173992)[0m    \[
[36m(main_task pid=173992)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=173992)[0m    \]
[36m(main_task pid=173992)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=173992)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=173992)[0m    \[
[36m(main_task pid=173992)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=173992)[0m    \]
[36m(main_task pid=173992)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m Let's implement this in Python to get the exact values for \(r\) and \(\theta\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m ```python
[36m(main_task pid=173992)[0m import sympy as sp
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Define the rectangular coordinates
[36m(main_task pid=173992)[0m x = 0
[36m(main_task pid=173992)[0m y = 3
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Calculate the radius r
[36m(main_task pid=173992)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Calculate the angle theta
[36m(main_task pid=173992)[0m theta = sp.atan2(y, x)
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=173992)[0m if theta < 0:
[36m(main_task pid=173992)[0m     theta += 2 * sp.pi
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Print the result
[36m(main_task pid=173992)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=173992)[0m ```
[36m(main_task pid=173992)[0m ```output
[36m(main_task pid=173992)[0m r = 3, theta = pi/2
[36m(main_task pid=173992)[0m ```
[36m(main_task pid=173992)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=173992)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=173992)[0m [score] 1.0
[36m(main_task pid=173992)[0m ERROR:2025-04-18 21:40:33,068:Error during comparison
[36m(main_task pid=173992)[0m Traceback (most recent call last):
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=173992)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=173992)[0m     return func(*args, **kwargs)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=173992)[0m     return sympy_expr_eq(
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=173992)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=173992)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=173992)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=173992)[0m     d[None].extend(seq)
[36m(main_task pid=173992)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(main_task pid=173992)[0m step:3 - global_seqlen/min:175043.000 - global_seqlen/max:194265.000 - global_seqlen/minmax_diff:19222.000 - global_seqlen/balanced_min:186400.000 - global_seqlen/balanced_max:186401.000 - global_seqlen/mean:186400.500 - critic/kl:-0.000 - critic/kl_coeff:0.001 - critic/vf_loss:0.830 - critic/vf_clipfrac:0.221 - critic/vpred_mean:0.240 - critic/grad_norm:34.104 - perf/mfu/critic:0.259 - critic/lr:0.000 - actor/entropy_loss:0.877 - actor/pg_loss:0.279 - actor/pg_clipfrac:0.009 - actor/ppo_kl:0.001 - actor/grad_norm:10.082 - perf/mfu/actor:0.362 - perf/max_memory_allocated_gb:61.635 - perf/max_memory_reserved_gb:74.730 - perf/cpu_memory_used_gb:69.573 - actor/lr:0.000 - val/test_score/MATH500:0.468 - val/pass_rate/avg:0.468 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.532 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.468 - critic/score/mean:0.039 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.039 - critic/rewards/max:1.002 - critic/rewards/min:-0.004 - critic/advantages/mean:-0.000 - critic/advantages/max:7.834 - critic/advantages/min:-6.508 - critic/returns/mean:0.040 - critic/returns/max:1.002 - critic/returns/min:-0.004 - critic/values/mean:0.414 - critic/values/max:9.562 - critic/values/min:-10.688 - critic/vf_explained_var:-50.745 - response_length/mean:591.997 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.191 - prompt_length/mean:136.130 - prompt_length/max:502.000 - prompt_length/min:56.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:31.178 - timing_s/old_log_prob:4.494 - timing_s/ref:4.505 - timing_s/values:6.961 - timing_s/adv:4.879 - timing_s/update_critic:25.713 - timing_s/update_actor:18.367 - timing_s/testing:28.397 - timing_s/step:124.514 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/update_critic:0.034 - timing_per_token_ms/values:0.009 - timing_per_token_ms/gen:0.051 - timing_per_token_ms/update_actor:0.025 - perf/total_num_tokens:745602.000 - perf/time_per_step:124.514 - perf/throughput:1497.020
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:21,609:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:21,767:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{71}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:21,803:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{509040}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:21,811:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-2013}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:21,964:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:21,989:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3333}'], Pred: [' \\newline \\newline \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,071:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{40}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,187:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{80}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,193:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,207:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,239:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3585}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,246:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,258:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{170}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,312:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{55}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,315:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{100}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,339:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{94}'], Pred: [' Not applicable<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,342:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,371:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{289}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,410:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: [' One possible answer per line.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,413:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: [' Thanks for all your support! If you enjoy what you are reading, please keep \\pinging!<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,444:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,513:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,514:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: [' Answer:<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,529:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,530:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{42}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,625:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{370}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,626:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{67}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,658:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{100}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,659:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{432}'], Pred: [' This puts the final answer inside the bracket.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,742:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{650}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,863:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{191}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,871:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,887:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,898:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:22,965:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,005:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1186}'], Pred: [' \n\n$\\boxed{}$<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,050:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1155}'], Pred: [' \\text{"The smallest odd number with four different prime factors." is the last line of your response.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,085:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,096:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{880}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,125:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,173:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,177:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,190:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{118}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,200:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{511}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,213:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,447:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,455:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{78}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,459:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{31}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,465:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1000}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,468:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,625:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{450}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,625:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,639:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,640:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{62}'], Pred: [" Let me know if you have any questions or if there's anything I can clarify, or just tell me when you're ready to get started on this one!<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,644:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,696:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,725:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{24}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,768:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,943:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,944:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{73}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,946:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{351}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,947:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:23,950:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,005:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{99}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,022:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{120}'], Pred: [' )<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,041:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,042:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{180}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,092:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{112}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,100:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1000}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,114:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,208:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10095}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,274:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,287:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{32}'], Pred: [' .<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,304:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{75}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,329:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: [' How is it going?<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,352:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{126632}'], Pred: [' Answer: \\()<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,389:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{31}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,426:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,439:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{335}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,467:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{307}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,483:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,484:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10000}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,538:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,544:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,784:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{277}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,795:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: [' (optional)<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,836:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9871}'], Pred: [" We welcome your feedback, comments and questions on our Facebook page or Twitter feed. And don't forget to subscribe if you want to make sure you don't miss out on the next article.<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,852:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{70}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,887:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:24,959:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:25,033:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:25,077:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:25,227:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6491}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:29,587:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:29,654:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:29,655:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:29,660:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{22}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:29,687:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{591}'], Pred: [' 复杂度分析可以看站.\n[recmax]<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:29,916:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{100}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:29,926:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{133}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:29,930:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:29,931:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{100}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:29,950:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:29,961:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{117649}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:29,975:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{75}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,008:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{151}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,041:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{294}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,134:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{501}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,149:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,193:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2007}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,228:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,239:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,241:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{65}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,262:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2704}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,268:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,278:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{932}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,285:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{35}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,288:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,334:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{65}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,361:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:41:30,383:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m step:4 - global_seqlen/min:171967.000 - global_seqlen/max:184695.000 - global_seqlen/minmax_diff:12728.000 - global_seqlen/balanced_min:176129.000 - global_seqlen/balanced_max:176130.000 - global_seqlen/mean:176129.750 - critic/kl:-0.006 - critic/kl_coeff:0.001 - critic/vf_loss:0.425 - critic/vf_clipfrac:0.069 - critic/vpred_mean:0.057 - critic/grad_norm:20.678 - perf/mfu/critic:0.241 - critic/lr:0.000 - actor/entropy_loss:0.934 - actor/pg_loss:-1.020 - actor/pg_clipfrac:0.006 - actor/ppo_kl:-0.001 - actor/grad_norm:9.399 - perf/mfu/actor:0.408 - perf/max_memory_allocated_gb:61.635 - perf/max_memory_reserved_gb:74.730 - perf/cpu_memory_used_gb:69.578 - actor/lr:0.000 - critic/score/mean:0.042 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.042 - critic/rewards/max:1.002 - critic/rewards/min:-0.003 - critic/advantages/mean:0.000 - critic/advantages/max:11.084 - critic/advantages/min:-8.096 - critic/returns/mean:0.045 - critic/returns/max:1.003 - critic/returns/min:-0.003 - critic/values/mean:0.191 - critic/values/max:7.375 - critic/values/min:-9.750 - critic/vf_explained_var:-17.574 - response_length/mean:553.054 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.162 - prompt_length/mean:134.953 - prompt_length/max:500.000 - prompt_length/min:56.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:30.273 - timing_s/old_log_prob:4.268 - timing_s/ref:4.277 - timing_s/values:6.955 - timing_s/adv:9.375 - timing_s/update_critic:26.037 - timing_s/update_actor:15.417 - timing_s/step:96.631 - timing_per_token_ms/adv:0.013 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/update_critic:0.037 - timing_per_token_ms/values:0.010 - timing_per_token_ms/gen:0.053 - timing_per_token_ms/update_actor:0.022 - perf/total_num_tokens:704519.000 - perf/time_per_step:96.631 - perf/throughput:1822.706
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:57,696:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:57,722:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{80}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:57,884:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:57,904:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:57,940:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:57,969:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18090}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:57,970:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:57,989:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,094:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{680}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,096:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-3}'], Pred: [" If it's a multiple-choice problem, output the correct option directly. Otherwise, just output the final answer.<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,106:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{24}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,127:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,232:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1648}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,239:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8083}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,252:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7933}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,478:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,537:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: [' The final answer is:<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,649:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,677:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,694:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{574}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,695:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-484}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,730:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{41}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,746:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{160}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,749:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{280}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,858:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{285}'], Pred: [' This will use the steps to constructively calculate the required answer.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,864:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,873:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,880:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{95}'], Pred: [" Dear student,\nI'm sorry, but the provided text doesn't seem to contain any instructions or questions. Could you please provide more context or clarify the problem so that I can assist you better?<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,892:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,893:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: [' a, b, c, d a, b, c, or d.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:58,984:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,035:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{505}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,043:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: [' Be careful!<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,170:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,274:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [' Will you provide the actual problem statement with the two lists?<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,284:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{57}'], Pred: [' #\n\nSee the answer<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,287:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,352:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{217}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,411:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,440:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{34}'], Pred: [" 大前提是“逻辑”中的双重否定,想法是把意思辨识正误一下,往往心得体会都出来了 好 大大的棒棒 没什么大道理,只是想大家闹笑话而已 其实逻辑里面的事是可数可闻的,很少有人参系的. 因此请问逻辑学习有什么作用 没什么把握 希望诸君能够给我补充更多功课 我接下看来参考书,看一下 有说句子思想哲理是对,说再复杂一些就是逻辑 是不是因为这样? 在看教你逻辑志中有什么可以精通 关键点 在数学内容中 有锥环\n\nA：Alison，who is it that you met yesterday？ B：It （1）______ John．I assumed he had left because he had gone home． A：No．You see，he sat on the bench I called him to． B： （2）______？But it was only ten o'clock，he could not be there yet! A：It has been raining （3）______．Maybe he went down for shelter when it stopped raining． B：Maybe so． （4）______？ A：Yes，it's very tall and old． B：Enough to be lived（5）______？ A：Well，you aren't in the wrong place．It's a monument． B：Oh，dear，this is the Income Tax Department，is that right？ A：No，on the contrary．Banks are （6）______．The Government signs up at other places．And （7）______． B：May I take this as an address？ A：Th we shall take （8）______ of this one at once．However it is，the block belongs to a charity of interest． B：Do you have details of the office where I can find the permit（许可）？ A： —Yes，it is in a building in the Main Centre．It is on Fleet Street．But （9）______we haven't admired enough the building itself for a while，would you care （10）______ our meetings there？ B：OK．I am sure they can allow me to take a seat． A：I will ring the head of the department，but I recommend you call two or three other （11）______by yourselves first，then you can give up their lists from some of your friends that you business associate （12）______ work occasionally． B：OK!Thanks again．Hope to see you early tomorrow． A：See you． By the sign,Why,about a week,where did it take place,for generations,to cater to,who it is,say,what do you mean,upon,after,general,In,that<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,442:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3196}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,517:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2004}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,526:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{40}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,527:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,631:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,677:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{85}'], Pred: [' The solution \\boxed{}.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,683:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,751:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2035151}'], Pred: [' \\centerboxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,767:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{199}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,773:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: [' \n    \n\n-- [Resharper]<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,774:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{26}'], Pred: [' The answer is<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,809:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,837:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,838:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{47}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,869:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{270}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,884:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{27}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,891:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{336}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,979:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,982:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:42:59,989:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,055:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,078:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: [' 解这个问题的关键是明确每次皆为0.6的概率是多少. 初始为甲向来答对，要想过渡为甲全部难以，轮到乙只会选出来他就答对，或不答对，最后交出(n−1)nATBA的分数．注意面试双眼应死死盯住已答完全(最后)的概率，当轮到甲再答题前，他答对的也是99%的概率了，让他提前退出好吗？概率就是这样，前面一定大，这也就是为啥约定好总积分20的概率才90%的原因。\n\n马克思主义与中国实际相结合的第一次历史性飞跃的理论成果是____( ) HYPERLINK "https://mooc1-1.chaoxing.com/work/javascript:void( )" \\o \\"点我复制链接\\" 资产阶级革命的成功，使得马克思主义进入了____( ) HYPERLINK "https://mooc1-1.chaoxing.com/work/javascript:void( )" \\o \\"点我复制链接\\" 中国化。 HYPERLINK "https://mooc1-1.chaoxing.com/work/javascript:void( )" \\o \\"点我复制链接\\"ENTA_1006368 STEMZ1013000030199\n\n绝缘靴的试验周期是（ ）。 .每日巡视\n\n中国大学MOOC: 软件测试的三个基本要素是（ ） 输入、处理、输出\n\n系统中的管向物件、变粗和变细应选用管（ ），气流进入屋面应选用管（ ）。 双管 三管<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,079:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{801}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,100:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,117:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{555}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,175:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{168}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,179:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,201:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{31}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,202:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,203:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,262:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7201}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,302:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,317:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{65}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,322:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{83}'], Pred: [' In checking, this specific angle found appropriate for my angle equality problem.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,412:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{401}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,456:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{109}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,499:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4022}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,523:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{30202}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,530:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: [' Answer: None<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,651:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2008}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,655:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{243}'], Pred: [' (答案：2) (最终答案：2)<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,670:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: [" \\text{Solver's Note}: The solver should be able to confirm the figures (using screensharing) by solving the equation.<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,776:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{42}'], Pred: [' The very first sequential item comprises of only being one.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,784:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{511}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,805:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,822:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{23}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,913:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{124}'], Pred: [' The answer is: \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:00,985:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{135}'], Pred: [' </s><|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,007:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{184}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,013:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,029:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,133:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,171:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1266}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,467:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{349}'], Pred: [' Answer: ④<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,472:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,498:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{80}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,499:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6528}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,521:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10060}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,627:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{899}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,690:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{807}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,701:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{200}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,722:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{899}'], Pred: [' Answer: .<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,860:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1625}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,871:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{241}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,886:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,959:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{131}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:01,966:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{88}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:02,017:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{304}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:02,025:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{38}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:02,026:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:02,044:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{60}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:02,157:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{43}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:02,205:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:43:02,315:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3004}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m step:5 - global_seqlen/min:170100.000 - global_seqlen/max:182873.000 - global_seqlen/minmax_diff:12773.000 - global_seqlen/balanced_min:175493.000 - global_seqlen/balanced_max:175493.000 - global_seqlen/mean:175493.000 - critic/kl:-0.011 - critic/kl_coeff:0.001 - critic/vf_loss:0.160 - critic/vf_clipfrac:0.044 - critic/vpred_mean:0.060 - critic/grad_norm:18.214 - perf/mfu/critic:0.239 - critic/lr:0.000 - actor/entropy_loss:0.816 - actor/pg_loss:-0.323 - actor/pg_clipfrac:0.008 - actor/ppo_kl:-0.003 - actor/grad_norm:7.685 - perf/mfu/actor:0.334 - perf/max_memory_allocated_gb:61.635 - perf/max_memory_reserved_gb:74.752 - perf/cpu_memory_used_gb:69.549 - actor/lr:0.000 - critic/score/mean:0.034 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.034 - critic/rewards/max:1.001 - critic/rewards/min:-0.003 - critic/advantages/mean:0.000 - critic/advantages/max:13.723 - critic/advantages/min:-11.549 - critic/returns/mean:0.035 - critic/returns/max:1.001 - critic/returns/min:-0.003 - critic/values/mean:0.224 - critic/values/max:7.344 - critic/values/min:-8.312 - critic/vf_explained_var:-10.394 - response_length/mean:551.119 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.175 - prompt_length/mean:134.400 - prompt_length/max:507.000 - prompt_length/min:57.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:29.829 - timing_s/old_log_prob:4.401 - timing_s/ref:4.408 - timing_s/values:6.977 - timing_s/adv:4.770 - timing_s/update_critic:26.137 - timing_s/update_actor:18.724 - timing_s/step:95.268 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/update_critic:0.037 - timing_per_token_ms/values:0.010 - timing_per_token_ms/gen:0.053 - timing_per_token_ms/update_actor:0.027 - perf/total_num_tokens:701972.000 - perf/time_per_step:95.268 - perf/throughput:1842.096
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,112:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,132:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{706}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,136:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4446}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,140:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,312:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{228}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,440:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: [' (the guessed answer) to define how the code is going to interpret your response.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,448:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1094}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,449:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,468:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{51}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,472:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,637:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: [" function f(x)=\\df{(x+1)}{(x)}+\\df{(x+2)}{(x+1)}+\\cdots+\\df{(x+2023)}{(x+2022)}; f(x)=\\df{(x+1)}{(x)}+\\df{(x+2)}{(x+1)}+\\cdots+\\df{(x+2023)}{(x+2022)}; Let's recall a fundamental mathematical concept called 'pattern'. Imagine fo...<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,709:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,799:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{73}'], Pred: [' Kenny Pak<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:34,835:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3024}'], Pred: [' \\end{document}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,083:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{198}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,120:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: [' The answer is<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,121:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{481}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,142:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,219:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{50}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,226:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,298:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,372:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{911}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,372:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,392:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2500}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,399:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,503:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{58}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,580:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,605:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,606:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,942:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:35,983:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,042:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{71}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,067:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [' II,，f T的一对交点位于斜率为x3的是前提．O C．若二个行小 thou4（抽sind中1. m个方term-inter area.~nV A．Craxl e,e茛 Ca. BC D．団ts5:aA C.\n\nPeople often start jobs before they’ve figured\twhat they want to do with their life. That’s completely natural. It’s all a learning process. Kids pick up who a mom is and who a dad is. Kindergartners are always asking questions. There’s lots of learning going on. And most of it you already know the answer to. Having those first jobs teaches kids the benefit of responsibility and the value of commitment (承诺) later in life. Listen, we know how much we’re taking for granted when we’re not trying to dig ourselves out of some debt and we’re not out in the workforce. We don’t want kids to have that experience early. It sends a message that working hard is OK. Many teenagers in America go to work at McDonald’s or Target. You’d think they went there because they had to. But it’s just another normal part of growing up. We all know kids never really leave home. There’s no closing a ZIP code or an X-ring of the world. They wear their mothers’ and fathers’ clothes but they carry on all day as if they’ve been running this place on their own. That’s a very inspiring thing. I usually tell my kids, if you’maxwell more stories, about this day in the driveway and this day of the week is usually started by some really ugly driving. So if your father’s hitting you up for money, and you don’t have the car repaired right away, and you don’t know what to do anymore, this is when that day when you first came home from work pops up. “I was just asking someone for money. “ 小题1:What does the underlined phrase mean 在第三段的第一句话中。 A．公司给了你一份工作的高薪. B．你应该了解一些有关童年的事情. C．你应该了解孩子的职业经历. D．你应该了解未来还有很长一段子. 小题2:From the third paragraph we can infer that. A．working hard is OK B．students are willing to help their parents. C．parents take a high sense of respect for their children. D．parents expect their kids go out and get a job 小题3:The word “ bambinos” in the third paragraph probably means in English. A．治疗的好多人. B．青春期的孩子们. C．童年时代的人. D．离家的现代人. 小题4:Where is the best place for us to read this passage? A．In a college textbook B．In a learning book C．In a family letter D．In a science novel 小题1: D 小题2: B 小题3: B 小题4: D<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,081:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{72}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,170:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,176:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,280:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{30}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,283:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: [' To write this in MathJax, it will look like {a+d+b+c+d=m}{(a-d)-(b-d)+(c-d)+(m-d)=(m-4)}\n\nMACD＞0是什么意思A. 越来越接近零 B. 越来越远离零 C. 越来越远离第一转换线 D. 越来越接近第一转换线\n越来越接近零<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,297:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,343:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: [" \\text{Let} \\qquad \\text{be the slope of} \\qquad Let's think step by step and output the final answer within . \\boxed{}}$ \\text{Let}<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,400:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,402:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,416:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{79}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,545:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{521}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,557:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,573:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{22}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,654:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,655:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{45}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,765:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{66}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,770:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{65}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,775:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{929}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,777:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{408}'], Pred: [' Answer: \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,800:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,805:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,830:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,912:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,919:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{24}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,953:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:36,988:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,122:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{42}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,157:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{834}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,300:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{810}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,301:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,456:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{36}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,462:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1185}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,797:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8465}'], Pred: [' \n\nPS: You can turn your thoughts into a finished paragraph using RST.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,821:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,846:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{34}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,856:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,860:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,865:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: [' 🔁<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,940:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,945:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14641}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,946:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{113}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,952:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{117}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:37,953:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:38,652:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{292}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:38,776:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{70}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:38,901:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2018}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:38,946:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:38,983:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{181}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:39,022:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:39,134:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: [' The final answer is: -boxed{-1}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:39,371:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{122}'], Pred: [' The boxed output is the solution to the question.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:44:39,379:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{250}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=173992)[0m validation generation end
[36m(main_task pid=173992)[0m Not computing the values of prompts.
[36m(main_task pid=173992)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=173992)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=173992)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=173992)[0m    \[
[36m(main_task pid=173992)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=173992)[0m    \]
[36m(main_task pid=173992)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=173992)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=173992)[0m    \[
[36m(main_task pid=173992)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=173992)[0m    \]
[36m(main_task pid=173992)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m Let's implement this in Python to get the exact values.
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m ```python
[36m(main_task pid=173992)[0m import sympy as sp
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Define the rectangular coordinates
[36m(main_task pid=173992)[0m x = 0
[36m(main_task pid=173992)[0m y = 3
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Calculate the radius r
[36m(main_task pid=173992)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Calculate the angle theta
[36m(main_task pid=173992)[0m theta = sp.atan2(y, x)
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=173992)[0m if theta < 0:
[36m(main_task pid=173992)[0m     theta += 2 * sp.pi
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Print the result
[36m(main_task pid=173992)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=173992)[0m ```
[36m(main_task pid=173992)[0m ```output
[36m(main_task pid=173992)[0m r = 3, theta = pi/2
[36m(main_task pid=173992)[0m ```
[36m(main_task pid=173992)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=173992)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=173992)[0m [score] 1.0
[36m(main_task pid=173992)[0m ERROR:2025-04-18 21:45:49,595:Error during comparison
[36m(main_task pid=173992)[0m Traceback (most recent call last):
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=173992)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=173992)[0m     return func(*args, **kwargs)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=173992)[0m     return sympy_expr_eq(
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=173992)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=173992)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=173992)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=173992)[0m     d[None].extend(seq)
[36m(main_task pid=173992)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(main_task pid=173992)[0m step:6 - global_seqlen/min:186141.000 - global_seqlen/max:190243.000 - global_seqlen/minmax_diff:4102.000 - global_seqlen/balanced_min:187698.000 - global_seqlen/balanced_max:187699.000 - global_seqlen/mean:187698.250 - critic/kl:-0.017 - critic/kl_coeff:0.001 - critic/vf_loss:0.077 - critic/vf_clipfrac:0.004 - critic/vpred_mean:0.020 - critic/grad_norm:21.763 - perf/mfu/critic:0.256 - critic/lr:0.000 - actor/entropy_loss:0.745 - actor/pg_loss:-0.976 - actor/pg_clipfrac:0.007 - actor/ppo_kl:0.002 - actor/grad_norm:7.078 - perf/mfu/actor:0.380 - perf/max_memory_allocated_gb:61.638 - perf/max_memory_reserved_gb:74.752 - perf/cpu_memory_used_gb:69.619 - actor/lr:0.000 - val/test_score/MATH500:0.462 - val/pass_rate/avg:0.462 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.538 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.462 - critic/score/mean:0.038 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.038 - critic/rewards/max:1.001 - critic/rewards/min:-0.003 - critic/advantages/mean:-0.000 - critic/advantages/max:12.615 - critic/advantages/min:-13.724 - critic/returns/mean:0.039 - critic/returns/max:1.002 - critic/returns/min:-0.003 - critic/values/mean:0.117 - critic/values/max:5.094 - critic/values/min:-4.531 - critic/vf_explained_var:-2.585 - response_length/mean:600.391 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.201 - prompt_length/mean:132.806 - prompt_length/max:463.000 - prompt_length/min:59.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:30.793 - timing_s/old_log_prob:4.533 - timing_s/ref:4.514 - timing_s/values:6.959 - timing_s/adv:5.373 - timing_s/update_critic:26.201 - timing_s/update_actor:17.620 - timing_s/testing:28.332 - timing_s/step:124.349 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/update_critic:0.035 - timing_per_token_ms/values:0.009 - timing_per_token_ms/gen:0.050 - timing_per_token_ms/update_actor:0.023 - perf/total_num_tokens:750793.000 - perf/time_per_step:124.349 - perf/throughput:1509.447
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:38,480:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{51}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:38,497:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:38,588:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3196}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:38,686:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{545}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:38,697:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:38,705:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:38,734:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{240}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:38,968:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:38,973:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:38,979:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,022:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,060:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,137:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{40}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,187:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: [' $$ $$\n\nKristen Nason is the principal of Starlight Church at Loma Linda, and also the CEO of Small Beautiful Church. How did you put together the leadership team that made everything happen? Tell me about the changes you have made locally.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,267:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,269:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: [" Casey's crew was searching for Casper Willems. Having led a troop to a saunter on the ecosphere near יה散, the girls made their way to a yammed forest in آبادي. Herring-glazed seismographers accentuated by the ludibrium of a swear-token; duckyy but refreshment which is that of a quiet brown part per unity. Cupping main bounds, modicum cellular vitreматurationnies involved to applaud tat he breaks the baneful spainery bridge of the pisshing demonstration. Spudgoing Brussels devils engaged to book on to the monopandic competition. Stacked dragging x-ray's domesticating fussy sputter of a kafkaflab, esentially unfump that transevolent urbane pronounces. Mastering the lingering наибольшее количество of named aids for the cmps liar, the googly information in the anxious poem was that faithmatical syndrome came from the beautiful bedside of the catguinty syrena. The majority fu(apperior goes real biennial piano beds; not-almost the cosiest decline was shyly subjected to the ukvisão noodles advikers, whose wodgers dissaye the fessakers for the sheepish parameter works. The tsangong and road passing the surprises in the shiarred expo belay the reined-action pandemoniums of a snanchap-lekker Wikipedia's. Indeed, the rough inter说得清楚 than this, logistically the blister assessments of a Gale is the sell-out specimen (here did the recessed wiener infect a quide-knacker?).<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,299:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,314:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{169}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,319:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,465:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,515:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,683:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{625}'], Pred: [' Answer:<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,748:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{67}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,836:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,837:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-15}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,854:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,909:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{96}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:39,910:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{122}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,032:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{59}'], Pred: [" Let's begin by calculating the probability then.\n\nCrossovers:\n\n{eq}\nBinomial series - Google Search\n{eq}\nBinomial distribution Probability Formula\n{eq}\nprob distribution formula\n{eq}\nprobability sum formula\n{eq}\ngeometric series formula\n{eq}\nprobability probability formula\n{eq}\nbinomial formula formula healthy\n{eq}\nweibull distribution wiki\n{eq}\nexponential distribution pdf formula\n{eq}\ngeometric distribution formula\n{eq}\nbinomial series distribution\n{eq}\npoisson distribution formula\n{eq}\ngeometric distribution formula\n{eq}\nweibull distribution wiki formula\n{eq}\nbinomial formula\n{eq}\nbinomial formula\n{eq}\nbinomial probability distribution formula\n{eq}\nweibull distribution formula\n{eq}\nbernoulli distribution formula\n{eq}\npoisson distribution formula\n{eq}\nweibull distribution formula\n{eq}\ngeometric distribution formula\n{eq}\nbinomial formula\n{eq}\nbinomial distribution probability \n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial distribution formula\n{eq}\nbinomial"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,138:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{71}'], Pred: [' """<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,212:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{36}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,232:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,266:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1346}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,323:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,369:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{23}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,420:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{78}'], Pred: [' \\Box.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,421:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{39}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,460:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,466:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,467:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,501:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,567:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1076}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,589:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{23}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,592:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1346}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,664:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13483236}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,682:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{148}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,688:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:40,901:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: [' We will make this approach: since the numbers are small, check if we can get the answer through a simple counting method. ##ティンプ南(http://just-teinv.com)マ特学生<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,023:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,024:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9901}'], Pred: [' #1 to #9: using double count on something where multiplication law can be applied and then cancel other over multiplication step by step\nboxed{5!} #10: basically is like asking for death, demise, annihilation of all matter (individual or objects).\nboxed{0}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,051:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,067:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{200}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,099:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,133:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{43}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,177:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{30}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,203:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,224:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,289:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{312}'], Pred: ['  \\ New琮 ( ?琮 ?琮 )琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮.琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮琮']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,632:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{144}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,635:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{100}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,697:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,729:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: [' Answer: (See below)<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,735:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{616}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,780:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,791:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{24}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:41,793:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{31}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,062:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{22}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,149:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{24}'], Pred: [' Hint: Hint: Hint: Hint\nHint: Hint: Hint:<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,210:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,229:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1012}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,270:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,282:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{28}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,288:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,472:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{269}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,474:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: [' ```python\nfrom sympy import solve, Symbol<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,503:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{108}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,505:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,572:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,585:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{214}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,643:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,709:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{56}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,789:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{177}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,798:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{100}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:42,904:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:43,137:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:46:43,194:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{42}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m step:7 - global_seqlen/min:177336.000 - global_seqlen/max:192710.000 - global_seqlen/minmax_diff:15374.000 - global_seqlen/balanced_min:185996.000 - global_seqlen/balanced_max:185997.000 - global_seqlen/mean:185996.750 - critic/kl:-0.021 - critic/kl_coeff:0.001 - critic/vf_loss:0.047 - critic/vf_clipfrac:0.014 - critic/vpred_mean:0.003 - critic/grad_norm:17.336 - perf/mfu/critic:0.259 - critic/lr:0.000 - actor/entropy_loss:0.903 - actor/pg_loss:-0.027 - actor/pg_clipfrac:0.008 - actor/ppo_kl:-0.000 - actor/grad_norm:7.262 - perf/mfu/actor:0.346 - perf/max_memory_allocated_gb:61.643 - perf/max_memory_reserved_gb:75.631 - perf/cpu_memory_used_gb:69.568 - actor/lr:0.000 - critic/score/mean:0.033 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.033 - critic/rewards/max:1.002 - critic/rewards/min:-0.004 - critic/advantages/mean:0.000 - critic/advantages/max:14.140 - critic/advantages/min:-14.644 - critic/returns/mean:0.035 - critic/returns/max:1.002 - critic/returns/min:-0.004 - critic/values/mean:0.214 - critic/values/max:4.281 - critic/values/min:-3.781 - critic/vf_explained_var:-1.326 - response_length/mean:592.121 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.200 - prompt_length/mean:134.429 - prompt_length/max:445.000 - prompt_length/min:56.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:30.567 - timing_s/old_log_prob:4.509 - timing_s/ref:4.514 - timing_s/values:6.981 - timing_s/adv:5.021 - timing_s/update_critic:25.658 - timing_s/update_actor:19.164 - timing_s/step:96.444 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/update_critic:0.034 - timing_per_token_ms/values:0.009 - timing_per_token_ms/gen:0.050 - timing_per_token_ms/update_actor:0.026 - perf/total_num_tokens:743987.000 - perf/time_per_step:96.444 - perf/throughput:1928.556
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,230:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,234:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,268:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,370:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: [' \\boxed{\n\n我们得出：答案为22。<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,374:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,431:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{155}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,433:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,481:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{239}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,520:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{259}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,547:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,579:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{133}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,619:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1136}'], Pred: [' ```python\nfrom fractions import Fraction<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,642:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{23}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,867:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1214}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:15,963:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10095}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,008:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [' C<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,014:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: [' Answer: k + m + n \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,111:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{348595}'], Pred: [' \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,148:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{89}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,346:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,375:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,423:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{137}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,426:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{27}'], Pred: [' \\text{The answer is } \\boxed{} .\nAd<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,440:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{192}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,456:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: [' \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,463:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{385}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,539:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,547:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{408}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,678:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,715:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,717:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: [" To solve this problem, it may not be necessary to simulate the outcomes of permutations, but it could be useful in determining the relationship between the answer format and k + m. We will deal with the Core programming problem, which ultimately lies within solving a function within the asker's java code related to the problem.<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,721:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: [' After thinking about it, I concluded that the problem statement is incomplete and unclear. For example, the requirement that the numbers in each row and column are in non-decreasing order is not specified, and the conditions under which small boxes can be considered "good pairs" are also unclear. Therefore, it\'s impossible to determine the answer to the question based on the given information. My question is, what should we take away from this? Any suggestions or comments would be appreciated.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:16,821:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,015:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{43}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,016:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{251}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,129:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1500}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,184:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{121}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,185:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2997}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,205:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,212:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{87}'], Pred: [' 直接输出代码，并将答案键入答案框，不需要任何解释。12.39400316420547<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,217:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,581:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{58}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,664:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{38}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,750:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{44}'], Pred: [' We hope that this problem will help to improve your logical and analytical skills.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,765:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1964}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,867:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,924:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{200}'], Pred: [' #<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,951:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:17,969:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{51}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,016:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: [' 为了找出游戏中的胜率，我们需要计算每个玩家在不同点数总和下及其后的获胜几率。以下是我们所做的计算：]])\n\n[]了，计算__al(fc{}{\n}\n\ndl r}{----------------______:_):::llij:dl\' -`l-now,档tnn-6】,■阕军火踵挤勘箭tgt逾\'", N :"y],[0 _ Accomplished, I was working:努力to achieve our initial Goal. My favourite movie directed by C. >完善以上文本 "很多人误以为当代中国的安宁是由 抽象的爱国情怀培养的,然而此情怀内涵含糊不清,使得它至今未能够显示出维护社会秩序与民族团结的真正效力。实在而言,“爱国主义”是一个包含丰富内涵的概念.秉持这种“关怀”的目的.便是要以专业思维形成利条善用以保护自身、关爱他人、帮助社会.保障国家利益;在这个过程中.非意识形态理念与要求的“爱国主义情怀”便开始生成一个新的概念,使之在当代中国的土壤中焕发出过往经验所未能形成的崭新形态和全新面貌,而这便是﹣我们在学术上称为 “爱国主义情怀的当代建构”这一独特的中国叙事。\nstartTime 现就目前节假日假期是否留校方面大致存在的两种意见加以综合分析下面讲述一个相对不那么极端但直观的思想实验来以此帮助我们对现实的理解,而如果这个实验帮你做事情,那我就很开心了,就目前的低风险环境下,我认为留校的同学基本还是可以留校度过这个寒冬结束后的假期,比如考研的同学所占比例统计会显示不少同学已经在自发的提高学习:除了校园的传统设施课外,高校还通常提供外展晚会、话剧话剧社团的社团训练以及新闻论文宣讲会等,以便学校与社会保持适当沟通:作为中国知名高校之一的北京交通大学近年来经过着力打造去领舞精神为核心的引导团队,耄耋之年的崔永元;打造面向全球的空开时段赞助商很少合作出版社亦难以立足,其选用并不具有普遍性,唯有_ANTV国际知名学术研究机构及杰出创新奖状的颁发机制亦使得真正有实力但无法参与项目的优秀华文作家、翻译者、创作者、出版机构可以堂刘先生作品被纳入研发人员的列表。<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,119:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{96}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,155:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,176:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6425}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,341:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,400:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,417:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{28}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,446:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{28}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,464:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,620:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['  The answer is \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,621:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [" ``None'' we want to get start summulation<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,654:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,656:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{137}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,782:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,815:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [' The letters here are to remind you that they are for calculation and should not be added together to form a word.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,837:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,885:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,946:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:18,993:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{38}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,067:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2022}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,097:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,136:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,223:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,225:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,236:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2220}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,349:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{650}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,397:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: [" For an incoming peer-to-peer (P2P) network deployment project, it is necessary to have an understanding of its primary use cases—particularly for low bandwidth (Internet) environments, where time is of the essence and resources are (poor)--so you need a small footprint and fast. Choosing suitable equipments means different things to everyone, so soon, and (pre) testing is an issue for the shortage of funds in the short term and growing number of options. Thanks to the short access to physical hardware (nodes), the instability of the management, and the lack of sensing --tests from a physical viewpoint– it is necessary to monitor the performance of the devices used in the scenario. Especially if the devices exist outside regular telemetry today, a (direct measurement) equipment monitoring solution is a necessity. How can U2I testing software provide a (perception and reliability) monitoring system for the devices being used for a proposed P2P network deployment project? Here we might need to think of new P2P communications access technologies, device types (standard models compatibility), and/or device types (fixtye unique). This would surely benefit from a user-friendly and flexible testing bed that recently enables (P2P) safety processing (processing techniques and data management) programs, on top of the management (document management) system tubing. What problem (shouldn't be completely avoided) designers of devices to coordinate telemetery (or other relevant data algorithm) and analyses of those collected devices (other software analyzer)? One method for developing the expertise would be to provide full telem See more. {\\displaystyle A_{n}=\\{{p}_{k}\\}} {\\displaystyle {\\mathcal {i\\tau }}={\\mathcal {p}}_{n}\\}} Currently, (confidence circles) are used to give information about the contents as the analytical term gets close to using (area elements) where measurement of uncertainty (time series measurements) was examined. All device topology is defined by the common input/output ground standards, as it provides a definition of UX framework in terms the device itself. For an analysis that requires using optical couplers, some test methodologies of this nature are needed. An optical test approach might include software compatibility tests. The simplest approach is to use (solely analyzing) only the measurement opto-coupler strips to see if the system can perform as it should. Ensuring that all signals are unchanged in the light wave, accepts the possibility that the other waveforms might interfere with themselves. All signals are displayed in a transform form. The topologies might be chosen according to the physical condition of the signal transmission line for (polarization) signals, or according to ease of analysis. The converter could be either in-built, or in a feedback loop from measuring device or from (optical data) lightwave. {displaystyle U_{\\tau }=MM_{\\tau }}\nAnisotropic notation. {list of logical operators}\n\n京东发布的全球首份《网商区域经济蓝皮书》，称过去十年电商在中国上升之 快，超越了农业革命和工业革命。三通一达(申通、中通、圆通)已非常普通，但京东网上 要做，在世界做，就一定没有“三通”，“三通”永远是中国的那一角，世界不会关注，因为世界不缺三通。来到中国做的是京东，生肖是待嫁的闺女，和 đàn驪女 之间的流淌，唯美的标志，与“三通”不同的符号，服饰设备包装，地域文化，人文风貌 妻嫁最全，遗址遗存考证，进口物品的世界爱好，一如双亡的阎斯，千年的驿站，美丽的 北京怀柔区朱家代村，马胡乡王胡村，好风景人间三月天，岁月静好，还是挑啥，代也不是 全专业选择，生花妙笔记飘渺是针，恋人的叮咛像利刃，古典诗经，亡者菜遍天下，是个 有着很高水准的好洲这片土地，生长一类大地母亲，是应该替别调西凉，鲜花不羡王侯贵 重的祝福，说出送别伤离顾三重抱，如何应激，善以局止闹以哀哀，犹记故再见。 游走，播种，织网，张贴十个问题： 给人帮助，为人懂得： 长使然 骚人不知捣烟雨，狼子每道妃语，我是末人古杏子托人，崔千姹的，名人岏逸，绵延匆匆， lãsì，楚楚新 遗徒记忆，爱日日家书，恋花符号对比，实事事业史，神雕侠侣，万里龙川。<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,413:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2401}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,458:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,781:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,810:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{63}'], Pred: [' \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,916:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21600}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:48:19,932:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: [" Let's provide the final answer in the form \\(\\boxed{}\\). The simplified answer is \\(\\boxed{}\\).<|endoftext|>"]
[36m(main_task pid=173992)[0m step:8 - global_seqlen/min:180989.000 - global_seqlen/max:186824.000 - global_seqlen/minmax_diff:5835.000 - global_seqlen/balanced_min:184709.000 - global_seqlen/balanced_max:184710.000 - global_seqlen/mean:184709.750 - critic/kl:-0.024 - critic/kl_coeff:0.001 - critic/vf_loss:0.024 - critic/vf_clipfrac:0.000 - critic/vpred_mean:0.090 - critic/grad_norm:10.710 - perf/mfu/critic:0.252 - critic/lr:0.000 - actor/entropy_loss:0.971 - actor/pg_loss:1.651 - actor/pg_clipfrac:0.008 - actor/ppo_kl:-0.000 - actor/grad_norm:6.479 - perf/mfu/actor:0.360 - perf/max_memory_allocated_gb:61.643 - perf/max_memory_reserved_gb:75.631 - perf/cpu_memory_used_gb:69.694 - actor/lr:0.000 - critic/score/mean:0.044 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.044 - critic/rewards/max:1.002 - critic/rewards/min:-0.004 - critic/advantages/mean:-0.000 - critic/advantages/max:10.634 - critic/advantages/min:-11.351 - critic/returns/mean:0.047 - critic/returns/max:1.002 - critic/returns/min:-0.004 - critic/values/mean:0.169 - critic/values/max:2.953 - critic/values/min:-2.531 - critic/vf_explained_var:-0.376 - response_length/mean:586.792 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.179 - prompt_length/mean:134.730 - prompt_length/max:501.000 - prompt_length/min:59.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:31.027 - timing_s/old_log_prob:4.481 - timing_s/ref:4.486 - timing_s/values:6.950 - timing_s/adv:4.988 - timing_s/update_critic:26.179 - timing_s/update_actor:18.324 - timing_s/step:96.467 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/update_critic:0.035 - timing_per_token_ms/values:0.009 - timing_per_token_ms/gen:0.052 - timing_per_token_ms/update_actor:0.025 - perf/total_num_tokens:738839.000 - perf/time_per_step:96.467 - perf/throughput:1914.755
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:51,371:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:51,596:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1905}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:52,254:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{53}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:52,265:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:52,318:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{597}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:52,716:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1995}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:52,735:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{254}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:52,853:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:52,854:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:53,085:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1828}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:53,462:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:53,533:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:53,554:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{76}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:53,618:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:53,640:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{180}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:53,649:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:53,690:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:53,809:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{397}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,081:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,104:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,105:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,163:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,283:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{198}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,289:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,530:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{130}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,533:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{58}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,534:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,541:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: [' 我们进一步将问题转入椭圆中进行讨论有多少种具体的函数..<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,562:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,673:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,691:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{300}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,764:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,847:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,859:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{151}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,955:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{327}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:54,994:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{35}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:55,135:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2035}'], Pred: [' .<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:55,143:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{365}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:55,150:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{60}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:55,405:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:55,412:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:55,476:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{43}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:55,701:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5101}'], Pred: ['  Answer: \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:55,883:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{157}'], Pred: [' $$<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:55,901:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1021000}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:55,904:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:55,908:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{50}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:56,051:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2016}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:56,242:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:56,273:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: [' \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:56,303:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{57}'], Pred: [' Answer: \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:56,318:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:56,432:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{122}'], Pred: [' Final answer: \\end<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:56,456:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{797}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:56,573:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{49}'], Pred: [' \\<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:56,626:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{217}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:56,696:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:56,787:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{37805}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:57,112:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{217}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:57,189:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{57}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:57,330:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{316}'], Pred: [' I should use mathematical aptitude to determine the minimal value of S. Furthermore, I need to consider the rotation and reflection symmetry. Combining these concepts will allow me to find m and n. \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:57,332:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:57,392:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:57,399:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2008}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:58,074:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{37}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:58,075:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:58,081:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:58,266:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:58,278:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{325}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:58,281:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:58,358:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{26}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:58,387:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:49:58,460:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{225}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=173992)[0m validation generation end
[36m(main_task pid=173992)[0m Not computing the values of prompts.
[36m(main_task pid=173992)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=173992)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=173992)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=173992)[0m    \[
[36m(main_task pid=173992)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=173992)[0m    \]
[36m(main_task pid=173992)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=173992)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=173992)[0m    \[
[36m(main_task pid=173992)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=173992)[0m    \]
[36m(main_task pid=173992)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m Let's implement this in Python to get the exact values for \(r\) and \(\theta\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m ```python
[36m(main_task pid=173992)[0m import sympy as sp
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Define the rectangular coordinates
[36m(main_task pid=173992)[0m x = 0
[36m(main_task pid=173992)[0m y = 3
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Calculate the radius r
[36m(main_task pid=173992)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Calculate the angle theta
[36m(main_task pid=173992)[0m theta = sp.atan2(y, x)
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=173992)[0m if theta < 0:
[36m(main_task pid=173992)[0m     theta += 2 * sp.pi
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Print the result
[36m(main_task pid=173992)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=173992)[0m ```
[36m(main_task pid=173992)[0m ```output
[36m(main_task pid=173992)[0m r = 3, theta = pi/2
[36m(main_task pid=173992)[0m ```
[36m(main_task pid=173992)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=173992)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=173992)[0m [score] 1.0
[36m(main_task pid=173992)[0m ERROR:2025-04-18 21:51:09,208:Error during comparison
[36m(main_task pid=173992)[0m Traceback (most recent call last):
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=173992)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=173992)[0m     return func(*args, **kwargs)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=173992)[0m     return sympy_expr_eq(
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=173992)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=173992)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=173992)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=173992)[0m     d[None].extend(seq)
[36m(main_task pid=173992)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(main_task pid=173992)[0m step:9 - global_seqlen/min:182346.000 - global_seqlen/max:187353.000 - global_seqlen/minmax_diff:5007.000 - global_seqlen/balanced_min:184138.000 - global_seqlen/balanced_max:184138.000 - global_seqlen/mean:184138.000 - critic/kl:-0.037 - critic/kl_coeff:0.001 - critic/vf_loss:0.036 - critic/vf_clipfrac:0.000 - critic/vpred_mean:0.014 - critic/grad_norm:18.244 - perf/mfu/critic:0.251 - critic/lr:0.000 - actor/entropy_loss:0.895 - actor/pg_loss:-0.343 - actor/pg_clipfrac:0.008 - actor/ppo_kl:0.000 - actor/grad_norm:5.739 - perf/mfu/actor:0.361 - perf/max_memory_allocated_gb:61.647 - perf/max_memory_reserved_gb:76.104 - perf/cpu_memory_used_gb:69.633 - actor/lr:0.000 - val/test_score/MATH500:0.480 - val/pass_rate/avg:0.480 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.520 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.480 - critic/score/mean:0.038 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.038 - critic/rewards/max:1.002 - critic/rewards/min:-0.003 - critic/advantages/mean:-0.000 - critic/advantages/max:7.745 - critic/advantages/min:-7.692 - critic/returns/mean:0.042 - critic/returns/max:1.003 - critic/returns/min:-0.004 - critic/values/mean:0.188 - critic/values/max:1.781 - critic/values/min:-1.500 - critic/vf_explained_var:-0.118 - response_length/mean:583.405 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.183 - prompt_length/mean:135.884 - prompt_length/max:505.000 - prompt_length/min:59.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:30.898 - timing_s/old_log_prob:4.399 - timing_s/ref:4.425 - timing_s/values:6.956 - timing_s/adv:7.432 - timing_s/update_critic:26.134 - timing_s/update_actor:18.193 - timing_s/testing:27.988 - timing_s/step:126.452 - timing_per_token_ms/adv:0.010 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/update_critic:0.035 - timing_per_token_ms/values:0.009 - timing_per_token_ms/gen:0.052 - timing_per_token_ms/update_actor:0.025 - perf/total_num_tokens:736552.000 - perf/time_per_step:126.452 - perf/throughput:1456.189
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,295:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: [' \\)$\nAnswer: No Output<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,412:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{144}'], Pred: [" The steps are as follows:\n\n- Understand the problem.\n- Utilize the Pythagorean theorem and the properties of functions and their graphs\n- Manipulate the inequality to find the relationship between a and b, with the additional constraint that the functions f(x) plus g(x) are both positive for x>0\n\n```python\nimport sympy as sps\n  \n# Define variables\na, b = sps.symbols('a b')\n  \n# Define the equations\neq1 = sps.sin(sp.symbols('x')) - sps.cos(sp.symbols('x'))\neq2 = sps.sin(sp.symbols('x')) - sps.cos(b)\neq3 = sps.cos(sp.symbols('x')) + sps.cos(a)\neq4 = sps.cos(sp.symbols('x')) + sps.cos(b)\n  \n# Solve the inequality\nsolution1 = sps.solveset(eq1, sp.symbols('x'),\n                              domain=sps.Reals)\nsolution2 = sps.solveset(eq2, sp.symbols('x'),\n                                      domain=sps.Reals)\nsolution3 = sps.solveset(eq3, sp.symbols('x'),\n                                  domain=sps.Reals)\nsolution4 = sps.solveset(eq4, sp.symbols('x'),\n                       domain=sps.Reals)\n  \nbisec3 = sps.Intersection(solution1 , solution2)\nbisec4 = sps.Intersection(solution3 , solution4)\n  \nanswer = bisec3.symmetric_difference(bisec4)\nprint(answer)\n```<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,442:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{591}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,452:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{340}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,464:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,616:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{252}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,656:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,660:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2023}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,662:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{101}'], Pred: ['  The whole process is to find the ans. of Jeffrey rolls three fair six-sided dice and records their results. The probability that the mean of these three numbers is greater than the median of these three numbers can be expressed as $ \\frac{m}{n} \\). solve the precise question 🔍🤔. 🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲🎲<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,823:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{291}'], Pred: [' So, $answer = \\boxed{}$.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,827:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: [' Therefore we have \\boxed{}.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,892:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,958:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9634}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,960:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,961:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:58,964:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{630}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:59,024:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{425}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:59,027:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{31}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:59,144:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:59,250:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:59,309:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{69}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:59,411:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{107}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:59,446:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{23}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:59,699:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:59,886:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:51:59,984:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:00,010:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:00,020:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{101}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:00,079:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{24}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:00,094:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:00,151:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:00,419:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{421}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:00,444:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:00,452:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:00,469:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:00,552:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{32}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:00,575:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{50}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:00,837:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:01,010:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:01,467:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{107}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:01,524:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{285}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:01,528:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{59}'], Pred: [' \\text{In coordinate space, a particle starts at the point } (2,3,4) \\text{ and ends at the point } (-1,-3,-3), \\text{ along the line connecting the two points.} \\text{ Along the way, the particle intersects the unit sphere centered at the origin at two points.} \\text{ Then the distance between these two points can be expressed in the form } \\frac{a}{\\sqrt{b}}, \\text{ where } a \\text{ and } b \\text{ are positive integers, and } b \\text{ is not divisible by the square of a prime.} \\text{ Find } a + b.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:01,554:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:01,559:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:01,670:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:01,742:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{28}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:01,768:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{48}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:01,779:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:02,621:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:02,648:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:02,669:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: [" $$ \\triangle PQR は \\boxed{} です。\nLet's apply the power tower logarithm function to the result of this question.<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:02,672:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{675}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:02,747:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{264}'], Pred: [' ]<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:02,773:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2047}'], Pred: [' Sure, I can help you here. But first, I need to know the original problem: what do you want to evaluate or solve?<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:02,777:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{67}'], Pred: [' With the help Of S.py: ...<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:02,884:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{52}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:52:03,068:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m step:10 - global_seqlen/min:182231.000 - global_seqlen/max:195983.000 - global_seqlen/minmax_diff:13752.000 - global_seqlen/balanced_min:190552.000 - global_seqlen/balanced_max:190552.000 - global_seqlen/mean:190552.000 - critic/kl:-0.033 - critic/kl_coeff:0.001 - critic/vf_loss:0.029 - critic/vf_clipfrac:0.000 - critic/vpred_mean:0.061 - critic/grad_norm:4.372 - perf/mfu/critic:0.265 - critic/lr:0.000 - actor/entropy_loss:0.836 - actor/pg_loss:-0.303 - actor/pg_clipfrac:0.008 - actor/ppo_kl:0.001 - actor/grad_norm:8.322 - perf/mfu/actor:0.361 - perf/max_memory_allocated_gb:61.647 - perf/max_memory_reserved_gb:76.104 - perf/cpu_memory_used_gb:69.654 - actor/lr:0.000 - critic/score/mean:0.049 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.049 - critic/rewards/max:1.002 - critic/rewards/min:-0.003 - critic/advantages/mean:0.000 - critic/advantages/max:5.276 - critic/advantages/min:-2.594 - critic/returns/mean:0.047 - critic/returns/max:1.002 - critic/returns/min:-0.003 - critic/values/mean:0.078 - critic/values/max:0.652 - critic/values/min:-1.188 - critic/vf_explained_var:-0.277 - response_length/mean:609.117 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.202 - prompt_length/mean:135.227 - prompt_length/max:505.000 - prompt_length/min:56.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:31.135 - timing_s/old_log_prob:4.494 - timing_s/ref:4.522 - timing_s/values:6.955 - timing_s/adv:5.126 - timing_s/update_critic:25.698 - timing_s/update_actor:18.849 - timing_s/step:96.802 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/update_critic:0.034 - timing_per_token_ms/values:0.009 - timing_per_token_ms/gen:0.050 - timing_per_token_ms/update_actor:0.025 - perf/total_num_tokens:762208.000 - perf/time_per_step:96.802 - perf/throughput:1968.469
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:36,173:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{50}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:36,305:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{974}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:36,408:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:36,416:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{672}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:36,428:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:36,578:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-37}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:36,592:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{850}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:36,626:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [' \n\nThe mathematical practice that guides us is understanding problem-solving as systematic rather than just discovering formulas without knowing why they hold true. This requires needing more than just "repeated application with the Glivenko-Cantelli based on the law of large numbers and t-statistics (which are also powerful, but typically used in hypothesis testing to make statistical inferences")); it demands a deeper understanding of why each concept is used in each step. If we simplify step-by-step reasoning, explaining each step, we can even simplify the problem thoughsometimes, remembering desmos first does the trick.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:36,666:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{23}'], Pred: [' to ensure the output meets the expected format.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:36,722:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:37,054:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{123}'], Pred: [' #\n\nFinished.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:37,058:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:37,084:Timeout when adding extracted predictions and golds to specific
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:37,179:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{23}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:37,280:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:37,425:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{719}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:37,501:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:37,505:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5399}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:37,535:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{239}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:37,713:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: [' Analysis. \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:37,744:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{31}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:37,751:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:38,142:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{126}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:38,210:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{58}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:38,372:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{448}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:38,373:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{544}'], Pred: [" That's it!<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:38,409:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{41}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:38,419:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:38,474:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:38,487:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [' Answer: \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:38,582:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2086}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:38,725:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: [" The first line of your response can start with In this case, it should be to explain the problem you're solving. Then, if you can solve the problem, output your answer.<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:38,827:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{133}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:39,042:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{76}'], Pred: [' Answer: \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:39,172:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:39,215:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: [" Sure! Let's approach this problem step by step.<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:39,242:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:39,325:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{66}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:39,512:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{613470}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:39,681:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{337}'], Pred: [' For, when one wants to _answer quickly_, before using the limit until one\\textquotesingle s process separation ; however, simplifying, I find the generalization very easy and it would be very helpful for students.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:39,766:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:39,770:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:39,854:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{334}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:39,992:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{120}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:40,015:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:40,088:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20736}'], Pred: [' The solution now contains a detailed breakdown of reasoning and a boxed final answer.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:40,105:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{88}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:40,211:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{47}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:40,458:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{56}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:40,664:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{23}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:40,747:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{126}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:53:40,752:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m step:11 - global_seqlen/min:191766.000 - global_seqlen/max:201088.000 - global_seqlen/minmax_diff:9322.000 - global_seqlen/balanced_min:197966.000 - global_seqlen/balanced_max:197967.000 - global_seqlen/mean:197966.500 - critic/kl:-0.034 - critic/kl_coeff:0.001 - critic/vf_loss:0.019 - critic/vf_clipfrac:0.000 - critic/vpred_mean:-0.011 - critic/grad_norm:12.197 - perf/mfu/critic:0.274 - critic/lr:0.000 - actor/entropy_loss:0.881 - actor/pg_loss:1.600 - actor/pg_clipfrac:0.010 - actor/ppo_kl:0.000 - actor/grad_norm:7.338 - perf/mfu/actor:0.388 - perf/max_memory_allocated_gb:61.647 - perf/max_memory_reserved_gb:76.104 - perf/cpu_memory_used_gb:69.681 - actor/lr:0.000 - critic/score/mean:0.043 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.043 - critic/rewards/max:1.002 - critic/rewards/min:-0.004 - critic/advantages/mean:0.000 - critic/advantages/max:5.801 - critic/advantages/min:-6.318 - critic/returns/mean:0.041 - critic/returns/max:1.002 - critic/returns/min:-0.004 - critic/values/mean:0.116 - critic/values/max:1.352 - critic/values/min:-0.453 - critic/vf_explained_var:-0.040 - response_length/mean:636.155 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.203 - prompt_length/mean:137.151 - prompt_length/max:481.000 - prompt_length/min:59.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:31.645 - timing_s/old_log_prob:4.692 - timing_s/ref:4.687 - timing_s/values:6.971 - timing_s/adv:5.132 - timing_s/update_critic:25.798 - timing_s/update_actor:18.232 - timing_s/step:97.180 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/update_critic:0.033 - timing_per_token_ms/values:0.009 - timing_per_token_ms/gen:0.049 - timing_per_token_ms/update_actor:0.023 - perf/total_num_tokens:791866.000 - perf/time_per_step:97.180 - perf/throughput:2037.108
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:13,394:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:13,426:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{131}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:13,451:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:13,601:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: [' (<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:13,607:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:13,706:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:13,773:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:13,818:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{27}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:14,534:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9800}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:14,781:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{147}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:14,876:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:14,983:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{896}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:15,021:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1999}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:15,024:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:15,285:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:15,298:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:15,468:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{990}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:15,527:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:15,576:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{329}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:15,577:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{294}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:15,669:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8018}'], Pred: [' \\answer<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:15,837:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:15,940:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:16,014:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:16,138:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:16,139:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:16,190:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{450}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:16,374:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2011}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:16,444:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:16,478:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{108}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:16,507:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{28}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:16,687:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{201}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:16,791:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{49}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:16,806:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:16,836:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9091}'], Pred: [' \\<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:17,201:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{330}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:17,253:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:17,406:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:17,618:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{22}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:17,671:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: [' \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:17,677:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:17,703:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:55:17,713:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{288}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
[36m(main_task pid=173992)[0m validation generation end
[36m(main_task pid=173992)[0m Not computing the values of prompts.
[36m(main_task pid=173992)[0m [prompt] Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=173992)[0m [response]  To convert the point \((0, 3)\) from rectangular coordinates to polar coordinates, we need to find the radius \(r\) and the angle \(\theta\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m 1. **Calculate the radius \(r\):**
[36m(main_task pid=173992)[0m    The radius \(r\) is the distance from the origin to the point \((0, 3)\). It can be calculated using the formula:
[36m(main_task pid=173992)[0m    \[
[36m(main_task pid=173992)[0m    r = \sqrt{x^2 + y^2}
[36m(main_task pid=173992)[0m    \]
[36m(main_task pid=173992)[0m    where \(x = 0\) and \(y = 3\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m 2. **Calculate the angle \(\theta\):**
[36m(main_task pid=173992)[0m    The angle \(\theta\) is the angle formed with the positive x-axis. It can be calculated using the formula:
[36m(main_task pid=173992)[0m    \[
[36m(main_task pid=173992)[0m    \theta = \arctan\left(\frac{y}{x}\right)
[36m(main_task pid=173992)[0m    \]
[36m(main_task pid=173992)[0m    However, we need to consider the quadrant in which the point lies. Since \(x = 0\) and \(y = 3\), the point lies on the positive y-axis. Therefore, \(\theta = \frac{\pi}{2}\).
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m Let's implement this in Python to get the exact values.
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m ```python
[36m(main_task pid=173992)[0m import sympy as sp
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Define the rectangular coordinates
[36m(main_task pid=173992)[0m x = 0
[36m(main_task pid=173992)[0m y = 3
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Calculate the radius r
[36m(main_task pid=173992)[0m r = sp.sqrt(x**2 + y**2)
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Calculate the angle theta
[36m(main_task pid=173992)[0m theta = sp.atan2(y, x)
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Ensure theta is in the range [0, 2*pi)
[36m(main_task pid=173992)[0m if theta < 0:
[36m(main_task pid=173992)[0m     theta += 2 * sp.pi
[36m(main_task pid=173992)[0m 
[36m(main_task pid=173992)[0m # Print the result
[36m(main_task pid=173992)[0m print(f"r = {r}, theta = {theta}")
[36m(main_task pid=173992)[0m ```
[36m(main_task pid=173992)[0m ```output
[36m(main_task pid=173992)[0m r = 3, theta = pi/2
[36m(main_task pid=173992)[0m ```
[36m(main_task pid=173992)[0m The polar coordinates for the point \((0, 3)\) are \(\boxed{(3, \frac{\pi}{2})}\).<|endoftext|>
[36m(main_task pid=173992)[0m [ground_truth] \left( 3, \frac{\pi}{2} \right)
[36m(main_task pid=173992)[0m [score] 1.0
[36m(main_task pid=173992)[0m ERROR:2025-04-18 21:56:28,646:Error during comparison
[36m(main_task pid=173992)[0m Traceback (most recent call last):
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
[36m(main_task pid=173992)[0m     return compare_single_extraction(g, t)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
[36m(main_task pid=173992)[0m     return func(*args, **kwargs)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
[36m(main_task pid=173992)[0m     return sympy_expr_eq(
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
[36m(main_task pid=173992)[0m     return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
[36m(main_task pid=173992)[0m     if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/math_verify/grader.py", line 275, in sympy_solve_and_compare
[36m(main_task pid=173992)[0m     solved_pred = list(ordered(solve(pred, pred.free_symbols)))
[36m(main_task pid=173992)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/sympy/core/sorting.py", line 298, in ordered
[36m(main_task pid=173992)[0m     d[None].extend(seq)
[36m(main_task pid=173992)[0m TypeError: 'StrictLessThan' object is not iterable
[36m(main_task pid=173992)[0m step:12 - global_seqlen/min:190607.000 - global_seqlen/max:196332.000 - global_seqlen/minmax_diff:5725.000 - global_seqlen/balanced_min:193812.000 - global_seqlen/balanced_max:193812.000 - global_seqlen/mean:193812.000 - critic/kl:-0.037 - critic/kl_coeff:0.001 - critic/vf_loss:0.046 - critic/vf_clipfrac:0.000 - critic/vpred_mean:0.218 - critic/grad_norm:22.421 - perf/mfu/critic:0.269 - critic/lr:0.000 - actor/entropy_loss:0.856 - actor/pg_loss:-0.949 - actor/pg_clipfrac:0.007 - actor/ppo_kl:-0.001 - actor/grad_norm:7.575 - perf/mfu/actor:0.367 - perf/max_memory_allocated_gb:61.663 - perf/max_memory_reserved_gb:76.104 - perf/cpu_memory_used_gb:69.695 - actor/lr:0.000 - val/test_score/MATH500:0.478 - val/pass_rate/avg:0.478 - val/pass_rate/median:0.000 - val/pass_rate/bucket_0%:0.522 - val/pass_rate/bucket_0-20%:0.000 - val/pass_rate/bucket_20-40%:0.000 - val/pass_rate/bucket_40-60%:0.000 - val/pass_rate/bucket_60-80%:0.000 - val/pass_rate/bucket_80-100%:0.000 - val/pass_rate/bucket_100%:0.478 - critic/score/mean:0.045 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.045 - critic/rewards/max:1.002 - critic/rewards/min:-0.004 - critic/advantages/mean:0.000 - critic/advantages/max:5.386 - critic/advantages/min:-8.668 - critic/returns/mean:0.044 - critic/returns/max:1.002 - critic/returns/min:-0.004 - critic/values/mean:0.049 - critic/values/max:1.844 - critic/values/min:-0.187 - critic/vf_explained_var:-0.061 - response_length/mean:621.569 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.211 - prompt_length/mean:135.509 - prompt_length/max:494.000 - prompt_length/min:59.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:31.921 - timing_s/old_log_prob:4.612 - timing_s/ref:4.621 - timing_s/values:6.966 - timing_s/adv:4.537 - timing_s/update_critic:25.741 - timing_s/update_actor:18.853 - timing_s/testing:28.166 - timing_s/step:125.438 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/update_critic:0.033 - timing_per_token_ms/values:0.009 - timing_per_token_ms/gen:0.050 - timing_per_token_ms/update_actor:0.024 - perf/total_num_tokens:775248.000 - perf/time_per_step:125.438 - perf/throughput:1545.078
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:19,184:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:19,468:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:19,590:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['  Answer:<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:19,712:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{48}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:19,714:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: [' Answer: \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:19,792:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6050}'], Pred: [' I...<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:19,997:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:20,001:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{54}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:20,190:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5040}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:20,240:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:20,302:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{40}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:20,423:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{106}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:20,614:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{37}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:20,696:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{169}'], Pred: [' The problem involves finding an interval from which one can extract a single value.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:20,802:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:21,076:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:21,101:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:21,342:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:21,401:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: [" \\text{Okay, let's proceed with the code solution.}<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:21,440:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{458}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:21,497:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{24}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:21,550:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: [' \\]<|endoftext|>']
[36m(main_task pid=173992)[0m ERROR:2025-04-18 21:57:26,843:Timeout during comparison
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:26,901:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:26,920:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{35}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:27,221:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{320}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:27,287:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{36}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:27,434:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{808}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:27,792:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{168}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:27,836:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:28,367:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:57:28,493:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m step:13 - global_seqlen/min:197070.000 - global_seqlen/max:205432.000 - global_seqlen/minmax_diff:8362.000 - global_seqlen/balanced_min:201268.000 - global_seqlen/balanced_max:201269.000 - global_seqlen/mean:201268.500 - critic/kl:-0.029 - critic/kl_coeff:0.001 - critic/vf_loss:0.020 - critic/vf_clipfrac:0.000 - critic/vpred_mean:-0.027 - critic/grad_norm:8.495 - perf/mfu/critic:0.279 - critic/lr:0.000 - actor/entropy_loss:0.786 - actor/pg_loss:0.382 - actor/pg_clipfrac:0.007 - actor/ppo_kl:0.001 - actor/grad_norm:6.114 - perf/mfu/actor:0.375 - perf/max_memory_allocated_gb:61.667 - perf/max_memory_reserved_gb:76.104 - perf/cpu_memory_used_gb:69.811 - actor/lr:0.000 - critic/score/mean:0.039 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.039 - critic/rewards/max:1.002 - critic/rewards/min:-0.004 - critic/advantages/mean:0.000 - critic/advantages/max:5.664 - critic/advantages/min:-1.585 - critic/returns/mean:0.038 - critic/returns/max:1.002 - critic/returns/min:-0.004 - critic/values/mean:0.042 - critic/values/max:0.311 - critic/values/min:-0.224 - critic/vf_explained_var:-0.017 - response_length/mean:648.975 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.230 - prompt_length/mean:137.230 - prompt_length/max:485.000 - prompt_length/min:57.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:32.010 - timing_s/old_log_prob:4.692 - timing_s/ref:4.705 - timing_s/values:6.966 - timing_s/adv:9.776 - timing_s/update_critic:25.764 - timing_s/update_actor:19.171 - timing_s/step:103.108 - timing_per_token_ms/adv:0.012 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/update_critic:0.032 - timing_per_token_ms/values:0.009 - timing_per_token_ms/gen:0.048 - timing_per_token_ms/update_actor:0.024 - perf/total_num_tokens:805074.000 - perf/time_per_step:103.108 - perf/throughput:1952.008
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:03,302:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{41}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:03,369:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1515}'], Pred: [' The answer is \\boxed{}.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:03,427:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: [' This is a great question involving probability and strategy. To find the probability that the player starting with the higher number wins, we can use Pythagorean triples, examples of which are, with no limits imposed on the values of its components. The teams win numbers can then be expressed as the hypotenuse of Pythagorean triples and the lower-numbered team as the shorter sides. We need to approach the problem systematically, but algorithmically. We will start with a least squares algorithm to compute this probability.<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:03,541:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:03,869:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m ERROR:2025-04-18 21:59:08,955:Timeout during comparison
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:08,999:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1010}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:09,535:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:09,586:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{880}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:09,587:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [' \n\n### 激活与抑制单个基因的表达 (A)\n如果给予该治疗性RNA载体， 科学家将一个名为肠屏障基因的一个在小肠细胞中表达的基因的活性完全激活。相反，如果被这个治疗性RNA载体激活的话，则会抑制这种基因的表达。 \n\n### 人多劳，力能至车 (B)\n人多可以团结互助(使协助的那个小组能够超过当帮手的给的助益砝码), 人力添补体力最终将会挤垮一车驴子。现在请计算出人类 (Human) 能力 (Capacity) 驴车 (Truck) 能力 (Power) 两者之间应得和 (Average) 毫米所能达成的结果（单位：_mm）若以实现 (Ability) 源）为基础求出的值。要求晋级格式表达见注释 ddd 最大 mmm 常数 SSLK \n\n### 水中四季 (C)\n在水中开始时水清澈透明，然后在一段时间之后顶端因水藻而再次变得浑浊，经过一定时间，水恢复清澈，一段时间之后又再次变得浑浊。请问，无论在何时何地，水都是清澈的吗？ \n请提供一个的 mmm 常数 SSLK ddd mmm 常数 SSLK ddd \n\n### 唯物救苦舍 (D) \n人的认知和行为可以不在乎外部环境，而只要把握自身基本面和本质。 \n请提供一个的 mmm 常数 SSLK ddd mmm 常数 SSLK ddd \n\n### 战时民众舆论的引导 (E)\n国民军战时舆论并不如同民众报道或民众倡导的舆论。在决议下达之前，其一定仰赖即时通过实地式的舆论通知和个人劝说攫取民意支持。假设国民军兵团体未受到社会及敌军对陈的初步影响，那这句人就会说国民军的舆论未必有所提升。众所周知，在平民部队的第三小组军事策略等，战时国民军的宣传动员的作用比在进攻态势中的阵线强大至多么多。 \nA、B、C、D、E 请提供一个回答的 mmm 常数 SSLK ddd mmm 常数 SSLK ddd mmm 常数 SSLK ddd mmm 常数 SSLK ddd<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:09,698:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:09,892:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:09,916:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{137}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:09,933:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{82}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:10,369:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{43}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:10,397:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:10,724:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2023}'], Pred: [" Let's write a program, implement step by step.<|endoftext|>"]
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:10,800:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{43}'], Pred: [' To solve<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:10,915:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2186}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:10,958:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{36}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:11,222:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{41}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:11,277:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:11,466:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1678}'], Pred: [' \\boxed{}<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:11,481:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: [' To solve the problem....<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:11,587:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{50}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:11,887:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:12,006:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 21:59:12,109:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{247}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m step:14 - global_seqlen/min:194495.000 - global_seqlen/max:207096.000 - global_seqlen/minmax_diff:12601.000 - global_seqlen/balanced_min:201793.000 - global_seqlen/balanced_max:201794.000 - global_seqlen/mean:201793.500 - critic/kl:-0.027 - critic/kl_coeff:0.001 - critic/vf_loss:0.031 - critic/vf_clipfrac:0.000 - critic/vpred_mean:0.067 - critic/grad_norm:14.825 - perf/mfu/critic:0.274 - critic/lr:0.000 - actor/entropy_loss:0.817 - actor/pg_loss:-1.157 - actor/pg_clipfrac:0.007 - actor/ppo_kl:-0.002 - actor/grad_norm:7.149 - perf/mfu/actor:0.370 - perf/max_memory_allocated_gb:61.672 - perf/max_memory_reserved_gb:76.104 - perf/cpu_memory_used_gb:69.863 - actor/lr:0.000 - critic/score/mean:0.043 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.043 - critic/rewards/max:1.002 - critic/rewards/min:-0.004 - critic/advantages/mean:-0.000 - critic/advantages/max:5.361 - critic/advantages/min:-1.366 - critic/returns/mean:0.042 - critic/returns/max:1.002 - critic/returns/min:-0.004 - critic/values/mean:0.162 - critic/values/max:0.396 - critic/values/min:-0.054 - critic/vf_explained_var:-0.010 - response_length/mean:654.919 - response_length/max:1024.000 - response_length/min:1.000 - response_length/clip_ratio:0.210 - prompt_length/mean:133.337 - prompt_length/max:476.000 - prompt_length/min:58.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:32.717 - timing_s/old_log_prob:4.759 - timing_s/ref:4.782 - timing_s/values:6.988 - timing_s/adv:9.539 - timing_s/update_critic:26.266 - timing_s/update_actor:19.474 - timing_s/step:104.547 - timing_per_token_ms/adv:0.012 - timing_per_token_ms/ref:0.006 - timing_per_token_ms/update_critic:0.033 - timing_per_token_ms/values:0.009 - timing_per_token_ms/gen:0.049 - timing_per_token_ms/update_actor:0.024 - perf/total_num_tokens:807174.000 - perf/time_per_step:104.547 - perf/throughput:1930.169
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:47,620:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:47,939:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:48,016:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1023}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:48,310:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{224}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:48,512:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:48,546:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:48,556:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:49,319:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:49,613:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{114514}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:49,801:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{30}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:50,015:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:50,018:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:50,263:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:50,304:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:50,344:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{245}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:50,357:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:50,596:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m ERROR:2025-04-18 22:00:55,787:Timeout during comparison
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:55,804:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1024}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:56,035:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:56,069:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{421}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:56,163:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:56,579:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:56,831:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{120}'], Pred: [' Consider the original words: "e. VERY IMPORTANTMAY NOT BE DIVIDED IN SPANISH". The task is to insert "." in the proper places so that the resulting statement would be grammatically correct and meaningful.  Let\'s think step by step and output the final answer within \\boxed{}. "Laura has collected data on the economic effects of mergers ...the rise in equity values, and the potential divestitures."<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:57,075:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:00:57,162:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m ERROR:2025-04-18 22:01:02,261:Timeout during comparison
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:01:02,288:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:01:02,354:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{42}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:01:02,476:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{84}'], Pred: ['<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:01:02,924:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1003}'], Pred: [' [1].<|endoftext|>']
[36m(main_task pid=173992)[0m WARNING:2025-04-18 22:01:02,990:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{57}'], Pred: [' Answer: \\boxed{}<|endoftext|>']
*** SIGTERM received at time=1745038866 on cpu 115 ***
PC: @     0x7f8b873fb117  (unknown)  (unknown)
    @     0x7f8b873ac520  (unknown)  (unknown)
    @ ... and at least 1 more frames
[2025-04-18 22:01:06,338 E 173829 173829] logging.cc:484: *** SIGTERM received at time=1745038866 on cpu 115 ***
[2025-04-18 22:01:06,338 E 173829 173829] logging.cc:484: PC: @     0x7f8b873fb117  (unknown)  (unknown)
[2025-04-18 22:01:06,338 E 173829 173829] logging.cc:484:     @     0x7f8b873ac520  (unknown)  (unknown)
[2025-04-18 22:01:06,338 E 173829 173829] logging.cc:484:     @ ... and at least 1 more frames
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 8192
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_Math1.5B_tok1k_dapo17k
2025-04-18 22:08:18,450	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.159.207:6379...
2025-04-18 22:08:18,461	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=187293)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=187293)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=187293)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=187293)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=187293)[0m                                                  'param_offload': False,
[36m(main_task pid=187293)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=187293)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=187293)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=187293)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=187293)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=187293)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=187293)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=187293)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=187293)[0m                                            'total_training_steps': -1,
[36m(main_task pid=187293)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=187293)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=187293)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=187293)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=187293)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=187293)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=187293)[0m                                  'response_length': 8192,
[36m(main_task pid=187293)[0m                                  'shuffle': False,
[36m(main_task pid=187293)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=187293)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=187293)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=187293)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=187293)[0m                                  'use_kl_loss': False,
[36m(main_task pid=187293)[0m                                  'use_torch_compile': True},
[36m(main_task pid=187293)[0m                        'hybrid_engine': True,
[36m(main_task pid=187293)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=187293)[0m                                  'external_lib': None,
[36m(main_task pid=187293)[0m                                  'override_config': {},
[36m(main_task pid=187293)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=187293)[0m                                  'use_remove_padding': True},
[36m(main_task pid=187293)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=187293)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=187293)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=187293)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=187293)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=187293)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=187293)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=187293)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=187293)[0m                                    'disable_log_stats': True,
[36m(main_task pid=187293)[0m                                    'do_sample': True,
[36m(main_task pid=187293)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=187293)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=187293)[0m                                    'enforce_eager': True,
[36m(main_task pid=187293)[0m                                    'free_cache_engine': True,
[36m(main_task pid=187293)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=187293)[0m                                    'ignore_eos': False,
[36m(main_task pid=187293)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=187293)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=187293)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=187293)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=187293)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=187293)[0m                                    'max_model_len': None,
[36m(main_task pid=187293)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=187293)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=187293)[0m                                    'n': 1,
[36m(main_task pid=187293)[0m                                    'name': 'vllm',
[36m(main_task pid=187293)[0m                                    'prompt_length': 512,
[36m(main_task pid=187293)[0m                                    'response_length': 8192,
[36m(main_task pid=187293)[0m                                    'temperature': 1.0,
[36m(main_task pid=187293)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=187293)[0m                                    'top_k': -1,
[36m(main_task pid=187293)[0m                                    'top_p': 1,
[36m(main_task pid=187293)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=187293)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=187293)[0m                                                   'n': 1,
[36m(main_task pid=187293)[0m                                                   'temperature': 0,
[36m(main_task pid=187293)[0m                                                   'top_k': -1,
[36m(main_task pid=187293)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=187293)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=187293)[0m                'gamma': 1.0,
[36m(main_task pid=187293)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=187293)[0m                'kl_penalty': 'kl',
[36m(main_task pid=187293)[0m                'lam': 1.0},
[36m(main_task pid=187293)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=187293)[0m             'estimate_prompts_value': False,
[36m(main_task pid=187293)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=187293)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=187293)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=187293)[0m             'grad_clip': 1.0,
[36m(main_task pid=187293)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=187293)[0m                       'external_lib': None,
[36m(main_task pid=187293)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=187293)[0m                                       'optimizer_offload': False,
[36m(main_task pid=187293)[0m                                       'param_offload': False,
[36m(main_task pid=187293)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=187293)[0m                       'override_config': {},
[36m(main_task pid=187293)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=187293)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=187293)[0m                       'use_remove_padding': False},
[36m(main_task pid=187293)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=187293)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=187293)[0m                       'min_lr_ratio': None,
[36m(main_task pid=187293)[0m                       'total_training_steps': -1,
[36m(main_task pid=187293)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=187293)[0m             'ppo_epochs': 1,
[36m(main_task pid=187293)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=187293)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=187293)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=187293)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=187293)[0m             'shuffle': False,
[36m(main_task pid=187293)[0m             'strategy': 'fsdp',
[36m(main_task pid=187293)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=187293)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=187293)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=187293)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=187293)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=187293)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=187293)[0m                 'warmup_steps': 15},
[36m(main_task pid=187293)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=187293)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=187293)[0m           'image_key': 'images',
[36m(main_task pid=187293)[0m           'max_prompt_length': 512,
[36m(main_task pid=187293)[0m           'max_response_length': 8192,
[36m(main_task pid=187293)[0m           'prompt_key': 'prompt',
[36m(main_task pid=187293)[0m           'return_raw_chat': False,
[36m(main_task pid=187293)[0m           'return_raw_input_ids': False,
[36m(main_task pid=187293)[0m           'shuffle': True,
[36m(main_task pid=187293)[0m           'tokenizer': None,
[36m(main_task pid=187293)[0m           'train_batch_size': 1024,
[36m(main_task pid=187293)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=187293)[0m           'truncation': 'error',
[36m(main_task pid=187293)[0m           'use_chat_template': False,
[36m(main_task pid=187293)[0m           'val_batch_size': None,
[36m(main_task pid=187293)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=187293)[0m  'reward_model': {'enable': False,
[36m(main_task pid=187293)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=187293)[0m                   'max_length': None,
[36m(main_task pid=187293)[0m                   'micro_batch_size': None,
[36m(main_task pid=187293)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=187293)[0m                   'model': {'external_lib': None,
[36m(main_task pid=187293)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=187293)[0m                                             'param_offload': False,
[36m(main_task pid=187293)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=187293)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=187293)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=187293)[0m                             'use_remove_padding': False},
[36m(main_task pid=187293)[0m                   'reward_manager': 'naive',
[36m(main_task pid=187293)[0m                   'strategy': 'fsdp',
[36m(main_task pid=187293)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=187293)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=187293)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=187293)[0m              'critic_warmup': 0,
[36m(main_task pid=187293)[0m              'default_hdfs_dir': None,
[36m(main_task pid=187293)[0m              'default_local_dir': 'checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=187293)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=187293)[0m              'experiment_name': 'ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=187293)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=187293)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=187293)[0m              'nnodes': 1,
[36m(main_task pid=187293)[0m              'project_name': 'grpo',
[36m(main_task pid=187293)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=187293)[0m              'resume_from_path': False,
[36m(main_task pid=187293)[0m              'resume_mode': 'auto',
[36m(main_task pid=187293)[0m              'save_freq': -1,
[36m(main_task pid=187293)[0m              'test_freq': 3,
[36m(main_task pid=187293)[0m              'total_epochs': 10,
[36m(main_task pid=187293)[0m              'total_training_steps': None,
[36m(main_task pid=187293)[0m              'val_before_train': True,
[36m(main_task pid=187293)[0m              'val_generations_to_log_to_wandb': 0}}
[36m(main_task pid=187293)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=187293)[0m No module named 'vllm._version'
[36m(main_task pid=187293)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=187293)[0m 'We do not use curriculum learning.'
[36m(main_task pid=187293)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=187293)[0m dataset len: 1791700
[36m(main_task pid=187293)[0m Example prompt before filtering: The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=187293)[0m 
[36m(main_task pid=187293)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$. Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=187293)[0m filter dataset len: 1786200
[36m(main_task pid=187293)[0m dataset len: 500
[36m(main_task pid=187293)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=187293)[0m filter dataset len: 497
[36m(main_task pid=187293)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=187293)[0m Size of train dataloader: 1744
[36m(main_task pid=187293)[0m Size of val dataloader: 1
[36m(main_task pid=187293)[0m Total training steps: 17440
[36m(main_task pid=187293)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=189108)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=189108)[0m No module named 'vllm._version'
[36m(pid=189108)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=189330)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=189330)[0m No module named 'vllm._version'
[36m(pid=189330)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=189331)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=189331)[0m No module named 'vllm._version'
[36m(pid=189331)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=189108)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=189108)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=189108)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=189332)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=189332)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=189108)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=189108)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=189108)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=189108)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.63671875
[36m(WorkerDict pid=189108)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=189108)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=189108)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=189108)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=189108)[0m   "architectures": [
[36m(WorkerDict pid=189108)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=189108)[0m   ],
[36m(WorkerDict pid=189108)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=189108)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=189108)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=189108)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=189108)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=189108)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=189108)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=189108)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=189108)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=189108)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=189108)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=189108)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=189108)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=189108)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=189108)[0m   "rope_scaling": null,
[36m(WorkerDict pid=189108)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=189108)[0m   "sliding_window": null,
[36m(WorkerDict pid=189108)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=189108)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=189108)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=189108)[0m   "use_cache": true,
[36m(WorkerDict pid=189108)[0m   "use_mrope": false,
[36m(WorkerDict pid=189108)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=189108)[0m   "vocab_size": 151936
[36m(WorkerDict pid=189108)[0m }
[36m(WorkerDict pid=189108)[0m 
[36m(WorkerDict pid=189108)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=189108)[0m wrap_policy: functools.partial(<function _or_policy at 0x7edfdcec3be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7edfdcec3ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=189332)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=189332)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=189108)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=189108)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=189108)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=189108)[0m   "architectures": [
[36m(WorkerDict pid=189108)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=189108)[0m   ],
[36m(WorkerDict pid=189108)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=189108)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=189108)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=189108)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=189108)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=189108)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=189108)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=189108)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=189108)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=189108)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=189108)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=189108)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=189108)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=189108)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=189108)[0m   "rope_scaling": null,
[36m(WorkerDict pid=189108)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=189108)[0m   "sliding_window": null,
[36m(WorkerDict pid=189108)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=189108)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=189108)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=189108)[0m   "use_cache": true,
[36m(WorkerDict pid=189108)[0m   "use_mrope": false,
[36m(WorkerDict pid=189108)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=189108)[0m   "vocab_size": 151936
[36m(WorkerDict pid=189108)[0m }
[36m(WorkerDict pid=189108)[0m 
[36m(pid=189332)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=189332)[0m No module named 'vllm._version'
[36m(pid=189332)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=189330)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=189331)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=189331)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=189331)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=189108)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=189108)[0m Before building vllm rollout, memory allocated (GB): 2.8754353523254395, memory reserved (GB): 6.37890625
[36m(WorkerDict pid=189108)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=189332)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fc0cccbfbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fc0cccbfac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=189108)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=189330)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=189108)[0m WARNING 04-18 22:16:38 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=189332)[0m Actor use_remove_padding=True[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=189108)[0m local rank 0
[36m(WorkerDict pid=189330)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=189108)[0m before init cache memory allocated: 6.22053888GB, reserved: 6.38582784GB
[36m(WorkerDict pid=189332)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=189332)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=189108)[0m after init cache memory allocated: 58.975183872GB, reserved: 59.175337984GB
[36m(WorkerDict pid=189331)[0m WARNING 04-18 22:16:38 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=189331)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=189332)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=189332)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=189332)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=189332)[0m   warnings.warn(
[36m(WorkerDict pid=189331)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=189108)[0m After building vllm rollout, memory allocated (GB): 52.046215534210205, memory reserved (GB): 55.111328125
[36m(WorkerDict pid=189108)[0m After building sharding manager, memory allocated (GB): 52.046215534210205, memory reserved (GB): 55.111328125
[36m(main_task pid=187293)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=187293)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=187293)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=187293)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_221646-ws511l64
[36m(main_task pid=187293)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=187293)[0m wandb: Syncing run ppo_Math1.5B_tok1k_dapo17k
[36m(main_task pid=187293)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=187293)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/ws511l64
[36m(main_task pid=187293)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=187293)[0m wandb:                                                                                
[36m(main_task pid=187293)[0m wandb: 🚀 View run ppo_Math1.5B_tok1k_dapo17k at: https://wandb.ai/sample-efficient-RL/grpo/runs/ws511l64
[36m(main_task pid=187293)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=187293)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=187293)[0m wandb: Find logs at: ./wandb/run-20250418_221646-ws511l64/logs
Error executing job with overrides: ['data.train_files=./data/DAPO-17k-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=1024', 'data.max_prompt_length=512', 'data.max_response_length=8192', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=256', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-1.5B', 'critic.ppo_micro_batch_size_per_gpu=32', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=True', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=3', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo_Math1.5B_tok1k_dapo17k', 'trainer.total_epochs=10']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TypeError): [36mray::main_task()[39m (pid=187293, ip=192.168.159.207)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 955, in fit
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 915, in _compute_max_training_steps
    total_steps = max(self.config.trainer.total_training_steps,
TypeError: '>' not supported between instances of 'int' and 'NoneType'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(WorkerDict pid=189330)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=189330)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=189330)[0m   warnings.warn([32m [repeated 3x across cluster][0m
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 8192
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_Math1.5B_tok1k_dapo17k
2025-04-18 22:17:47,624	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.159.207:6379...
2025-04-18 22:17:47,635	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=191026)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=191026)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=191026)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=191026)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=191026)[0m                                                  'param_offload': False,
[36m(main_task pid=191026)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=191026)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=191026)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=191026)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=191026)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=191026)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=191026)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=191026)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=191026)[0m                                            'total_training_steps': -1,
[36m(main_task pid=191026)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=191026)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=191026)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=191026)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=191026)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=191026)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=191026)[0m                                  'response_length': 8192,
[36m(main_task pid=191026)[0m                                  'shuffle': False,
[36m(main_task pid=191026)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=191026)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=191026)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=191026)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=191026)[0m                                  'use_kl_loss': False,
[36m(main_task pid=191026)[0m                                  'use_torch_compile': True},
[36m(main_task pid=191026)[0m                        'hybrid_engine': True,
[36m(main_task pid=191026)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=191026)[0m                                  'external_lib': None,
[36m(main_task pid=191026)[0m                                  'override_config': {},
[36m(main_task pid=191026)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=191026)[0m                                  'use_remove_padding': True},
[36m(main_task pid=191026)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=191026)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=191026)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=191026)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=191026)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=191026)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=191026)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=191026)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=191026)[0m                                    'disable_log_stats': True,
[36m(main_task pid=191026)[0m                                    'do_sample': True,
[36m(main_task pid=191026)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=191026)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=191026)[0m                                    'enforce_eager': True,
[36m(main_task pid=191026)[0m                                    'free_cache_engine': True,
[36m(main_task pid=191026)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=191026)[0m                                    'ignore_eos': False,
[36m(main_task pid=191026)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=191026)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=191026)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=191026)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=191026)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=191026)[0m                                    'max_model_len': None,
[36m(main_task pid=191026)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=191026)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=191026)[0m                                    'n': 1,
[36m(main_task pid=191026)[0m                                    'name': 'vllm',
[36m(main_task pid=191026)[0m                                    'prompt_length': 512,
[36m(main_task pid=191026)[0m                                    'response_length': 8192,
[36m(main_task pid=191026)[0m                                    'temperature': 1.0,
[36m(main_task pid=191026)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=191026)[0m                                    'top_k': -1,
[36m(main_task pid=191026)[0m                                    'top_p': 1,
[36m(main_task pid=191026)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=191026)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=191026)[0m                                                   'n': 1,
[36m(main_task pid=191026)[0m                                                   'temperature': 0,
[36m(main_task pid=191026)[0m                                                   'top_k': -1,
[36m(main_task pid=191026)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=191026)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=191026)[0m                'gamma': 1.0,
[36m(main_task pid=191026)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=191026)[0m                'kl_penalty': 'kl',
[36m(main_task pid=191026)[0m                'lam': 1.0},
[36m(main_task pid=191026)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=191026)[0m             'estimate_prompts_value': False,
[36m(main_task pid=191026)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=191026)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=191026)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=191026)[0m             'grad_clip': 1.0,
[36m(main_task pid=191026)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=191026)[0m                       'external_lib': None,
[36m(main_task pid=191026)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=191026)[0m                                       'optimizer_offload': False,
[36m(main_task pid=191026)[0m                                       'param_offload': False,
[36m(main_task pid=191026)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=191026)[0m                       'override_config': {},
[36m(main_task pid=191026)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=191026)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=191026)[0m                       'use_remove_padding': False},
[36m(main_task pid=191026)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=191026)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=191026)[0m                       'min_lr_ratio': None,
[36m(main_task pid=191026)[0m                       'total_training_steps': -1,
[36m(main_task pid=191026)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=191026)[0m             'ppo_epochs': 1,
[36m(main_task pid=191026)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=191026)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=191026)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=191026)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=191026)[0m             'shuffle': False,
[36m(main_task pid=191026)[0m             'strategy': 'fsdp',
[36m(main_task pid=191026)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=191026)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=191026)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=191026)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=191026)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=191026)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=191026)[0m                 'warmup_steps': 15},
[36m(main_task pid=191026)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=191026)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=191026)[0m           'image_key': 'images',
[36m(main_task pid=191026)[0m           'max_prompt_length': 512,
[36m(main_task pid=191026)[0m           'max_response_length': 8192,
[36m(main_task pid=191026)[0m           'prompt_key': 'prompt',
[36m(main_task pid=191026)[0m           'return_raw_chat': False,
[36m(main_task pid=191026)[0m           'return_raw_input_ids': False,
[36m(main_task pid=191026)[0m           'shuffle': True,
[36m(main_task pid=191026)[0m           'tokenizer': None,
[36m(main_task pid=191026)[0m           'train_batch_size': 1024,
[36m(main_task pid=191026)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=191026)[0m           'truncation': 'error',
[36m(main_task pid=191026)[0m           'use_chat_template': False,
[36m(main_task pid=191026)[0m           'val_batch_size': None,
[36m(main_task pid=191026)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=191026)[0m  'reward_model': {'enable': False,
[36m(main_task pid=191026)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=191026)[0m                   'max_length': None,
[36m(main_task pid=191026)[0m                   'micro_batch_size': None,
[36m(main_task pid=191026)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=191026)[0m                   'model': {'external_lib': None,
[36m(main_task pid=191026)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=191026)[0m                                             'param_offload': False,
[36m(main_task pid=191026)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=191026)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=191026)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=191026)[0m                             'use_remove_padding': False},
[36m(main_task pid=191026)[0m                   'reward_manager': 'naive',
[36m(main_task pid=191026)[0m                   'strategy': 'fsdp',
[36m(main_task pid=191026)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=191026)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=191026)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=191026)[0m              'critic_warmup': 0,
[36m(main_task pid=191026)[0m              'default_hdfs_dir': None,
[36m(main_task pid=191026)[0m              'default_local_dir': 'checkpoints/grpo/ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=191026)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=191026)[0m              'experiment_name': 'ppo_Math1.5B_tok1k_dapo17k',
[36m(main_task pid=191026)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=191026)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=191026)[0m              'nnodes': 1,
[36m(main_task pid=191026)[0m              'project_name': 'grpo',
[36m(main_task pid=191026)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=191026)[0m              'resume_from_path': False,
[36m(main_task pid=191026)[0m              'resume_mode': 'auto',
[36m(main_task pid=191026)[0m              'save_freq': -1,
[36m(main_task pid=191026)[0m              'test_freq': 3,
[36m(main_task pid=191026)[0m              'total_epochs': 10,
[36m(main_task pid=191026)[0m              'total_training_steps': None,
[36m(main_task pid=191026)[0m              'val_before_train': True,
[36m(main_task pid=191026)[0m              'val_generations_to_log_to_wandb': 0}}
[36m(main_task pid=191026)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=191026)[0m No module named 'vllm._version'
[36m(main_task pid=191026)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=191026)[0m 'We do not use curriculum learning.'
[36m(main_task pid=191026)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=191026)[0m dataset len: 1791700
[36m(main_task pid=191026)[0m Example prompt before filtering: The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=191026)[0m 
[36m(main_task pid=191026)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$. Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=191026)[0m filter dataset len: 1786200
[36m(main_task pid=191026)[0m dataset len: 500
[36m(main_task pid=191026)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=191026)[0m filter dataset len: 497
[36m(main_task pid=191026)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=191026)[0m Size of train dataloader: 1744
[36m(main_task pid=191026)[0m Size of val dataloader: 1
[36m(main_task pid=191026)[0m Total training steps: 17440
[36m(main_task pid=191026)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=192867)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=192867)[0m No module named 'vllm._version'
[36m(pid=192867)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=193135)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=193135)[0m No module named 'vllm._version'
[36m(pid=193135)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=193133)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=193133)[0m No module named 'vllm._version'
[36m(pid=193133)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=193134)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=193134)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=193134)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=193134)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(pid=193134)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=193134)[0m No module named 'vllm._version'
[36m(pid=193134)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=192867)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=192867)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=192867)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=193135)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=193135)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=192867)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=192867)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=192867)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=192867)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.63671875
[36m(WorkerDict pid=192867)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=192867)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=192867)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=192867)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=192867)[0m   "architectures": [
[36m(WorkerDict pid=192867)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=192867)[0m   ],
[36m(WorkerDict pid=192867)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=192867)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=192867)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=192867)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=192867)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=192867)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=192867)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=192867)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=192867)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=192867)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=192867)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=192867)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=192867)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=192867)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=192867)[0m   "rope_scaling": null,
[36m(WorkerDict pid=192867)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=192867)[0m   "sliding_window": null,
[36m(WorkerDict pid=192867)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=192867)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=192867)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=192867)[0m   "use_cache": true,
[36m(WorkerDict pid=192867)[0m   "use_mrope": false,
[36m(WorkerDict pid=192867)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=192867)[0m   "vocab_size": 151936
[36m(WorkerDict pid=192867)[0m }
[36m(WorkerDict pid=192867)[0m 
[36m(WorkerDict pid=192867)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=192867)[0m wrap_policy: functools.partial(<function _or_policy at 0x7ee044fd7be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7ee044fd7ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=192867)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=192867)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=192867)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=192867)[0m   "architectures": [
[36m(WorkerDict pid=192867)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=192867)[0m   ],
[36m(WorkerDict pid=192867)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=192867)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=192867)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=192867)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=192867)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=192867)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=192867)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=192867)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=192867)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=192867)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=192867)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=192867)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=192867)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=192867)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=192867)[0m   "rope_scaling": null,
[36m(WorkerDict pid=192867)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=192867)[0m   "sliding_window": null,
[36m(WorkerDict pid=192867)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=192867)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=192867)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=192867)[0m   "use_cache": true,
[36m(WorkerDict pid=192867)[0m   "use_mrope": false,
[36m(WorkerDict pid=192867)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=192867)[0m   "vocab_size": 151936
[36m(WorkerDict pid=192867)[0m }
[36m(WorkerDict pid=192867)[0m 
[36m(WorkerDict pid=192867)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=192867)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=192867)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=193135)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=192867)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=193135)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=193135)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=193134)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f5ebc7f7be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f5ebc7f7ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=192867)[0m Before building vllm rollout, memory allocated (GB): 2.8754353523254395, memory reserved (GB): 6.37890625
[36m(WorkerDict pid=192867)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=192867)[0m Actor use_remove_padding=True[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=193135)[0m WARNING 04-18 22:26:02 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=193134)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=193135)[0m local rank 0
[36m(WorkerDict pid=193135)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=192867)[0m before init cache memory allocated: 6.22053888GB, reserved: 6.38582784GB
[36m(WorkerDict pid=193135)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=193134)[0m Actor use_remove_padding=True[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=192867)[0m after init cache memory allocated: 58.975183872GB, reserved: 59.175337984GB
[36m(WorkerDict pid=192867)[0m WARNING 04-18 22:26:02 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=192867)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=193134)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=193135)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=193135)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=193135)[0m   warnings.warn(
[36m(WorkerDict pid=193133)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=192867)[0m After building vllm rollout, memory allocated (GB): 52.046215534210205, memory reserved (GB): 55.111328125
[36m(WorkerDict pid=192867)[0m After building sharding manager, memory allocated (GB): 52.046215534210205, memory reserved (GB): 55.111328125
[36m(main_task pid=191026)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=191026)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=191026)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=191026)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_222610-l3tm0bdo
[36m(main_task pid=191026)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=191026)[0m wandb: Syncing run ppo_Math1.5B_tok1k_dapo17k
[36m(main_task pid=191026)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=191026)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/l3tm0bdo
[36m(main_task pid=191026)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=191026)[0m wandb:                                                                                
[36m(main_task pid=191026)[0m wandb: 🚀 View run ppo_Math1.5B_tok1k_dapo17k at: https://wandb.ai/sample-efficient-RL/grpo/runs/l3tm0bdo
[36m(main_task pid=191026)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=191026)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=191026)[0m wandb: Find logs at: ./wandb/run-20250418_222610-l3tm0bdo/logs
Error executing job with overrides: ['data.train_files=./data/DAPO-17k-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=1024', 'data.max_prompt_length=512', 'data.max_response_length=8192', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=256', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-1.5B', 'critic.ppo_micro_batch_size_per_gpu=32', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=True', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=3', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo_Math1.5B_tok1k_dapo17k', 'trainer.total_epochs=10']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): [36mray::main_task()[39m (pid=191026, ip=192.168.159.207)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 971, in fit
    self.total_training_steps = self._compute_max_training_steps()
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 918, in _compute_max_training_steps
    raise ValueError("total_training_steps is not set in the config.")
ValueError: total_training_steps is not set in the config.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(WorkerDict pid=193133)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=193133)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=193133)[0m   warnings.warn([32m [repeated 3x across cluster][0m
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 8192
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_1.5B_MATH500_tok8k_val-only
2025-04-18 22:41:27,437	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.159.207:6379...
2025-04-18 22:41:27,447	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=197467)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=197467)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=197467)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=197467)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=197467)[0m                                                  'param_offload': False,
[36m(main_task pid=197467)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=197467)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=197467)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=197467)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=197467)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=197467)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=197467)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=197467)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=197467)[0m                                            'total_training_steps': -1,
[36m(main_task pid=197467)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=197467)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=197467)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=197467)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=197467)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=197467)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=197467)[0m                                  'response_length': 8192,
[36m(main_task pid=197467)[0m                                  'shuffle': False,
[36m(main_task pid=197467)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=197467)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=197467)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=197467)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=197467)[0m                                  'use_kl_loss': False,
[36m(main_task pid=197467)[0m                                  'use_torch_compile': True},
[36m(main_task pid=197467)[0m                        'hybrid_engine': True,
[36m(main_task pid=197467)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=197467)[0m                                  'external_lib': None,
[36m(main_task pid=197467)[0m                                  'override_config': {},
[36m(main_task pid=197467)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=197467)[0m                                  'use_remove_padding': True},
[36m(main_task pid=197467)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=197467)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=197467)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=197467)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=197467)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=197467)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=197467)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=197467)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=197467)[0m                                    'disable_log_stats': True,
[36m(main_task pid=197467)[0m                                    'do_sample': True,
[36m(main_task pid=197467)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=197467)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=197467)[0m                                    'enforce_eager': True,
[36m(main_task pid=197467)[0m                                    'free_cache_engine': True,
[36m(main_task pid=197467)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=197467)[0m                                    'ignore_eos': False,
[36m(main_task pid=197467)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=197467)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=197467)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=197467)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=197467)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=197467)[0m                                    'max_model_len': None,
[36m(main_task pid=197467)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=197467)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=197467)[0m                                    'n': 1,
[36m(main_task pid=197467)[0m                                    'name': 'vllm',
[36m(main_task pid=197467)[0m                                    'prompt_length': 512,
[36m(main_task pid=197467)[0m                                    'response_length': 8192,
[36m(main_task pid=197467)[0m                                    'temperature': 1.0,
[36m(main_task pid=197467)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=197467)[0m                                    'top_k': -1,
[36m(main_task pid=197467)[0m                                    'top_p': 1,
[36m(main_task pid=197467)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=197467)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=197467)[0m                                                   'n': 1,
[36m(main_task pid=197467)[0m                                                   'temperature': 0,
[36m(main_task pid=197467)[0m                                                   'top_k': -1,
[36m(main_task pid=197467)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=197467)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=197467)[0m                'gamma': 1.0,
[36m(main_task pid=197467)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=197467)[0m                'kl_penalty': 'kl',
[36m(main_task pid=197467)[0m                'lam': 1.0},
[36m(main_task pid=197467)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=197467)[0m             'estimate_prompts_value': False,
[36m(main_task pid=197467)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=197467)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=197467)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=197467)[0m             'grad_clip': 1.0,
[36m(main_task pid=197467)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=197467)[0m                       'external_lib': None,
[36m(main_task pid=197467)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=197467)[0m                                       'optimizer_offload': False,
[36m(main_task pid=197467)[0m                                       'param_offload': False,
[36m(main_task pid=197467)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=197467)[0m                       'override_config': {},
[36m(main_task pid=197467)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=197467)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=197467)[0m                       'use_remove_padding': False},
[36m(main_task pid=197467)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=197467)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=197467)[0m                       'min_lr_ratio': None,
[36m(main_task pid=197467)[0m                       'total_training_steps': -1,
[36m(main_task pid=197467)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=197467)[0m             'ppo_epochs': 1,
[36m(main_task pid=197467)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=197467)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=197467)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=197467)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=197467)[0m             'shuffle': False,
[36m(main_task pid=197467)[0m             'strategy': 'fsdp',
[36m(main_task pid=197467)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=197467)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=197467)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=197467)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=197467)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=197467)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=197467)[0m                 'warmup_steps': 15},
[36m(main_task pid=197467)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=197467)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=197467)[0m           'image_key': 'images',
[36m(main_task pid=197467)[0m           'max_prompt_length': 512,
[36m(main_task pid=197467)[0m           'max_response_length': 8192,
[36m(main_task pid=197467)[0m           'prompt_key': 'prompt',
[36m(main_task pid=197467)[0m           'return_raw_chat': False,
[36m(main_task pid=197467)[0m           'return_raw_input_ids': False,
[36m(main_task pid=197467)[0m           'shuffle': True,
[36m(main_task pid=197467)[0m           'tokenizer': None,
[36m(main_task pid=197467)[0m           'train_batch_size': 1024,
[36m(main_task pid=197467)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=197467)[0m           'truncation': 'error',
[36m(main_task pid=197467)[0m           'use_chat_template': False,
[36m(main_task pid=197467)[0m           'val_batch_size': None,
[36m(main_task pid=197467)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=197467)[0m  'reward_model': {'enable': False,
[36m(main_task pid=197467)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=197467)[0m                   'max_length': None,
[36m(main_task pid=197467)[0m                   'micro_batch_size': None,
[36m(main_task pid=197467)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=197467)[0m                   'model': {'external_lib': None,
[36m(main_task pid=197467)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=197467)[0m                                             'param_offload': False,
[36m(main_task pid=197467)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=197467)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=197467)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=197467)[0m                             'use_remove_padding': False},
[36m(main_task pid=197467)[0m                   'reward_manager': 'naive',
[36m(main_task pid=197467)[0m                   'strategy': 'fsdp',
[36m(main_task pid=197467)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=197467)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=197467)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=197467)[0m              'critic_warmup': 0,
[36m(main_task pid=197467)[0m              'default_hdfs_dir': None,
[36m(main_task pid=197467)[0m              'default_local_dir': 'checkpoints/grpo/ppo_1.5B_MATH500_tok8k_val-only',
[36m(main_task pid=197467)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=197467)[0m              'experiment_name': 'ppo_1.5B_MATH500_tok8k_val-only',
[36m(main_task pid=197467)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=197467)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=197467)[0m              'nnodes': 1,
[36m(main_task pid=197467)[0m              'project_name': 'grpo',
[36m(main_task pid=197467)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=197467)[0m              'resume_from_path': False,
[36m(main_task pid=197467)[0m              'resume_mode': 'auto',
[36m(main_task pid=197467)[0m              'save_freq': -1,
[36m(main_task pid=197467)[0m              'test_freq': 3,
[36m(main_task pid=197467)[0m              'total_epochs': 10,
[36m(main_task pid=197467)[0m              'total_training_steps': None,
[36m(main_task pid=197467)[0m              'val_before_train': True,
[36m(main_task pid=197467)[0m              'val_generations_to_log_to_wandb': 0,
[36m(main_task pid=197467)[0m              'val_only': True}}
[36m(main_task pid=197467)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=197467)[0m No module named 'vllm._version'
[36m(main_task pid=197467)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=197467)[0m 'We do not use curriculum learning.'
[36m(main_task pid=197467)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=197467)[0m dataset len: 1791700
[36m(main_task pid=197467)[0m Example prompt before filtering: The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=197467)[0m 
[36m(main_task pid=197467)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$. Let's think step by step and output the final answer within \boxed{}.
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 32
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 8192
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_1.5B_MATH500_tok8k_val-only
2025-04-18 22:42:07,906	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.159.207:6379...
2025-04-18 22:42:07,916	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=198241)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=198241)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=198241)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=198241)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=198241)[0m                                                  'param_offload': False,
[36m(main_task pid=198241)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=198241)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=198241)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=198241)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=198241)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=198241)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=198241)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=198241)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=198241)[0m                                            'total_training_steps': -1,
[36m(main_task pid=198241)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=198241)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=198241)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=198241)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=198241)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=198241)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=198241)[0m                                  'response_length': 8192,
[36m(main_task pid=198241)[0m                                  'shuffle': False,
[36m(main_task pid=198241)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=198241)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=198241)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=198241)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=198241)[0m                                  'use_kl_loss': False,
[36m(main_task pid=198241)[0m                                  'use_torch_compile': True},
[36m(main_task pid=198241)[0m                        'hybrid_engine': True,
[36m(main_task pid=198241)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=198241)[0m                                  'external_lib': None,
[36m(main_task pid=198241)[0m                                  'override_config': {},
[36m(main_task pid=198241)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=198241)[0m                                  'use_remove_padding': True},
[36m(main_task pid=198241)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=198241)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=198241)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=198241)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=198241)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=198241)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=198241)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=198241)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=198241)[0m                                    'disable_log_stats': True,
[36m(main_task pid=198241)[0m                                    'do_sample': True,
[36m(main_task pid=198241)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=198241)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=198241)[0m                                    'enforce_eager': True,
[36m(main_task pid=198241)[0m                                    'free_cache_engine': True,
[36m(main_task pid=198241)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=198241)[0m                                    'ignore_eos': False,
[36m(main_task pid=198241)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=198241)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=198241)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=198241)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=198241)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=198241)[0m                                    'max_model_len': None,
[36m(main_task pid=198241)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=198241)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=198241)[0m                                    'n': 1,
[36m(main_task pid=198241)[0m                                    'name': 'vllm',
[36m(main_task pid=198241)[0m                                    'prompt_length': 512,
[36m(main_task pid=198241)[0m                                    'response_length': 8192,
[36m(main_task pid=198241)[0m                                    'temperature': 1.0,
[36m(main_task pid=198241)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=198241)[0m                                    'top_k': -1,
[36m(main_task pid=198241)[0m                                    'top_p': 1,
[36m(main_task pid=198241)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=198241)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=198241)[0m                                                   'n': 32,
[36m(main_task pid=198241)[0m                                                   'temperature': 0,
[36m(main_task pid=198241)[0m                                                   'top_k': -1,
[36m(main_task pid=198241)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=198241)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=198241)[0m                'gamma': 1.0,
[36m(main_task pid=198241)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=198241)[0m                'kl_penalty': 'kl',
[36m(main_task pid=198241)[0m                'lam': 1.0},
[36m(main_task pid=198241)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=198241)[0m             'estimate_prompts_value': False,
[36m(main_task pid=198241)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=198241)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=198241)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=198241)[0m             'grad_clip': 1.0,
[36m(main_task pid=198241)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=198241)[0m                       'external_lib': None,
[36m(main_task pid=198241)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=198241)[0m                                       'optimizer_offload': False,
[36m(main_task pid=198241)[0m                                       'param_offload': False,
[36m(main_task pid=198241)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=198241)[0m                       'override_config': {},
[36m(main_task pid=198241)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=198241)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=198241)[0m                       'use_remove_padding': False},
[36m(main_task pid=198241)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=198241)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=198241)[0m                       'min_lr_ratio': None,
[36m(main_task pid=198241)[0m                       'total_training_steps': -1,
[36m(main_task pid=198241)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=198241)[0m             'ppo_epochs': 1,
[36m(main_task pid=198241)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=198241)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=198241)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=198241)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=198241)[0m             'shuffle': False,
[36m(main_task pid=198241)[0m             'strategy': 'fsdp',
[36m(main_task pid=198241)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=198241)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=198241)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=198241)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=198241)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=198241)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=198241)[0m                 'warmup_steps': 15},
[36m(main_task pid=198241)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=198241)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=198241)[0m           'image_key': 'images',
[36m(main_task pid=198241)[0m           'max_prompt_length': 512,
[36m(main_task pid=198241)[0m           'max_response_length': 8192,
[36m(main_task pid=198241)[0m           'prompt_key': 'prompt',
[36m(main_task pid=198241)[0m           'return_raw_chat': False,
[36m(main_task pid=198241)[0m           'return_raw_input_ids': False,
[36m(main_task pid=198241)[0m           'shuffle': True,
[36m(main_task pid=198241)[0m           'tokenizer': None,
[36m(main_task pid=198241)[0m           'train_batch_size': 1024,
[36m(main_task pid=198241)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=198241)[0m           'truncation': 'error',
[36m(main_task pid=198241)[0m           'use_chat_template': False,
[36m(main_task pid=198241)[0m           'val_batch_size': None,
[36m(main_task pid=198241)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=198241)[0m  'reward_model': {'enable': False,
[36m(main_task pid=198241)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=198241)[0m                   'max_length': None,
[36m(main_task pid=198241)[0m                   'micro_batch_size': None,
[36m(main_task pid=198241)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=198241)[0m                   'model': {'external_lib': None,
[36m(main_task pid=198241)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=198241)[0m                                             'param_offload': False,
[36m(main_task pid=198241)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=198241)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=198241)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=198241)[0m                             'use_remove_padding': False},
[36m(main_task pid=198241)[0m                   'reward_manager': 'naive',
[36m(main_task pid=198241)[0m                   'strategy': 'fsdp',
[36m(main_task pid=198241)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=198241)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=198241)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=198241)[0m              'critic_warmup': 0,
[36m(main_task pid=198241)[0m              'default_hdfs_dir': None,
[36m(main_task pid=198241)[0m              'default_local_dir': 'checkpoints/grpo/ppo_1.5B_MATH500_tok8k_val-only',
[36m(main_task pid=198241)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=198241)[0m              'experiment_name': 'ppo_1.5B_MATH500_tok8k_val-only',
[36m(main_task pid=198241)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=198241)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=198241)[0m              'nnodes': 1,
[36m(main_task pid=198241)[0m              'project_name': 'grpo',
[36m(main_task pid=198241)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=198241)[0m              'resume_from_path': False,
[36m(main_task pid=198241)[0m              'resume_mode': 'auto',
[36m(main_task pid=198241)[0m              'save_freq': -1,
[36m(main_task pid=198241)[0m              'test_freq': 3,
[36m(main_task pid=198241)[0m              'total_epochs': 10,
[36m(main_task pid=198241)[0m              'total_training_steps': None,
[36m(main_task pid=198241)[0m              'val_before_train': True,
[36m(main_task pid=198241)[0m              'val_generations_to_log_to_wandb': 0,
[36m(main_task pid=198241)[0m              'val_only': True}}
[36m(main_task pid=198241)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=198241)[0m No module named 'vllm._version'
[36m(main_task pid=198241)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=198241)[0m 'We do not use curriculum learning.'
[36m(main_task pid=198241)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=198241)[0m dataset len: 1791700
[36m(main_task pid=198241)[0m Example prompt before filtering: The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=198241)[0m 
[36m(main_task pid=198241)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$. Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=197467)[0m filter dataset len: 1786200
[36m(main_task pid=197467)[0m dataset len: 500
[36m(main_task pid=197467)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=197467)[0m filter dataset len: 497
[36m(main_task pid=197467)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=197467)[0m Size of train dataloader: 1744
[36m(main_task pid=197467)[0m Size of val dataloader: 1
[36m(main_task pid=197467)[0m Total training steps: 17440
[36m(main_task pid=197467)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=199903)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=199903)[0m No module named 'vllm._version'
[36m(pid=199903)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=200111)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=200111)[0m No module named 'vllm._version'
[36m(pid=200111)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=200110)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=200110)[0m No module named 'vllm._version'
[36m(pid=200110)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=199903)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=199903)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=199903)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=199903)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=199903)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=199903)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=199903)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=199903)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=199903)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.63671875
[36m(WorkerDict pid=199903)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=199903)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=199903)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=199903)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=199903)[0m   "architectures": [
[36m(WorkerDict pid=199903)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=199903)[0m   ],
[36m(WorkerDict pid=199903)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=199903)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=199903)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=199903)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=199903)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=199903)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=199903)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=199903)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=199903)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=199903)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=199903)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=199903)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=199903)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=199903)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=199903)[0m   "rope_scaling": null,
[36m(WorkerDict pid=199903)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=199903)[0m   "sliding_window": null,
[36m(WorkerDict pid=199903)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=199903)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=199903)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=199903)[0m   "use_cache": true,
[36m(WorkerDict pid=199903)[0m   "use_mrope": false,
[36m(WorkerDict pid=199903)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=199903)[0m   "vocab_size": 151936
[36m(WorkerDict pid=199903)[0m }
[36m(WorkerDict pid=199903)[0m 
[36m(WorkerDict pid=199903)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=199903)[0m wrap_policy: functools.partial(<function _or_policy at 0x7efe0c6cfbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7efe0c6cfac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=200112)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=199903)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=199903)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=199903)[0m   "architectures": [
[36m(WorkerDict pid=199903)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=199903)[0m   ],
[36m(WorkerDict pid=199903)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=199903)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=199903)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=199903)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=199903)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=199903)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=199903)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=199903)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=199903)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=199903)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=199903)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=199903)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=199903)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=199903)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=199903)[0m   "rope_scaling": null,
[36m(WorkerDict pid=199903)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=199903)[0m   "sliding_window": null,
[36m(WorkerDict pid=199903)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=199903)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=199903)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=199903)[0m   "use_cache": true,
[36m(WorkerDict pid=199903)[0m   "use_mrope": false,
[36m(WorkerDict pid=199903)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=199903)[0m   "vocab_size": 151936
[36m(WorkerDict pid=199903)[0m }
[36m(WorkerDict pid=199903)[0m 
[36m(pid=200112)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=200112)[0m No module named 'vllm._version'
[36m(pid=200112)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=199903)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=200111)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=200111)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=200111)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=199903)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=200111)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=200111)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=200111)[0m wrap_policy: functools.partial(<function _or_policy at 0x7ef36a35bbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7ef36a35bac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=199903)[0m Before building vllm rollout, memory allocated (GB): 2.8754358291625977, memory reserved (GB): 6.37890625
[36m(WorkerDict pid=199903)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=200110)[0m WARNING 04-18 22:49:31 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=200111)[0m Actor use_remove_padding=True[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=200110)[0m local rank 0
[36m(WorkerDict pid=200111)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=200111)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=200112)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=199903)[0m before init cache memory allocated: 6.220056576GB, reserved: 6.377439232GB
[36m(WorkerDict pid=199903)[0m after init cache memory allocated: 59.00956672GB, reserved: 59.166949376GB
[36m(WorkerDict pid=199903)[0m WARNING 04-18 22:49:33 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=199903)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=200112)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=200111)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=200112)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=200112)[0m   warnings.warn(
[36m(WorkerDict pid=200111)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(main_task pid=197467)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(WorkerDict pid=199903)[0m After building vllm rollout, memory allocated (GB): 52.07868671417236, memory reserved (GB): 55.103515625
[36m(WorkerDict pid=199903)[0m After building sharding manager, memory allocated (GB): 52.07868671417236, memory reserved (GB): 55.103515625
[36m(main_task pid=197467)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=197467)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=197467)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_224941-xkxyqtn8
[36m(main_task pid=197467)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=197467)[0m wandb: Syncing run ppo_1.5B_MATH500_tok8k_val-only
[36m(main_task pid=197467)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=197467)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/xkxyqtn8
[36m(main_task pid=197467)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=197467)[0m wandb:                                                                                
[36m(main_task pid=197467)[0m wandb: 🚀 View run ppo_1.5B_MATH500_tok8k_val-only at: https://wandb.ai/sample-efficient-RL/grpo/runs/xkxyqtn8
[36m(main_task pid=197467)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=197467)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=197467)[0m wandb: Find logs at: ./wandb/run-20250418_224941-xkxyqtn8/logs
Error executing job with overrides: ['data.train_files=./data/DAPO-17k-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=1024', 'data.max_prompt_length=512', 'data.max_response_length=8192', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=256', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-1.5B', 'critic.ppo_micro_batch_size_per_gpu=32', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=True', 'trainer.val_only=True', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=3', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo_1.5B_MATH500_tok8k_val-only', 'trainer.total_epochs=10']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): [36mray::main_task()[39m (pid=197467, ip=192.168.159.207)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 971, in fit
    self.total_training_steps = self._compute_max_training_steps()
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 918, in _compute_max_training_steps
    raise ValueError("total_training_steps is not set in the config.")
ValueError: total_training_steps is not set in the config.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(WorkerDict pid=200111)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=200111)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=200111)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=198241)[0m filter dataset len: 1786200
[36m(main_task pid=198241)[0m dataset len: 500
[36m(main_task pid=198241)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=198241)[0m filter dataset len: 497
[36m(main_task pid=198241)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=198241)[0m Size of train dataloader: 1744
[36m(main_task pid=198241)[0m Size of val dataloader: 1
[36m(main_task pid=198241)[0m Total training steps: 17440
[36m(main_task pid=198241)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=201417)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=201417)[0m No module named 'vllm._version'
[36m(pid=201417)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=201701)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=201701)[0m No module named 'vllm._version'
[36m(pid=201701)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=201703)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=201703)[0m No module named 'vllm._version'
[36m(pid=201703)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=201417)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=201417)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=201417)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=201417)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=201417)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=201417)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=201417)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=201417)[0m NCCL version 2.20.5+cuda12.4
[36m(pid=201704)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=201704)[0m No module named 'vllm._version'
[36m(pid=201704)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=201704)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=201704)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=201704)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=201704)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=201701)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=201701)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=201417)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.63671875
[36m(WorkerDict pid=201417)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=201417)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=201417)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=201417)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=201417)[0m   "architectures": [
[36m(WorkerDict pid=201417)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=201417)[0m   ],
[36m(WorkerDict pid=201417)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=201417)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=201417)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=201417)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=201417)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=201417)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=201417)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=201417)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=201417)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=201417)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=201417)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=201417)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=201417)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=201417)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=201417)[0m   "rope_scaling": null,
[36m(WorkerDict pid=201417)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=201417)[0m   "sliding_window": null,
[36m(WorkerDict pid=201417)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=201417)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=201417)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=201417)[0m   "use_cache": true,
[36m(WorkerDict pid=201417)[0m   "use_mrope": false,
[36m(WorkerDict pid=201417)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=201417)[0m   "vocab_size": 151936
[36m(WorkerDict pid=201417)[0m }
[36m(WorkerDict pid=201417)[0m 
[36m(WorkerDict pid=201417)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=201417)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fbeb869bbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fbeb869bac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=201417)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=201417)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=201417)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=201417)[0m   "architectures": [
[36m(WorkerDict pid=201417)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=201417)[0m   ],
[36m(WorkerDict pid=201417)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=201417)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=201417)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=201417)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=201417)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=201417)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=201417)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=201417)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=201417)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=201417)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=201417)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=201417)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=201417)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=201417)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=201417)[0m   "rope_scaling": null,
[36m(WorkerDict pid=201417)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=201417)[0m   "sliding_window": null,
[36m(WorkerDict pid=201417)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=201417)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=201417)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=201417)[0m   "use_cache": true,
[36m(WorkerDict pid=201417)[0m   "use_mrope": false,
[36m(WorkerDict pid=201417)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=201417)[0m   "vocab_size": 151936
[36m(WorkerDict pid=201417)[0m }
[36m(WorkerDict pid=201417)[0m 
[36m(WorkerDict pid=201417)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=201701)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=201701)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=201417)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=201704)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=201704)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=201704)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fbd81603be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fbd81603ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=201417)[0m Before building vllm rollout, memory allocated (GB): 2.875436305999756, memory reserved (GB): 6.37890625
[36m(WorkerDict pid=201417)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=201417)[0m Actor use_remove_padding=True[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=201704)[0m WARNING 04-18 22:50:25 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=201704)[0m local rank 0
[36m(WorkerDict pid=201703)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=201701)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=201417)[0m before init cache memory allocated: 6.220056576GB, reserved: 6.377439232GB
[36m(WorkerDict pid=201704)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=201703)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=201417)[0m after init cache memory allocated: 59.00956672GB, reserved: 59.166949376GB
[36m(WorkerDict pid=201703)[0m WARNING 04-18 22:50:25 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=201703)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=201704)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=201704)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=201704)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=201704)[0m   warnings.warn(
[36m(WorkerDict pid=201704)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=201417)[0m After building vllm rollout, memory allocated (GB): 52.07868719100952, memory reserved (GB): 55.103515625
[36m(WorkerDict pid=201417)[0m After building sharding manager, memory allocated (GB): 52.07868719100952, memory reserved (GB): 55.103515625
[36m(main_task pid=198241)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=198241)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=198241)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=198241)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_225034-lo12igzc
[36m(main_task pid=198241)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=198241)[0m wandb: Syncing run ppo_1.5B_MATH500_tok8k_val-only
[36m(main_task pid=198241)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=198241)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/lo12igzc
[36m(main_task pid=198241)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=198241)[0m wandb:                                                                                
[36m(main_task pid=198241)[0m wandb: 🚀 View run ppo_1.5B_MATH500_tok8k_val-only at: https://wandb.ai/sample-efficient-RL/grpo/runs/lo12igzc
[36m(main_task pid=198241)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=198241)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=198241)[0m wandb: Find logs at: ./wandb/run-20250418_225034-lo12igzc/logs
Error executing job with overrides: ['data.train_files=./data/DAPO-17k-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=1024', 'data.max_prompt_length=512', 'data.max_response_length=8192', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=256', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=32', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'critic.optim.lr=1e-5', 'critic.model.path=Qwen/Qwen2.5-1.5B', 'critic.ppo_micro_batch_size_per_gpu=32', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=True', 'trainer.val_only=True', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=3', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo_1.5B_MATH500_tok8k_val-only', 'trainer.total_epochs=10']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): [36mray::main_task()[39m (pid=198241, ip=192.168.159.207)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 971, in fit
    self.total_training_steps = self._compute_max_training_steps()
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 918, in _compute_max_training_steps
    raise ValueError("total_training_steps is not set in the config.")
ValueError: total_training_steps is not set in the config.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(WorkerDict pid=201417)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=201417)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=201417)[0m   warnings.warn([32m [repeated 3x across cluster][0m
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 1e-6
Critic LR: 1e-5
KL Coefficient: 0.001
Number of Generations Validation: 32
Train Batch Size: 1024
PPO Mini Batch Size: 256
PPO Micro Batch Size: 32
Total Epochs: 10
Max Response Length: 8192
GPU Memory Utilization: 0.7
Test Frequency: 3
Number of GPUs: 4
Compute Prompts Values: False
Experiment Name: ppo_1.5B_MATH500_tok8k_val-only
2025-04-18 23:16:56,582	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.159.207:6379...
2025-04-18 23:16:56,592	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=207871)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=207871)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=207871)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=207871)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=207871)[0m                                                  'param_offload': False,
[36m(main_task pid=207871)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=207871)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=207871)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=207871)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=207871)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=207871)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=207871)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=207871)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=207871)[0m                                            'total_training_steps': -1,
[36m(main_task pid=207871)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=207871)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=207871)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=207871)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=207871)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=207871)[0m                                  'ppo_mini_batch_size': 256,
[36m(main_task pid=207871)[0m                                  'response_length': 8192,
[36m(main_task pid=207871)[0m                                  'shuffle': False,
[36m(main_task pid=207871)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=207871)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=207871)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=207871)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=207871)[0m                                  'use_kl_loss': False,
[36m(main_task pid=207871)[0m                                  'use_torch_compile': True},
[36m(main_task pid=207871)[0m                        'hybrid_engine': True,
[36m(main_task pid=207871)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=207871)[0m                                  'external_lib': None,
[36m(main_task pid=207871)[0m                                  'override_config': {},
[36m(main_task pid=207871)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=207871)[0m                                  'use_remove_padding': True},
[36m(main_task pid=207871)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=207871)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=207871)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=207871)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=207871)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=207871)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=207871)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=207871)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=207871)[0m                                    'disable_log_stats': True,
[36m(main_task pid=207871)[0m                                    'do_sample': True,
[36m(main_task pid=207871)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=207871)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=207871)[0m                                    'enforce_eager': True,
[36m(main_task pid=207871)[0m                                    'free_cache_engine': True,
[36m(main_task pid=207871)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=207871)[0m                                    'ignore_eos': False,
[36m(main_task pid=207871)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=207871)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=207871)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=207871)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(main_task pid=207871)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=207871)[0m                                    'max_model_len': None,
[36m(main_task pid=207871)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=207871)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=207871)[0m                                    'n': 1,
[36m(main_task pid=207871)[0m                                    'name': 'vllm',
[36m(main_task pid=207871)[0m                                    'prompt_length': 512,
[36m(main_task pid=207871)[0m                                    'response_length': 8192,
[36m(main_task pid=207871)[0m                                    'temperature': 1.0,
[36m(main_task pid=207871)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=207871)[0m                                    'top_k': -1,
[36m(main_task pid=207871)[0m                                    'top_p': 1,
[36m(main_task pid=207871)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=207871)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=207871)[0m                                                   'n': 32,
[36m(main_task pid=207871)[0m                                                   'temperature': 0,
[36m(main_task pid=207871)[0m                                                   'top_k': -1,
[36m(main_task pid=207871)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=207871)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=207871)[0m                'gamma': 1.0,
[36m(main_task pid=207871)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=207871)[0m                'kl_penalty': 'kl',
[36m(main_task pid=207871)[0m                'lam': 1.0},
[36m(main_task pid=207871)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=207871)[0m             'estimate_prompts_value': False,
[36m(main_task pid=207871)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=207871)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=207871)[0m             'forward_micro_batch_size_per_gpu': 32,
[36m(main_task pid=207871)[0m             'grad_clip': 1.0,
[36m(main_task pid=207871)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=207871)[0m                       'external_lib': None,
[36m(main_task pid=207871)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=207871)[0m                                       'optimizer_offload': False,
[36m(main_task pid=207871)[0m                                       'param_offload': False,
[36m(main_task pid=207871)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=207871)[0m                       'override_config': {},
[36m(main_task pid=207871)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=207871)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=207871)[0m                       'use_remove_padding': False},
[36m(main_task pid=207871)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=207871)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=207871)[0m                       'min_lr_ratio': None,
[36m(main_task pid=207871)[0m                       'total_training_steps': -1,
[36m(main_task pid=207871)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=207871)[0m             'ppo_epochs': 1,
[36m(main_task pid=207871)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=207871)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=207871)[0m             'ppo_micro_batch_size_per_gpu': 32,
[36m(main_task pid=207871)[0m             'ppo_mini_batch_size': 256,
[36m(main_task pid=207871)[0m             'shuffle': False,
[36m(main_task pid=207871)[0m             'strategy': 'fsdp',
[36m(main_task pid=207871)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=207871)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=207871)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=207871)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=207871)[0m                 'train_batch_size_pool': 3072,
[36m(main_task pid=207871)[0m                 'use_curriculum_learning': False,
[36m(main_task pid=207871)[0m                 'warmup_steps': 15},
[36m(main_task pid=207871)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=207871)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=207871)[0m           'image_key': 'images',
[36m(main_task pid=207871)[0m           'max_prompt_length': 512,
[36m(main_task pid=207871)[0m           'max_response_length': 8192,
[36m(main_task pid=207871)[0m           'prompt_key': 'prompt',
[36m(main_task pid=207871)[0m           'return_raw_chat': False,
[36m(main_task pid=207871)[0m           'return_raw_input_ids': False,
[36m(main_task pid=207871)[0m           'shuffle': True,
[36m(main_task pid=207871)[0m           'tokenizer': None,
[36m(main_task pid=207871)[0m           'train_batch_size': 1024,
[36m(main_task pid=207871)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=207871)[0m           'truncation': 'error',
[36m(main_task pid=207871)[0m           'use_chat_template': False,
[36m(main_task pid=207871)[0m           'val_batch_size': None,
[36m(main_task pid=207871)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=207871)[0m  'reward_model': {'enable': False,
[36m(main_task pid=207871)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=207871)[0m                   'max_length': None,
[36m(main_task pid=207871)[0m                   'micro_batch_size': None,
[36m(main_task pid=207871)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=207871)[0m                   'model': {'external_lib': None,
[36m(main_task pid=207871)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=207871)[0m                                             'param_offload': False,
[36m(main_task pid=207871)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=207871)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=207871)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=207871)[0m                             'use_remove_padding': False},
[36m(main_task pid=207871)[0m                   'reward_manager': 'naive',
[36m(main_task pid=207871)[0m                   'strategy': 'fsdp',
[36m(main_task pid=207871)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=207871)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=207871)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=207871)[0m              'critic_warmup': 0,
[36m(main_task pid=207871)[0m              'default_hdfs_dir': None,
[36m(main_task pid=207871)[0m              'default_local_dir': 'checkpoints/grpo/ppo_1.5B_MATH500_tok8k_val-only',
[36m(main_task pid=207871)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=207871)[0m              'experiment_name': 'ppo_1.5B_MATH500_tok8k_val-only',
[36m(main_task pid=207871)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=207871)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=207871)[0m              'nnodes': 1,
[36m(main_task pid=207871)[0m              'project_name': 'grpo',
[36m(main_task pid=207871)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=207871)[0m              'resume_from_path': False,
[36m(main_task pid=207871)[0m              'resume_mode': 'auto',
[36m(main_task pid=207871)[0m              'save_freq': -1,
[36m(main_task pid=207871)[0m              'test_freq': 3,
[36m(main_task pid=207871)[0m              'total_epochs': 10,
[36m(main_task pid=207871)[0m              'total_training_steps': None,
[36m(main_task pid=207871)[0m              'val_before_train': True,
[36m(main_task pid=207871)[0m              'val_generations_to_log_to_wandb': 0,
[36m(main_task pid=207871)[0m              'val_only': True}}
[36m(main_task pid=207871)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=207871)[0m No module named 'vllm._version'
[36m(main_task pid=207871)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=207871)[0m 'We do not use curriculum learning.'
[36m(main_task pid=207871)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=207871)[0m dataset len: 1791700
[36m(main_task pid=207871)[0m Example prompt before filtering: The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=207871)[0m 
[36m(main_task pid=207871)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$. Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=207871)[0m filter dataset len: 1786200
[36m(main_task pid=207871)[0m dataset len: 500
[36m(main_task pid=207871)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=207871)[0m filter dataset len: 497
[36m(main_task pid=207871)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=207871)[0m Size of train dataloader: 1744
[36m(main_task pid=207871)[0m Size of val dataloader: 1
[36m(main_task pid=207871)[0m Total training steps: 17440
[36m(main_task pid=207871)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=209636)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=209636)[0m No module named 'vllm._version'
[36m(pid=209636)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=209898)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=209898)[0m No module named 'vllm._version'
[36m(pid=209898)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=209897)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=209897)[0m No module named 'vllm._version'
[36m(pid=209897)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=209636)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=209897)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=209897)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=209897)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=209897)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=209636)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=209636)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=209636)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=209636)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.6328125
[36m(WorkerDict pid=209636)[0m Total steps: 17440, num_warmup_steps: 0
[36m(WorkerDict pid=209636)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=209636)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=209636)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=209636)[0m   "architectures": [
[36m(WorkerDict pid=209636)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=209636)[0m   ],
[36m(WorkerDict pid=209636)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=209636)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=209636)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=209636)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=209636)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=209636)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=209636)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=209636)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=209636)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=209636)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=209636)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=209636)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=209636)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=209636)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=209636)[0m   "rope_scaling": null,
[36m(WorkerDict pid=209636)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=209636)[0m   "sliding_window": null,
[36m(WorkerDict pid=209636)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=209636)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=209636)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=209636)[0m   "use_cache": true,
[36m(WorkerDict pid=209636)[0m   "use_mrope": false,
[36m(WorkerDict pid=209636)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=209636)[0m   "vocab_size": 151936
[36m(WorkerDict pid=209636)[0m }
[36m(WorkerDict pid=209636)[0m 
[36m(WorkerDict pid=209636)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=209636)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fa8ac15fbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fa8ac15fac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=209636)[0m Actor use_remove_padding=True
[36m(pid=209896)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=209896)[0m No module named 'vllm._version'
[36m(pid=209896)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=209897)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=209896)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=209896)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=209896)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=209636)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=209636)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=209636)[0m   "architectures": [
[36m(WorkerDict pid=209636)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=209636)[0m   ],
[36m(WorkerDict pid=209636)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=209636)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=209636)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=209636)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=209636)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=209636)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=209636)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=209636)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=209636)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=209636)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=209636)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=209636)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=209636)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=209636)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=209636)[0m   "rope_scaling": null,
[36m(WorkerDict pid=209636)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=209636)[0m   "sliding_window": null,
[36m(WorkerDict pid=209636)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=209636)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=209636)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=209636)[0m   "use_cache": true,
[36m(WorkerDict pid=209636)[0m   "use_mrope": false,
[36m(WorkerDict pid=209636)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=209636)[0m   "vocab_size": 151936
[36m(WorkerDict pid=209636)[0m }
[36m(WorkerDict pid=209636)[0m 
[36m(WorkerDict pid=209636)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=209896)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=209896)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=209896)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f4bb560bbe0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f4bb560bac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=209636)[0m Before building vllm rollout, memory allocated (GB): 2.8754353523254395, memory reserved (GB): 6.375
[36m(WorkerDict pid=209636)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=209636)[0m WARNING 04-18 23:25:01 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=209896)[0m Actor use_remove_padding=True[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=209896)[0m Total steps: 17440, num_warmup_steps: 0[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=209636)[0m local rank 0
[36m(WorkerDict pid=209898)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=209896)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=209636)[0m before init cache memory allocated: 6.22053888GB, reserved: 6.381633536GB
[36m(WorkerDict pid=209636)[0m after init cache memory allocated: 58.977936384GB, reserved: 59.17114368GB
[36m(WorkerDict pid=209897)[0m WARNING 04-18 23:25:02 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=209897)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=209897)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=209897)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=209897)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=209897)[0m   warnings.warn(
[36m(WorkerDict pid=209636)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(main_task pid=207871)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(WorkerDict pid=209636)[0m After building vllm rollout, memory allocated (GB): 52.048779010772705, memory reserved (GB): 55.107421875
[36m(WorkerDict pid=209636)[0m After building sharding manager, memory allocated (GB): 52.048779010772705, memory reserved (GB): 55.107421875
[36m(main_task pid=207871)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=207871)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=207871)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250418_232510-4xugwxio
[36m(main_task pid=207871)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=207871)[0m wandb: Syncing run ppo_1.5B_MATH500_tok8k_val-only
[36m(main_task pid=207871)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=207871)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/4xugwxio
[36m(main_task pid=207871)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=207871)[0m '######################## Total training steps: 17440 ########################'
[36m(main_task pid=207871)[0m 'Total training steps: 17440'
[36m(main_task pid=207871)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo_1.5B_MATH500_tok8k_val-only/latest_checkpointed_iteration.txt
[36m(main_task pid=207871)[0m Training from scratch
[36m(main_task pid=207871)[0m test_gen_batch meta info: {'eos_token_id': 151643, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True}
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 5e-7
Critic LR: 5e-6
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 512
PPO Mini Batch Size: 128
PPO Micro Batch Size: 4
Total Epochs: 10
Max Response Length: 8192
GPU Memory Utilization: 0.7
Test Frequency: 5
Number of GPUs: 4
Total Training Steps: 500
Compute Prompts Values: False
Experiment Name: ppo1.5B_dapo17k_tok8k
2025-04-20 21:25:30,138	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.102.77:6379...
2025-04-20 21:25:30,150	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=61774)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=61774)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=61774)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=61774)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=61774)[0m                                                  'param_offload': False,
[36m(main_task pid=61774)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=61774)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=61774)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=61774)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=61774)[0m                                  'optim': {'lr': 5e-07,
[36m(main_task pid=61774)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=61774)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=61774)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=61774)[0m                                            'total_training_steps': -1,
[36m(main_task pid=61774)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=61774)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=61774)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=61774)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=61774)[0m                                  'ppo_micro_batch_size_per_gpu': 4,
[36m(main_task pid=61774)[0m                                  'ppo_mini_batch_size': 128,
[36m(main_task pid=61774)[0m                                  'response_length': 8192,
[36m(main_task pid=61774)[0m                                  'shuffle': False,
[36m(main_task pid=61774)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=61774)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=61774)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=61774)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=61774)[0m                                  'use_kl_loss': False,
[36m(main_task pid=61774)[0m                                  'use_torch_compile': True},
[36m(main_task pid=61774)[0m                        'hybrid_engine': True,
[36m(main_task pid=61774)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=61774)[0m                                  'external_lib': None,
[36m(main_task pid=61774)[0m                                  'override_config': {},
[36m(main_task pid=61774)[0m                                  'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=61774)[0m                                  'use_remove_padding': True},
[36m(main_task pid=61774)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=61774)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=61774)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=61774)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=61774)[0m                                'log_prob_micro_batch_size_per_gpu': 4,
[36m(main_task pid=61774)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=61774)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=61774)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=61774)[0m                                    'disable_log_stats': True,
[36m(main_task pid=61774)[0m                                    'do_sample': True,
[36m(main_task pid=61774)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=61774)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=61774)[0m                                    'enforce_eager': True,
[36m(main_task pid=61774)[0m                                    'free_cache_engine': True,
[36m(main_task pid=61774)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=61774)[0m                                    'ignore_eos': False,
[36m(main_task pid=61774)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=61774)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=61774)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=61774)[0m                                    'log_prob_micro_batch_size_per_gpu': 4,
[36m(main_task pid=61774)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=61774)[0m                                    'max_model_len': None,
[36m(main_task pid=61774)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=61774)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=61774)[0m                                    'n': 1,
[36m(main_task pid=61774)[0m                                    'name': 'vllm',
[36m(main_task pid=61774)[0m                                    'prompt_length': 512,
[36m(main_task pid=61774)[0m                                    'response_length': 8192,
[36m(main_task pid=61774)[0m                                    'temperature': 1.0,
[36m(main_task pid=61774)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=61774)[0m                                    'top_k': -1,
[36m(main_task pid=61774)[0m                                    'top_p': 1,
[36m(main_task pid=61774)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=61774)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=61774)[0m                                                   'n': 1,
[36m(main_task pid=61774)[0m                                                   'temperature': 0,
[36m(main_task pid=61774)[0m                                                   'top_k': -1,
[36m(main_task pid=61774)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=61774)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=61774)[0m                'gamma': 1.0,
[36m(main_task pid=61774)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=61774)[0m                'kl_penalty': 'kl',
[36m(main_task pid=61774)[0m                'lam': 1.0},
[36m(main_task pid=61774)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=61774)[0m             'estimate_prompts_value': False,
[36m(main_task pid=61774)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=61774)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=61774)[0m             'forward_micro_batch_size_per_gpu': 4,
[36m(main_task pid=61774)[0m             'grad_clip': 1.0,
[36m(main_task pid=61774)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=61774)[0m                       'external_lib': None,
[36m(main_task pid=61774)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=61774)[0m                                       'optimizer_offload': False,
[36m(main_task pid=61774)[0m                                       'param_offload': False,
[36m(main_task pid=61774)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=61774)[0m                       'override_config': {},
[36m(main_task pid=61774)[0m                       'path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=61774)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=61774)[0m                       'use_remove_padding': False},
[36m(main_task pid=61774)[0m             'optim': {'lr': 5e-06,
[36m(main_task pid=61774)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=61774)[0m                       'min_lr_ratio': None,
[36m(main_task pid=61774)[0m                       'total_training_steps': -1,
[36m(main_task pid=61774)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=61774)[0m             'ppo_epochs': 1,
[36m(main_task pid=61774)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=61774)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=61774)[0m             'ppo_micro_batch_size_per_gpu': 4,
[36m(main_task pid=61774)[0m             'ppo_mini_batch_size': 128,
[36m(main_task pid=61774)[0m             'shuffle': False,
[36m(main_task pid=61774)[0m             'strategy': 'fsdp',
[36m(main_task pid=61774)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=61774)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=61774)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=61774)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=61774)[0m                 'train_batch_size_pool': 2048,
[36m(main_task pid=61774)[0m                 'use_curriculum_learning': True,
[36m(main_task pid=61774)[0m                 'warmup_steps': 3},
[36m(main_task pid=61774)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=61774)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=61774)[0m           'image_key': 'images',
[36m(main_task pid=61774)[0m           'max_prompt_length': 512,
[36m(main_task pid=61774)[0m           'max_response_length': 8192,
[36m(main_task pid=61774)[0m           'prompt_key': 'prompt',
[36m(main_task pid=61774)[0m           'return_raw_chat': False,
[36m(main_task pid=61774)[0m           'return_raw_input_ids': False,
[36m(main_task pid=61774)[0m           'shuffle': True,
[36m(main_task pid=61774)[0m           'tokenizer': None,
[36m(main_task pid=61774)[0m           'train_batch_size': 512,
[36m(main_task pid=61774)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=61774)[0m           'truncation': 'error',
[36m(main_task pid=61774)[0m           'use_chat_template': False,
[36m(main_task pid=61774)[0m           'val_batch_size': None,
[36m(main_task pid=61774)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=61774)[0m  'reward_model': {'enable': False,
[36m(main_task pid=61774)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=61774)[0m                   'max_length': None,
[36m(main_task pid=61774)[0m                   'micro_batch_size': None,
[36m(main_task pid=61774)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=61774)[0m                   'model': {'external_lib': None,
[36m(main_task pid=61774)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=61774)[0m                                             'param_offload': False,
[36m(main_task pid=61774)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=61774)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B',
[36m(main_task pid=61774)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=61774)[0m                             'use_remove_padding': False},
[36m(main_task pid=61774)[0m                   'reward_manager': 'naive',
[36m(main_task pid=61774)[0m                   'strategy': 'fsdp',
[36m(main_task pid=61774)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=61774)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=61774)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=61774)[0m              'critic_warmup': 0,
[36m(main_task pid=61774)[0m              'default_hdfs_dir': None,
[36m(main_task pid=61774)[0m              'default_local_dir': 'checkpoints/grpo/ppo1.5B_dapo17k_tok8k',
[36m(main_task pid=61774)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=61774)[0m              'experiment_name': 'ppo1.5B_dapo17k_tok8k',
[36m(main_task pid=61774)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=61774)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=61774)[0m              'nnodes': 1,
[36m(main_task pid=61774)[0m              'project_name': 'grpo',
[36m(main_task pid=61774)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=61774)[0m              'resume_from_path': False,
[36m(main_task pid=61774)[0m              'resume_mode': 'auto',
[36m(main_task pid=61774)[0m              'save_freq': -1,
[36m(main_task pid=61774)[0m              'test_freq': 5,
[36m(main_task pid=61774)[0m              'total_epochs': 10,
[36m(main_task pid=61774)[0m              'total_training_steps': 500,
[36m(main_task pid=61774)[0m              'val_before_train': False,
[36m(main_task pid=61774)[0m              'val_generations_to_log_to_wandb': 0,
[36m(main_task pid=61774)[0m              'val_only': False}}
[36m(main_task pid=61774)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=61774)[0m No module named 'vllm._version'
[36m(main_task pid=61774)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=61774)[0m 'We use curriculum learning.'
[36m(main_task pid=61774)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=61774)[0m dataset len: 1791700
[36m(main_task pid=61774)[0m Example prompt before filtering: The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=61774)[0m 
[36m(main_task pid=61774)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$. Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=61774)[0m filter dataset len: 1786200
[36m(main_task pid=61774)[0m dataset len: 500
[36m(main_task pid=61774)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=61774)[0m filter dataset len: 497
[36m(main_task pid=61774)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=61774)[0m Size of train dataloader: 3488
[36m(main_task pid=61774)[0m Size of val dataloader: 1
[36m(main_task pid=61774)[0m Total training steps: 500
[36m(main_task pid=61774)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=63568)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=63568)[0m No module named 'vllm._version'
[36m(pid=63568)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=63828)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=63828)[0m No module named 'vllm._version'
[36m(pid=63828)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=63830)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=63830)[0m No module named 'vllm._version'
[36m(pid=63830)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=63828)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=63828)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=63568)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=63830)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=63830)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=63568)[0m Qwen2ForTokenClassification contains 1.54B parameters
[36m(WorkerDict pid=63568)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=63568)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=63829)[0m Total steps: 500, num_warmup_steps: 0
[36m(WorkerDict pid=63829)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=63568)[0m After critic FSDP, memory allocated (GB): 1.4377117156982422, memory reserved (GB): 4.71484375
[36m(WorkerDict pid=63568)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=63568)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=63568)[0m   "architectures": [
[36m(WorkerDict pid=63568)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=63568)[0m   ],
[36m(WorkerDict pid=63568)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=63568)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=63568)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=63568)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=63568)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=63568)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=63568)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=63568)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=63568)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=63568)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=63568)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=63568)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=63568)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=63568)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=63568)[0m   "rope_scaling": null,
[36m(WorkerDict pid=63568)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=63568)[0m   "sliding_window": null,
[36m(WorkerDict pid=63568)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=63568)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=63568)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=63568)[0m   "use_cache": true,
[36m(WorkerDict pid=63568)[0m   "use_mrope": false,
[36m(WorkerDict pid=63568)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=63568)[0m   "vocab_size": 151936
[36m(WorkerDict pid=63568)[0m }
[36m(WorkerDict pid=63568)[0m 
[36m(WorkerDict pid=63568)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=63568)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f68700a00d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f6870067f40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=63568)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=63568)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=63568)[0m   "_name_or_path": "Qwen/Qwen2.5-1.5B",
[36m(WorkerDict pid=63568)[0m   "architectures": [
[36m(WorkerDict pid=63568)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=63568)[0m   ],
[36m(WorkerDict pid=63568)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=63568)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=63568)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=63568)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=63568)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=63568)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=63568)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=63568)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=63568)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=63568)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=63568)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=63568)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=63568)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=63568)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=63568)[0m   "rope_scaling": null,
[36m(WorkerDict pid=63568)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=63568)[0m   "sliding_window": null,
[36m(WorkerDict pid=63568)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=63568)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=63568)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=63568)[0m   "use_cache": true,
[36m(WorkerDict pid=63568)[0m   "use_mrope": false,
[36m(WorkerDict pid=63568)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=63568)[0m   "vocab_size": 151936
[36m(WorkerDict pid=63568)[0m }
[36m(WorkerDict pid=63568)[0m 
[36m(pid=63829)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=63829)[0m No module named 'vllm._version'
[36m(pid=63829)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=63830)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=63568)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=63568)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=63568)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=63830)[0m Total steps: 500, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=63830)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=63568)[0m Qwen2ForCausalLM contains 1.54B parameters
[36m(WorkerDict pid=63568)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f68700a00d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f6870067f40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=63568)[0m Before building vllm rollout, memory allocated (GB): 2.8754353523254395, memory reserved (GB): 6.45703125
[36m(WorkerDict pid=63568)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=63829)[0m WARNING 04-20 21:33:42 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=63828)[0m Actor use_remove_padding=True[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=63828)[0m Total steps: 500, num_warmup_steps: 0[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=63829)[0m local rank 0
[36m(WorkerDict pid=63568)[0m before init cache memory allocated: 6.220045312GB, reserved: 6.358564864GB
[36m(WorkerDict pid=63830)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=63829)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=63568)[0m after init cache memory allocated: 59.009555456GB, reserved: 59.148075008GB
[36m(WorkerDict pid=63830)[0m WARNING 04-20 21:33:43 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=63830)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=63568)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=63568)[0m After building vllm rollout, memory allocated (GB): 52.078686237335205, memory reserved (GB): 55.0859375
[36m(WorkerDict pid=63568)[0m After building sharding manager, memory allocated (GB): 52.078686237335205, memory reserved (GB): 55.0859375
[36m(WorkerDict pid=63830)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=63568)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=63568)[0m   warnings.warn(
[36m(WorkerDict pid=63829)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(main_task pid=61774)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=61774)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=61774)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=61774)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250420_213351-tgltloix
[36m(main_task pid=61774)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=61774)[0m wandb: Syncing run ppo1.5B_dapo17k_tok8k
[36m(main_task pid=61774)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=61774)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/tgltloix
[36m(main_task pid=61774)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=61774)[0m '######################## Total training steps: 500 ########################'
[36m(main_task pid=61774)[0m 'Total training steps: 500'
[36m(main_task pid=61774)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo1.5B_dapo17k_tok8k/latest_checkpointed_iteration.txt
[36m(main_task pid=61774)[0m Training from scratch
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:47,227:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:47,233:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: [' \\box{80}\\ \\mathrm{③}<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:47,246:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=63830)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=63830)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:47,409:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:47,574:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:47,753:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{65}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:47,757:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,088:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{53}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,092:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{32}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,098:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{43}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,267:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,269:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,284:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,290:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1044}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,328:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6067}'], Pred: ['```htmlboxed{} ```<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,397:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,406:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,435:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,472:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{35}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,537:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{35}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,542:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{770}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,548:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,555:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,558:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,708:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{33}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,709:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{84}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,710:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{37}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,768:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: [' \\<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,913:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{155}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,924:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:48,951:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,105:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,141:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2006}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,142:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{47}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,143:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{31}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,149:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,150:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,202:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{34}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,225:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{47}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,290:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,308:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,309:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{137}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,321:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{253}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,345:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{829}'], Pred: [" Sure, I can help with that! However, it seems that we don't have a specific question or problem statement provided here. It's important to have a clear description or problem statement to find a suitable answer.\n\nIf you could provide the problem statement or a more detailed description, I would be happy to assist you in finding the solution!<|endoftext|>"]
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,371:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{408}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,506:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{108}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,518:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,523:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{30}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,525:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1981}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,762:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,765:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{420}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,769:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:49,800:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2019}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,198:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4095}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,212:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{65}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,217:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2024}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,218:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{875}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,233:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,317:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{157}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,382:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4004}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,504:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,548:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{259}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,549:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{367}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,555:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{164}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,582:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{40}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,643:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{55}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,644:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7200}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:36:50,693:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=63568)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=63568)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
[36m(WorkerDict pid=63568)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=63568)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 4x across cluster][0m
[36m(main_task pid=61774)[0m step:1 - global_seqlen/min:103256.000 - global_seqlen/max:135238.000 - global_seqlen/minmax_diff:31982.000 - global_seqlen/balanced_min:118517.000 - global_seqlen/balanced_max:118518.000 - global_seqlen/mean:118517.750 - critic/kl:0.000 - critic/kl_coeff:0.001 - critic/vf_loss:2.610 - critic/vf_clipfrac:0.000 - critic/vpred_mean:-0.733 - critic/grad_norm:156.281 - perf/mfu/critic:0.062 - critic/lr:0.000 - actor/entropy_loss:0.998 - actor/pg_loss:0.002 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.223 - perf/mfu/actor:0.205 - perf/max_memory_allocated_gb:56.634 - perf/max_memory_reserved_gb:56.744 - perf/cpu_memory_used_gb:68.843 - actor/lr:0.000 - critic/score/mean:0.029 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.029 - critic/rewards/max:1.001 - critic/rewards/min:-0.003 - critic/advantages/mean:-0.000 - critic/advantages/max:4.806 - critic/advantages/min:-4.851 - critic/returns/mean:0.024 - critic/returns/max:1.002 - critic/returns/min:-0.005 - critic/values/mean:-0.742 - critic/values/max:9.750 - critic/values/min:-11.188 - critic/vf_explained_var:-203.440 - response_length/mean:791.250 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.004 - prompt_length/mean:134.670 - prompt_length/max:482.000 - prompt_length/min:56.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:142.085 - timing_s/old_log_prob:6.326 - timing_s/ref:6.585 - timing_s/values:19.273 - timing_s/adv:4.242 - timing_s/update_critic:72.594 - timing_s/update_actor:21.951 - timing_s/step:273.103 - timing_per_token_ms/values:0.041 - timing_per_token_ms/update_critic:0.153 - timing_per_token_ms/update_actor:0.046 - timing_per_token_ms/ref:0.014 - timing_per_token_ms/gen:0.351 - timing_per_token_ms/adv:0.009 - perf/total_num_tokens:474071.000 - perf/time_per_step:273.103 - perf/throughput:433.968
[36m(WorkerDict pid=63830)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,636:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5792}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,674:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,690:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{26}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=63829)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=63829)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 3x across cluster][0m
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,729:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{36}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,734:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{831}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,738:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,746:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,764:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{334}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,780:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,796:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{936}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,824:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{160}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,870:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{289}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,872:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,900:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,902:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{56}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,903:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{831}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,915:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{576}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:14,941:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,011:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,058:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{31}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,110:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,110:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,150:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{52}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,260:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{317}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,334:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,371:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,425:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{166}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,428:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,699:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{75}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,713:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,728:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{0}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,757:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{84}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,792:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,824:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,865:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1010}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,869:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{60}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,882:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{45}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:15,899:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{400}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:16,201:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:16,333:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{105101005}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:16,350:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:16,374:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:16,439:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{17}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:16,459:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{32}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:16,584:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{548}'], Pred: ['  Answer: \\boxed{}<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:16,642:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{288}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:16,646:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{65536}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:16,655:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:16,809:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{79}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,071:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{936}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,080:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{550}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,088:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{61}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,116:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{26}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,138:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{100}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,141:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,149:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,213:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,214:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,224:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{171}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,243:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{79}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,249:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{28}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,294:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{105}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,298:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{291}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,309:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{349}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,310:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,361:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{47}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,411:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2186}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,534:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{45}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,580:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{768}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:41:17,650:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m step:2 - global_seqlen/min:100464.000 - global_seqlen/max:124842.000 - global_seqlen/minmax_diff:24378.000 - global_seqlen/balanced_min:109110.000 - global_seqlen/balanced_max:109111.000 - global_seqlen/mean:109110.250 - critic/kl:-0.002 - critic/kl_coeff:0.001 - critic/vf_loss:2.436 - critic/vf_clipfrac:0.186 - critic/vpred_mean:-0.254 - critic/grad_norm:111.550 - perf/mfu/critic:0.056 - critic/lr:0.000 - actor/entropy_loss:0.810 - actor/pg_loss:0.009 - actor/pg_clipfrac:0.000 - actor/ppo_kl:-0.000 - actor/grad_norm:0.212 - perf/mfu/actor:0.221 - perf/max_memory_allocated_gb:61.284 - perf/max_memory_reserved_gb:62.842 - perf/cpu_memory_used_gb:69.711 - actor/lr:0.000 - critic/score/mean:0.031 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.031 - critic/rewards/max:1.002 - critic/rewards/min:-0.005 - critic/advantages/mean:-0.000 - critic/advantages/max:4.542 - critic/advantages/min:-4.377 - critic/returns/mean:0.020 - critic/returns/max:1.002 - critic/returns/min:-0.006 - critic/values/mean:-0.641 - critic/values/max:9.062 - critic/values/min:-10.750 - critic/vf_explained_var:-243.404 - response_length/mean:718.857 - response_length/max:7630.000 - response_length/min:1.000 - response_length/clip_ratio:0.000 - prompt_length/mean:133.566 - prompt_length/max:455.000 - prompt_length/min:63.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:139.405 - timing_s/old_log_prob:4.752 - timing_s/ref:5.242 - timing_s/values:19.182 - timing_s/adv:3.707 - timing_s/update_critic:72.830 - timing_s/update_actor:18.478 - timing_s/step:263.636 - timing_per_token_ms/values:0.044 - timing_per_token_ms/update_critic:0.167 - timing_per_token_ms/update_actor:0.042 - timing_per_token_ms/ref:0.012 - timing_per_token_ms/gen:0.379 - timing_per_token_ms/adv:0.008 - perf/total_num_tokens:436441.000 - perf/time_per_step:263.636 - perf/throughput:413.867
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:43,891:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:43,950:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{16}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,075:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,108:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{105}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,143:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,150:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,162:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,165:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,295:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,296:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{996}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,318:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{114}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,379:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,391:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{200}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,444:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,551:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,586:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8788}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,593:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{35}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,601:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1999999}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,642:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{525825}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,878:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{47}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:44,884:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{282}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,029:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,101:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,107:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,269:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3004}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,288:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,289:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9900}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,305:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,362:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,393:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{31}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,585:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1234}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,690:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,694:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{291}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,718:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3840}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,852:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:45,891:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{889}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m ERROR:2025-04-20 21:45:50,984:Timeout during comparison
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,024:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{45}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,031:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5024}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,042:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{37}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,048:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{53}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,055:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{170}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,107:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7448}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,115:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1512}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,133:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{13}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,158:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2007}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,307:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{160}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,308:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{216}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,342:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{80}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,383:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{319}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,386:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=61774)[0m WARNING:2025-04-20 21:45:51,415:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{29}'], Pred: ['<|endoftext|>']
*** SIGTERM received at time=1745210759 on cpu 247 ***
PC: @     0x7fda0780f117  (unknown)  (unknown)
    @     0x7fda077c0520  (unknown)  (unknown)
    @ ... and at least 1 more frames
[2025-04-20 21:45:59,328 E 61612 61612] logging.cc:484: *** SIGTERM received at time=1745210759 on cpu 247 ***
[2025-04-20 21:45:59,328 E 61612 61612] logging.cc:484: PC: @     0x7fda0780f117  (unknown)  (unknown)
[2025-04-20 21:45:59,328 E 61612 61612] logging.cc:484:     @     0x7fda077c0520  (unknown)  (unknown)
[2025-04-20 21:45:59,328 E 61612 61612] logging.cc:484:     @ ... and at least 1 more frames
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 5e-7
Critic LR: 5e-6
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 512
PPO Mini Batch Size: 128
PPO Micro Batch Size: 4
Total Epochs: 10
Max Response Length: 8192
GPU Memory Utilization: 0.7
Test Frequency: 5
Number of GPUs: 4
Total Training Steps: 500
Compute Prompts Values: False
Experiment Name: ppo7B_dapo17k_tok8k
2025-04-20 21:46:54,343	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.102.77:6379...
2025-04-20 21:46:54,354	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=68387)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=68387)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=68387)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=68387)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=68387)[0m                                                  'param_offload': False,
[36m(main_task pid=68387)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=68387)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=68387)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=68387)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=68387)[0m                                  'optim': {'lr': 5e-07,
[36m(main_task pid=68387)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=68387)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=68387)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=68387)[0m                                            'total_training_steps': -1,
[36m(main_task pid=68387)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=68387)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=68387)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=68387)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=68387)[0m                                  'ppo_micro_batch_size_per_gpu': 4,
[36m(main_task pid=68387)[0m                                  'ppo_mini_batch_size': 128,
[36m(main_task pid=68387)[0m                                  'response_length': 8192,
[36m(main_task pid=68387)[0m                                  'shuffle': False,
[36m(main_task pid=68387)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=68387)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=68387)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=68387)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=68387)[0m                                  'use_kl_loss': False,
[36m(main_task pid=68387)[0m                                  'use_torch_compile': True},
[36m(main_task pid=68387)[0m                        'hybrid_engine': True,
[36m(main_task pid=68387)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=68387)[0m                                  'external_lib': None,
[36m(main_task pid=68387)[0m                                  'override_config': {},
[36m(main_task pid=68387)[0m                                  'path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=68387)[0m                                  'use_remove_padding': True},
[36m(main_task pid=68387)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=68387)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=68387)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=68387)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=68387)[0m                                'log_prob_micro_batch_size_per_gpu': 4,
[36m(main_task pid=68387)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=68387)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=68387)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=68387)[0m                                    'disable_log_stats': True,
[36m(main_task pid=68387)[0m                                    'do_sample': True,
[36m(main_task pid=68387)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=68387)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=68387)[0m                                    'enforce_eager': True,
[36m(main_task pid=68387)[0m                                    'free_cache_engine': True,
[36m(main_task pid=68387)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=68387)[0m                                    'ignore_eos': False,
[36m(main_task pid=68387)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=68387)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=68387)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=68387)[0m                                    'log_prob_micro_batch_size_per_gpu': 4,
[36m(main_task pid=68387)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=68387)[0m                                    'max_model_len': None,
[36m(main_task pid=68387)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=68387)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=68387)[0m                                    'n': 1,
[36m(main_task pid=68387)[0m                                    'name': 'vllm',
[36m(main_task pid=68387)[0m                                    'prompt_length': 512,
[36m(main_task pid=68387)[0m                                    'response_length': 8192,
[36m(main_task pid=68387)[0m                                    'temperature': 1.0,
[36m(main_task pid=68387)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=68387)[0m                                    'top_k': -1,
[36m(main_task pid=68387)[0m                                    'top_p': 1,
[36m(main_task pid=68387)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=68387)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=68387)[0m                                                   'n': 1,
[36m(main_task pid=68387)[0m                                                   'temperature': 0,
[36m(main_task pid=68387)[0m                                                   'top_k': -1,
[36m(main_task pid=68387)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=68387)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=68387)[0m                'gamma': 1.0,
[36m(main_task pid=68387)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=68387)[0m                'kl_penalty': 'kl',
[36m(main_task pid=68387)[0m                'lam': 1.0},
[36m(main_task pid=68387)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=68387)[0m             'estimate_prompts_value': False,
[36m(main_task pid=68387)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=68387)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=68387)[0m             'forward_micro_batch_size_per_gpu': 4,
[36m(main_task pid=68387)[0m             'grad_clip': 1.0,
[36m(main_task pid=68387)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=68387)[0m                       'external_lib': None,
[36m(main_task pid=68387)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=68387)[0m                                       'optimizer_offload': False,
[36m(main_task pid=68387)[0m                                       'param_offload': False,
[36m(main_task pid=68387)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=68387)[0m                       'override_config': {},
[36m(main_task pid=68387)[0m                       'path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=68387)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=68387)[0m                       'use_remove_padding': False},
[36m(main_task pid=68387)[0m             'optim': {'lr': 5e-06,
[36m(main_task pid=68387)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=68387)[0m                       'min_lr_ratio': None,
[36m(main_task pid=68387)[0m                       'total_training_steps': -1,
[36m(main_task pid=68387)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=68387)[0m             'ppo_epochs': 1,
[36m(main_task pid=68387)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=68387)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=68387)[0m             'ppo_micro_batch_size_per_gpu': 4,
[36m(main_task pid=68387)[0m             'ppo_mini_batch_size': 128,
[36m(main_task pid=68387)[0m             'shuffle': False,
[36m(main_task pid=68387)[0m             'strategy': 'fsdp',
[36m(main_task pid=68387)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=68387)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=68387)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=68387)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=68387)[0m                 'train_batch_size_pool': 2048,
[36m(main_task pid=68387)[0m                 'use_curriculum_learning': True,
[36m(main_task pid=68387)[0m                 'warmup_steps': 3},
[36m(main_task pid=68387)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=68387)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=68387)[0m           'image_key': 'images',
[36m(main_task pid=68387)[0m           'max_prompt_length': 512,
[36m(main_task pid=68387)[0m           'max_response_length': 8192,
[36m(main_task pid=68387)[0m           'prompt_key': 'prompt',
[36m(main_task pid=68387)[0m           'return_raw_chat': False,
[36m(main_task pid=68387)[0m           'return_raw_input_ids': False,
[36m(main_task pid=68387)[0m           'shuffle': True,
[36m(main_task pid=68387)[0m           'tokenizer': None,
[36m(main_task pid=68387)[0m           'train_batch_size': 512,
[36m(main_task pid=68387)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=68387)[0m           'truncation': 'error',
[36m(main_task pid=68387)[0m           'use_chat_template': False,
[36m(main_task pid=68387)[0m           'val_batch_size': None,
[36m(main_task pid=68387)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=68387)[0m  'reward_model': {'enable': False,
[36m(main_task pid=68387)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=68387)[0m                   'max_length': None,
[36m(main_task pid=68387)[0m                   'micro_batch_size': None,
[36m(main_task pid=68387)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=68387)[0m                   'model': {'external_lib': None,
[36m(main_task pid=68387)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=68387)[0m                                             'param_offload': False,
[36m(main_task pid=68387)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=68387)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=68387)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=68387)[0m                             'use_remove_padding': False},
[36m(main_task pid=68387)[0m                   'reward_manager': 'naive',
[36m(main_task pid=68387)[0m                   'strategy': 'fsdp',
[36m(main_task pid=68387)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=68387)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=68387)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=68387)[0m              'critic_warmup': 0,
[36m(main_task pid=68387)[0m              'default_hdfs_dir': None,
[36m(main_task pid=68387)[0m              'default_local_dir': 'checkpoints/grpo/ppo7B_dapo17k_tok8k',
[36m(main_task pid=68387)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=68387)[0m              'experiment_name': 'ppo7B_dapo17k_tok8k',
[36m(main_task pid=68387)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=68387)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=68387)[0m              'nnodes': 1,
[36m(main_task pid=68387)[0m              'project_name': 'grpo',
[36m(main_task pid=68387)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=68387)[0m              'resume_from_path': False,
[36m(main_task pid=68387)[0m              'resume_mode': 'auto',
[36m(main_task pid=68387)[0m              'save_freq': -1,
[36m(main_task pid=68387)[0m              'test_freq': 5,
[36m(main_task pid=68387)[0m              'total_epochs': 10,
[36m(main_task pid=68387)[0m              'total_training_steps': 500,
[36m(main_task pid=68387)[0m              'val_before_train': False,
[36m(main_task pid=68387)[0m              'val_generations_to_log_to_wandb': 0,
[36m(main_task pid=68387)[0m              'val_only': False}}
[36m(main_task pid=68387)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=68387)[0m No module named 'vllm._version'
[36m(main_task pid=68387)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=68387)[0m 'We use curriculum learning.'
[36m(main_task pid=68387)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=68387)[0m dataset len: 1791700
[36m(main_task pid=68387)[0m Example prompt before filtering: The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=68387)[0m 
[36m(main_task pid=68387)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$. Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=68387)[0m filter dataset len: 1786200
[36m(main_task pid=68387)[0m dataset len: 500
[36m(main_task pid=68387)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=68387)[0m filter dataset len: 497
[36m(main_task pid=68387)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=68387)[0m Size of train dataloader: 3488
[36m(main_task pid=68387)[0m Size of val dataloader: 1
[36m(main_task pid=68387)[0m Total training steps: 500
[36m(main_task pid=68387)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=70150)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=70150)[0m No module named 'vllm._version'
[36m(pid=70150)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=70346)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=70346)[0m No module named 'vllm._version'
[36m(pid=70346)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=70347)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=70347)[0m No module named 'vllm._version'
[36m(pid=70347)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=70150)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=70348)[0m Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=70150)[0m Downloading shards:  25%|██▌       | 1/4 [00:11<00:33, 11.19s/it]
[36m(pid=70348)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=70348)[0m No module named 'vllm._version'
[36m(pid=70348)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=70347)[0m Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=70347)[0m Downloading shards:  50%|█████     | 2/4 [00:20<00:20, 10.13s/it][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=70150)[0m Downloading shards:  75%|███████▌  | 3/4 [00:30<00:10, 10.18s/it][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=70150)[0m Downloading shards: 100%|██████████| 4/4 [00:39<00:00,  9.61s/it]Downloading shards: 100%|██████████| 4/4 [00:39<00:00,  9.90s/it]
[36m(WorkerDict pid=70150)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=70150)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=70150)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=70348)[0m Downloading shards:  75%|███████▌  | 3/4 [00:30<00:10, 10.21s/it][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70346)[0m Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.95it/s]
[36m(WorkerDict pid=70347)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.35it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.92it/s]
[36m(WorkerDict pid=70347)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-7B and are newly initialized: ['score.bias']
[36m(WorkerDict pid=70347)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=70150)[0m Qwen2ForTokenClassification contains 7.07B parameters
[36m(WorkerDict pid=70150)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=70150)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-7B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=70348)[0m Downloading shards: 100%|██████████| 4/4 [00:39<00:00,  9.64s/it]Downloading shards: 100%|██████████| 4/4 [00:39<00:00,  9.94s/it][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70348)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70348)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70348)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70150)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=70346)[0m Total steps: 500, num_warmup_steps: 0
[36m(WorkerDict pid=70346)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=70150)[0m After critic FSDP, memory allocated (GB): 6.585044860839844, memory reserved (GB): 14.544921875
[36m(WorkerDict pid=70150)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.39s/it][32m [repeated 11x across cluster][0m
[36m(WorkerDict pid=70150)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.28s/it][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70348)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-7B and are newly initialized: ['score.bias'][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=70150)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70346)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=70347)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=70150)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=70150)[0m   "_name_or_path": "Qwen/Qwen2.5-7B",
[36m(WorkerDict pid=70150)[0m   "architectures": [
[36m(WorkerDict pid=70150)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=70150)[0m   ],
[36m(WorkerDict pid=70150)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=70150)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=70150)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=70150)[0m   "hidden_size": 3584,
[36m(WorkerDict pid=70150)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=70150)[0m   "intermediate_size": 18944,
[36m(WorkerDict pid=70150)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=70150)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=70150)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=70150)[0m   "num_attention_heads": 28,
[36m(WorkerDict pid=70150)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=70150)[0m   "num_key_value_heads": 4,
[36m(WorkerDict pid=70150)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=70150)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=70150)[0m   "rope_scaling": null,
[36m(WorkerDict pid=70150)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=70150)[0m   "sliding_window": null,
[36m(WorkerDict pid=70150)[0m   "tie_word_embeddings": false,
[36m(WorkerDict pid=70150)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=70150)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=70150)[0m   "use_cache": true,
[36m(WorkerDict pid=70150)[0m   "use_mrope": false,
[36m(WorkerDict pid=70150)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=70150)[0m   "vocab_size": 152064
[36m(WorkerDict pid=70150)[0m }
[36m(WorkerDict pid=70150)[0m 
[36m(WorkerDict pid=70150)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(WorkerDict pid=70150)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f7e1084c0d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f7e10813f40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=70348)[0m Total steps: 500, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70348)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70348)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=70150)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=70150)[0m   "_name_or_path": "Qwen/Qwen2.5-7B",
[36m(WorkerDict pid=70150)[0m   "architectures": [
[36m(WorkerDict pid=70150)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=70150)[0m   ],
[36m(WorkerDict pid=70150)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=70150)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=70150)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=70150)[0m   "hidden_size": 3584,
[36m(WorkerDict pid=70150)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=70150)[0m   "intermediate_size": 18944,
[36m(WorkerDict pid=70150)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=70150)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=70150)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=70150)[0m   "num_attention_heads": 28,
[36m(WorkerDict pid=70150)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=70150)[0m   "num_key_value_heads": 4,
[36m(WorkerDict pid=70150)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=70150)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=70150)[0m   "rope_scaling": null,
[36m(WorkerDict pid=70150)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=70150)[0m   "sliding_window": null,
[36m(WorkerDict pid=70150)[0m   "tie_word_embeddings": false,
[36m(WorkerDict pid=70150)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=70150)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=70150)[0m   "use_cache": true,
[36m(WorkerDict pid=70150)[0m   "use_mrope": false,
[36m(WorkerDict pid=70150)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=70150)[0m   "vocab_size": 152064
[36m(WorkerDict pid=70150)[0m }
[36m(WorkerDict pid=70150)[0m 
[36m(WorkerDict pid=70348)[0m wrap_policy: functools.partial(<function _or_policy at 0x7faf519280d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7faf518eff40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70150)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=70348)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  4.51it/s][32m [repeated 12x across cluster][0m
[36m(WorkerDict pid=70348)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.79it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.51it/s][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=70348)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=70150)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(WorkerDict pid=70347)[0m Actor use_remove_padding=True[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70150)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f7e1084c0d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f7e10813f40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=70348)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70150)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.42s/it][32m [repeated 12x across cluster][0m
[36m(WorkerDict pid=70150)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.40s/it][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=70348)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=70346)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f590d9fc0d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f590d9c3f40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=70346)[0m Total steps: 500, num_warmup_steps: 0
[36m(WorkerDict pid=70150)[0m Before building vllm rollout, memory allocated (GB): 13.678153038024902, memory reserved (GB): 28.693359375
[36m(WorkerDict pid=70150)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=70348)[0m WARNING 04-20 21:56:01 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=70150)[0m Actor use_remove_padding=True[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=70348)[0m wrap_policy: functools.partial(<function _or_policy at 0x7faf519280d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7faf518eff40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=70348)[0m local rank 0
[36m(WorkerDict pid=70150)[0m Total steps: 500, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70346)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=70348)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70150)[0m before init cache memory allocated: 30.009989632GB, reserved: 30.23044608GB
[36m(WorkerDict pid=70150)[0m after init cache memory allocated: 66.00550656GB, reserved: 66.225963008GB
[36m(WorkerDict pid=70150)[0m WARNING 04-20 21:56:02 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70150)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70348)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=70348)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=70348)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=70348)[0m   warnings.warn(
[36m(WorkerDict pid=70150)[0m After building vllm rollout, memory allocated (GB): 47.24077892303467, memory reserved (GB): 61.677734375
[36m(WorkerDict pid=70150)[0m After building sharding manager, memory allocated (GB): 47.24077892303467, memory reserved (GB): 61.677734375
[36m(main_task pid=68387)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=68387)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=68387)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=68387)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250420_215610-7e1lphl9
[36m(main_task pid=68387)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=68387)[0m wandb: Syncing run ppo7B_dapo17k_tok8k
[36m(main_task pid=68387)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=68387)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/7e1lphl9
[36m(main_task pid=68387)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=68387)[0m '######################## Total training steps: 500 ########################'
[36m(main_task pid=68387)[0m 'Total training steps: 500'
[36m(main_task pid=68387)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo7B_dapo17k_tok8k/latest_checkpointed_iteration.txt
[36m(main_task pid=68387)[0m Training from scratch
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:35,589:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:35,591:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: [' Answer:<|endoftext|>']
[36m(WorkerDict pid=70347)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70347)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:35,749:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:35,758:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:35,783:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1314}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:35,821:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{35}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:35,902:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:35,903:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:35,920:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2024}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,007:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,008:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{387}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,016:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{506}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,036:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,046:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{594}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,053:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{49}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,057:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{43}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,058:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{246}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,089:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,091:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,094:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{367}'], Pred: [' Okay!<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,108:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,114:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2035151}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,119:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,129:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,140:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: [' \nAnswer: $Answer<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,192:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{28}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,228:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,290:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{34}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,291:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{24}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,298:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,311:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,332:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,338:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{255}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,374:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3987}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,391:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{85}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,409:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1524}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,431:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{53}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,436:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{71}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,440:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10000}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,444:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1983}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,468:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{92}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,553:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{164}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,554:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,574:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2018}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,580:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:36,989:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{295}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,020:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,051:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2504}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,057:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{65}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,146:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{43}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,153:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{111888}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,283:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,286:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10099}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,293:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{45}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,303:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,305:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{75}'], Pred: [' If you need more information or want to solve another problem, please let me know!<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,307:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: [' If you need the intermediate steps go to the chat prompt.<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,310:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4004}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,311:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,312:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [' Also, the last line of your response should be of the form Answer: $\\boxed<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,343:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,382:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{831}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,396:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{337}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,397:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{343}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,405:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{150}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,406:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,419:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2358}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,438:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,439:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-27}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,461:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{674}'], Pred: [" We don't calculate answers within text.<|endoftext|>"]
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,477:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2006}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,549:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: [' (a+b)^{x}<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,551:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,563:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,598:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{784}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,673:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,694:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,708:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{37}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,726:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2331}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,744:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,768:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{92}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,769:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,772:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1019595}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,780:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{271}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,787:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7200}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,796:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{78}'], Pred: [' **In Progress**<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,797:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{35}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,813:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4021}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,818:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{799}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,819:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: [' Answer:<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,834:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{170}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,835:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,843:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,859:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{47}'], Pred: ['<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,869:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: [' Note: I will output the final answer within \\boxed{} as requested, which will be in the form I can recognize easily.\nAnswer: {}<|endoftext|>']
[36m(main_task pid=68387)[0m WARNING:2025-04-20 22:00:37,873:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{161051}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=70150)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=70150)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
[36m(WorkerDict pid=70150)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=70150)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 4x across cluster][0m
[36m(main_task pid=68387)[0m step:1 - global_seqlen/min:94290.000 - global_seqlen/max:111626.000 - global_seqlen/minmax_diff:17336.000 - global_seqlen/balanced_min:101550.000 - global_seqlen/balanced_max:101551.000 - global_seqlen/mean:101550.500 - critic/kl:-0.001 - critic/kl_coeff:0.001 - critic/vf_loss:18.604 - critic/vf_clipfrac:0.000 - critic/vpred_mean:4.664 - critic/grad_norm:1345.001 - perf/mfu/critic:0.058 - critic/lr:0.000 - actor/entropy_loss:0.516 - actor/pg_loss:-0.004 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.230 - perf/mfu/actor:0.272 - perf/max_memory_allocated_gb:68.562 - perf/max_memory_reserved_gb:77.469 - perf/cpu_memory_used_gb:111.807 - actor/lr:0.000 - critic/score/mean:0.115 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.115 - critic/rewards/max:1.001 - critic/rewards/min:-0.006 - critic/advantages/mean:0.000 - critic/advantages/max:4.984 - critic/advantages/min:-4.845 - critic/returns/mean:0.113 - critic/returns/max:1.001 - critic/returns/min:-0.006 - critic/values/mean:4.562 - critic/values/max:24.250 - critic/values/min:-15.938 - critic/vf_explained_var:-165.089 - response_length/mean:658.693 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.004 - prompt_length/mean:134.670 - prompt_length/max:482.000 - prompt_length/min:56.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:155.748 - timing_s/old_log_prob:14.599 - timing_s/ref:21.204 - timing_s/values:71.354 - timing_s/adv:3.020 - timing_s/update_critic:267.178 - timing_s/update_actor:57.406 - timing_s/step:590.549 - timing_per_token_ms/update_actor:0.141 - timing_per_token_ms/update_critic:0.658 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/ref:0.052 - timing_per_token_ms/gen:0.462 - timing_per_token_ms/values:0.176 - perf/total_num_tokens:406202.000 - perf/time_per_step:590.549 - perf/throughput:171.959
[36m(WorkerDict pid=70347)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=68387)[0m wandb:                                                                                
[36m(main_task pid=68387)[0m wandb: 
[36m(main_task pid=68387)[0m wandb: Run history:
[36m(main_task pid=68387)[0m wandb:                actor/entropy_loss ▁
[36m(main_task pid=68387)[0m wandb:                   actor/grad_norm ▁
[36m(main_task pid=68387)[0m wandb:                          actor/lr ▁
[36m(main_task pid=68387)[0m wandb:                 actor/pg_clipfrac ▁
[36m(main_task pid=68387)[0m wandb:                     actor/pg_loss ▁
[36m(main_task pid=68387)[0m wandb:                      actor/ppo_kl ▁
[36m(main_task pid=68387)[0m wandb:             critic/advantages/max ▁
[36m(main_task pid=68387)[0m wandb:            critic/advantages/mean ▁
[36m(main_task pid=68387)[0m wandb:             critic/advantages/min ▁
[36m(main_task pid=68387)[0m wandb:                  critic/grad_norm ▁
[36m(main_task pid=68387)[0m wandb:                         critic/kl ▁
[36m(main_task pid=68387)[0m wandb:                   critic/kl_coeff ▁
[36m(main_task pid=68387)[0m wandb:                         critic/lr ▁
[36m(main_task pid=68387)[0m wandb:                critic/returns/max ▁
[36m(main_task pid=68387)[0m wandb:               critic/returns/mean ▁
[36m(main_task pid=68387)[0m wandb:                critic/returns/min ▁
[36m(main_task pid=68387)[0m wandb:                critic/rewards/max ▁
[36m(main_task pid=68387)[0m wandb:               critic/rewards/mean ▁
[36m(main_task pid=68387)[0m wandb:                critic/rewards/min ▁
[36m(main_task pid=68387)[0m wandb:                  critic/score/max ▁
[36m(main_task pid=68387)[0m wandb:                 critic/score/mean ▁
[36m(main_task pid=68387)[0m wandb:                  critic/score/min ▁
[36m(main_task pid=68387)[0m wandb:                 critic/values/max ▁
[36m(main_task pid=68387)[0m wandb:                critic/values/mean ▁
[36m(main_task pid=68387)[0m wandb:                 critic/values/min ▁
[36m(main_task pid=68387)[0m wandb:                critic/vf_clipfrac ▁
[36m(main_task pid=68387)[0m wandb:           critic/vf_explained_var ▁
[36m(main_task pid=68387)[0m wandb:                    critic/vf_loss ▁
[36m(main_task pid=68387)[0m wandb:                 critic/vpred_mean ▁
[36m(main_task pid=68387)[0m wandb:        global_seqlen/balanced_max ▁
[36m(main_task pid=68387)[0m wandb:        global_seqlen/balanced_min ▁
[36m(main_task pid=68387)[0m wandb:                 global_seqlen/max ▁
[36m(main_task pid=68387)[0m wandb:                global_seqlen/mean ▁
[36m(main_task pid=68387)[0m wandb:                 global_seqlen/min ▁
[36m(main_task pid=68387)[0m wandb:         global_seqlen/minmax_diff ▁
[36m(main_task pid=68387)[0m wandb:           perf/cpu_memory_used_gb ▁
[36m(main_task pid=68387)[0m wandb:      perf/max_memory_allocated_gb ▁
[36m(main_task pid=68387)[0m wandb:       perf/max_memory_reserved_gb ▁
[36m(main_task pid=68387)[0m wandb:                    perf/mfu/actor ▁
[36m(main_task pid=68387)[0m wandb:                   perf/mfu/critic ▁
[36m(main_task pid=68387)[0m wandb:                   perf/throughput ▁
[36m(main_task pid=68387)[0m wandb:                perf/time_per_step ▁
[36m(main_task pid=68387)[0m wandb:             perf/total_num_tokens ▁
[36m(main_task pid=68387)[0m wandb:          prompt_length/clip_ratio ▁
[36m(main_task pid=68387)[0m wandb:                 prompt_length/max ▁
[36m(main_task pid=68387)[0m wandb:                prompt_length/mean ▁
[36m(main_task pid=68387)[0m wandb:                 prompt_length/min ▁
[36m(main_task pid=68387)[0m wandb:        response_length/clip_ratio ▁
[36m(main_task pid=68387)[0m wandb:               response_length/max ▁
[36m(main_task pid=68387)[0m wandb:              response_length/mean ▁
[36m(main_task pid=68387)[0m wandb:               response_length/min ▁
[36m(main_task pid=68387)[0m wandb:           timing_per_token_ms/adv ▁
[36m(main_task pid=68387)[0m wandb:           timing_per_token_ms/gen ▁
[36m(main_task pid=68387)[0m wandb:           timing_per_token_ms/ref ▁
[36m(main_task pid=68387)[0m wandb:  timing_per_token_ms/update_actor ▁
[36m(main_task pid=68387)[0m wandb: timing_per_token_ms/update_critic ▁
[36m(main_task pid=68387)[0m wandb:        timing_per_token_ms/values ▁
[36m(main_task pid=68387)[0m wandb:                      timing_s/adv ▁
[36m(main_task pid=68387)[0m wandb:                      timing_s/gen ▁
[36m(main_task pid=68387)[0m wandb:             timing_s/old_log_prob ▁
[36m(main_task pid=68387)[0m wandb:                      timing_s/ref ▁
[36m(main_task pid=68387)[0m wandb:                     timing_s/step ▁
[36m(main_task pid=68387)[0m wandb:             timing_s/update_actor ▁
[36m(main_task pid=68387)[0m wandb:            timing_s/update_critic ▁
[36m(main_task pid=68387)[0m wandb:                   timing_s/values ▁
[36m(main_task pid=68387)[0m wandb: 
[36m(main_task pid=68387)[0m wandb: Run summary:
[36m(main_task pid=68387)[0m wandb:                actor/entropy_loss 0.51553
[36m(main_task pid=68387)[0m wandb:                   actor/grad_norm 0.23015
[36m(main_task pid=68387)[0m wandb:                          actor/lr 0.0
[36m(main_task pid=68387)[0m wandb:                 actor/pg_clipfrac 0
[36m(main_task pid=68387)[0m wandb:                     actor/pg_loss -0.00409
[36m(main_task pid=68387)[0m wandb:                      actor/ppo_kl 0
[36m(main_task pid=68387)[0m wandb:             critic/advantages/max 4.98386
[36m(main_task pid=68387)[0m wandb:            critic/advantages/mean 0.0
[36m(main_task pid=68387)[0m wandb:             critic/advantages/min -4.84477
[36m(main_task pid=68387)[0m wandb:                  critic/grad_norm 1345.00104
[36m(main_task pid=68387)[0m wandb:                         critic/kl -0.0009
[36m(main_task pid=68387)[0m wandb:                   critic/kl_coeff 0.001
[36m(main_task pid=68387)[0m wandb:                         critic/lr 1e-05
[36m(main_task pid=68387)[0m wandb:                critic/returns/max 1.00134
[36m(main_task pid=68387)[0m wandb:               critic/returns/mean 0.11343
[36m(main_task pid=68387)[0m wandb:                critic/returns/min -0.00581
[36m(main_task pid=68387)[0m wandb:                critic/rewards/max 1.00127
[36m(main_task pid=68387)[0m wandb:               critic/rewards/mean 0.11523
[36m(main_task pid=68387)[0m wandb:                critic/rewards/min -0.0058
[36m(main_task pid=68387)[0m wandb:                  critic/score/max 1
[36m(main_task pid=68387)[0m wandb:                 critic/score/mean 0.11523
[36m(main_task pid=68387)[0m wandb:                  critic/score/min 0
[36m(main_task pid=68387)[0m wandb:                 critic/values/max 24.25
[36m(main_task pid=68387)[0m wandb:                critic/values/mean 4.5625
[36m(main_task pid=68387)[0m wandb:                 critic/values/min -15.9375
[36m(main_task pid=68387)[0m wandb:                critic/vf_clipfrac 0
[36m(main_task pid=68387)[0m wandb:           critic/vf_explained_var -165.08868
[36m(main_task pid=68387)[0m wandb:                    critic/vf_loss 18.60441
[36m(main_task pid=68387)[0m wandb:                 critic/vpred_mean 4.66406
[36m(main_task pid=68387)[0m wandb:        global_seqlen/balanced_max 101551
[36m(main_task pid=68387)[0m wandb:        global_seqlen/balanced_min 101550
[36m(main_task pid=68387)[0m wandb:                 global_seqlen/max 111626
[36m(main_task pid=68387)[0m wandb:                global_seqlen/mean 101550.5
[36m(main_task pid=68387)[0m wandb:                 global_seqlen/min 94290
[36m(main_task pid=68387)[0m wandb:         global_seqlen/minmax_diff 17336
[36m(main_task pid=68387)[0m wandb:           perf/cpu_memory_used_gb 111.80662
[36m(main_task pid=68387)[0m wandb:      perf/max_memory_allocated_gb 68.56152
[36m(main_task pid=68387)[0m wandb:       perf/max_memory_reserved_gb 77.46875
[36m(main_task pid=68387)[0m wandb:                    perf/mfu/actor 0.27241
[36m(main_task pid=68387)[0m wandb:                   perf/mfu/critic 0.05843
[36m(main_task pid=68387)[0m wandb:                   perf/throughput 171.95946
[36m(main_task pid=68387)[0m wandb:                perf/time_per_step 590.54908
[36m(main_task pid=68387)[0m wandb:             perf/total_num_tokens 406202
[36m(main_task pid=68387)[0m wandb:          prompt_length/clip_ratio 0
[36m(main_task pid=68387)[0m wandb:                 prompt_length/max 482
[36m(main_task pid=68387)[0m wandb:                prompt_length/mean 134.66992
[36m(main_task pid=68387)[0m wandb:                 prompt_length/min 56
[36m(main_task pid=68387)[0m wandb:        response_length/clip_ratio 0.00391
[36m(main_task pid=68387)[0m wandb:               response_length/max 8192
[36m(main_task pid=68387)[0m wandb:              response_length/mean 658.69336
[36m(main_task pid=68387)[0m wandb:               response_length/min 1
[36m(main_task pid=68387)[0m wandb:           timing_per_token_ms/adv 0.00743
[36m(main_task pid=68387)[0m wandb:           timing_per_token_ms/gen 0.46182
[36m(main_task pid=68387)[0m wandb:           timing_per_token_ms/ref 0.0522
[36m(main_task pid=68387)[0m wandb:  timing_per_token_ms/update_actor 0.14132
[36m(main_task pid=68387)[0m wandb: timing_per_token_ms/update_critic 0.65775
[36m(main_task pid=68387)[0m wandb:        timing_per_token_ms/values 0.17566
[36m(main_task pid=68387)[0m wandb:                      timing_s/adv 3.01961
[36m(main_task pid=68387)[0m wandb:                      timing_s/gen 155.74816
[36m(main_task pid=68387)[0m wandb:             timing_s/old_log_prob 14.59871
[36m(main_task pid=68387)[0m wandb:                      timing_s/ref 21.20449
[36m(main_task pid=68387)[0m wandb:                     timing_s/step 590.54908
[36m(main_task pid=68387)[0m wandb:             timing_s/update_actor 57.40645
[36m(main_task pid=68387)[0m wandb:            timing_s/update_critic 267.17827
[36m(main_task pid=68387)[0m wandb:                   timing_s/values 71.35371
[36m(main_task pid=68387)[0m wandb: 
[36m(main_task pid=68387)[0m wandb: 🚀 View run ppo7B_dapo17k_tok8k at: https://wandb.ai/sample-efficient-RL/grpo/runs/7e1lphl9
[36m(main_task pid=68387)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=68387)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=68387)[0m wandb: Find logs at: ./wandb/run-20250420_215610-7e1lphl9/logs
[36m(WorkerDict pid=70347)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=70347)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 3x across cluster][0m
[36m(main_task pid=68387)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=70347, ip=192.168.102.77, actor_id=520527d78df43bec6f87b9640b000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f356d9a1b10>)
[36m(main_task pid=68387)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=68387)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=68387)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=68387)[0m     return func(*args, **kwargs)
[36m(main_task pid=68387)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 513, in generate_sequences
[36m(main_task pid=68387)[0m     output = self.rollout.generate_sequences(prompts=prompts)
[36m(main_task pid=68387)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(main_task pid=68387)[0m     return func(*args, **kwargs)
[36m(main_task pid=68387)[0m   File "/home/jovyan/project/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 161, in generate_sequences
[36m(main_task pid=68387)[0m     self.inference_engine.init_cache_engine()
[36m(main_task pid=68387)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 146, in init_cache_engine
[36m(main_task pid=68387)[0m     self.llm_engine.init_cache_engine()
[36m(main_task pid=68387)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 347, in init_cache_engine
[36m(main_task pid=68387)[0m     self.model_executor.init_cache_engine()
[36m(main_task pid=68387)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 157, in init_cache_engine
[36m(main_task pid=68387)[0m     self.worker._init_cache_engine()
[36m(main_task pid=68387)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 237, in _init_cache_engine
[36m(main_task pid=68387)[0m     super()._init_cache_engine()
[36m(main_task pid=68387)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 275, in _init_cache_engine
[36m(main_task pid=68387)[0m     self.cache_engine = [
[36m(main_task pid=68387)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 276, in <listcomp>
[36m(main_task pid=68387)[0m     CacheEngine(self.cache_config, self.model_config,
[36m(main_task pid=68387)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 63, in __init__
[36m(main_task pid=68387)[0m     self.gpu_cache = self._allocate_kv_cache(
[36m(main_task pid=68387)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 82, in _allocate_kv_cache
[36m(main_task pid=68387)[0m     torch.zeros(kv_cache_shape,
[36m(main_task pid=68387)[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 754.75 MiB is free. Process 154768 has 78.48 GiB memory in use. Of the allocated memory 72.01 GiB is allocated by PyTorch, and 4.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: ['data.train_files=./data/DAPO-17k-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=512', 'data.max_prompt_length=512', 'data.max_response_length=8192', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-7B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=5e-7', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=128', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=4', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4', 'critic.optim.lr=5e-6', 'critic.model.path=Qwen/Qwen2.5-7B', 'critic.ppo_micro_batch_size_per_gpu=4', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=False', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.total_training_steps=500', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=5', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo7B_dapo17k_tok8k', 'trainer.total_epochs=10', 'curriculum.use_curriculum_learning=True', 'curriculum.train_batch_size_pool=2048', 'curriculum.warmup_steps=3']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::main_task()[39m (pid=68387, ip=192.168.102.77)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 1064, in fit
    gen_batch_output = self.actor_rollout_wg.generate_sequences(gen_batch)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=70348, ip=192.168.102.77, actor_id=51b86527a67a53dc4d98c12b0b000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7faf329f9090>)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 513, in generate_sequences
    output = self.rollout.generate_sequences(prompts=prompts)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 161, in generate_sequences
    self.inference_engine.init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 146, in init_cache_engine
    self.llm_engine.init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 347, in init_cache_engine
    self.model_executor.init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 157, in init_cache_engine
    self.worker._init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 237, in _init_cache_engine
    super()._init_cache_engine()
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 275, in _init_cache_engine
    self.cache_engine = [
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 276, in <listcomp>
    CacheEngine(self.cache_config, self.model_config,
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 63, in __init__
    self.gpu_cache = self._allocate_kv_cache(
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 82, in _allocate_kv_cache
    torch.zeros(kv_cache_shape,
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 438.75 MiB is free. Process 154769 has 78.79 GiB memory in use. Of the allocated memory 72.06 GiB is allocated by PyTorch, and 4.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 5e-7
Critic LR: 5e-6
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 512
PPO Mini Batch Size: 128
PPO Micro Batch Size: 1
Total Epochs: 10
Max Response Length: 8192
GPU Memory Utilization: 0.7
Test Frequency: 5
Number of GPUs: 4
Total Training Steps: 500
Compute Prompts Values: False
Experiment Name: ppo7B_dapo17k_tok8k
2025-04-20 22:22:22,611	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.102.77:6379...
2025-04-20 22:22:22,622	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=77271)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=77271)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=77271)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=77271)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=77271)[0m                                                  'param_offload': False,
[36m(main_task pid=77271)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=77271)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=77271)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=77271)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=77271)[0m                                  'optim': {'lr': 5e-07,
[36m(main_task pid=77271)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=77271)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=77271)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=77271)[0m                                            'total_training_steps': -1,
[36m(main_task pid=77271)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=77271)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=77271)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=77271)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=77271)[0m                                  'ppo_micro_batch_size_per_gpu': 1,
[36m(main_task pid=77271)[0m                                  'ppo_mini_batch_size': 128,
[36m(main_task pid=77271)[0m                                  'response_length': 8192,
[36m(main_task pid=77271)[0m                                  'shuffle': False,
[36m(main_task pid=77271)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=77271)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=77271)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=77271)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=77271)[0m                                  'use_kl_loss': False,
[36m(main_task pid=77271)[0m                                  'use_torch_compile': True},
[36m(main_task pid=77271)[0m                        'hybrid_engine': True,
[36m(main_task pid=77271)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=77271)[0m                                  'external_lib': None,
[36m(main_task pid=77271)[0m                                  'override_config': {},
[36m(main_task pid=77271)[0m                                  'path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=77271)[0m                                  'use_remove_padding': True},
[36m(main_task pid=77271)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=77271)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=77271)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=77271)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=77271)[0m                                'log_prob_micro_batch_size_per_gpu': 1,
[36m(main_task pid=77271)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=77271)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=77271)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=77271)[0m                                    'disable_log_stats': True,
[36m(main_task pid=77271)[0m                                    'do_sample': True,
[36m(main_task pid=77271)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=77271)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=77271)[0m                                    'enforce_eager': True,
[36m(main_task pid=77271)[0m                                    'free_cache_engine': True,
[36m(main_task pid=77271)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=77271)[0m                                    'ignore_eos': False,
[36m(main_task pid=77271)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=77271)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=77271)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=77271)[0m                                    'log_prob_micro_batch_size_per_gpu': 1,
[36m(main_task pid=77271)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=77271)[0m                                    'max_model_len': None,
[36m(main_task pid=77271)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=77271)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=77271)[0m                                    'n': 1,
[36m(main_task pid=77271)[0m                                    'name': 'vllm',
[36m(main_task pid=77271)[0m                                    'prompt_length': 512,
[36m(main_task pid=77271)[0m                                    'response_length': 8192,
[36m(main_task pid=77271)[0m                                    'temperature': 1.0,
[36m(main_task pid=77271)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=77271)[0m                                    'top_k': -1,
[36m(main_task pid=77271)[0m                                    'top_p': 1,
[36m(main_task pid=77271)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=77271)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=77271)[0m                                                   'n': 1,
[36m(main_task pid=77271)[0m                                                   'temperature': 0,
[36m(main_task pid=77271)[0m                                                   'top_k': -1,
[36m(main_task pid=77271)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=77271)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=77271)[0m                'gamma': 1.0,
[36m(main_task pid=77271)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=77271)[0m                'kl_penalty': 'kl',
[36m(main_task pid=77271)[0m                'lam': 1.0},
[36m(main_task pid=77271)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=77271)[0m             'estimate_prompts_value': False,
[36m(main_task pid=77271)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=77271)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=77271)[0m             'forward_micro_batch_size_per_gpu': 1,
[36m(main_task pid=77271)[0m             'grad_clip': 1.0,
[36m(main_task pid=77271)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=77271)[0m                       'external_lib': None,
[36m(main_task pid=77271)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=77271)[0m                                       'optimizer_offload': False,
[36m(main_task pid=77271)[0m                                       'param_offload': False,
[36m(main_task pid=77271)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=77271)[0m                       'override_config': {},
[36m(main_task pid=77271)[0m                       'path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=77271)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=77271)[0m                       'use_remove_padding': False},
[36m(main_task pid=77271)[0m             'optim': {'lr': 5e-06,
[36m(main_task pid=77271)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=77271)[0m                       'min_lr_ratio': None,
[36m(main_task pid=77271)[0m                       'total_training_steps': -1,
[36m(main_task pid=77271)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=77271)[0m             'ppo_epochs': 1,
[36m(main_task pid=77271)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=77271)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=77271)[0m             'ppo_micro_batch_size_per_gpu': 1,
[36m(main_task pid=77271)[0m             'ppo_mini_batch_size': 128,
[36m(main_task pid=77271)[0m             'shuffle': False,
[36m(main_task pid=77271)[0m             'strategy': 'fsdp',
[36m(main_task pid=77271)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=77271)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=77271)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=77271)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=77271)[0m                 'train_batch_size_pool': 2048,
[36m(main_task pid=77271)[0m                 'use_curriculum_learning': True,
[36m(main_task pid=77271)[0m                 'warmup_steps': 3},
[36m(main_task pid=77271)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=77271)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=77271)[0m           'image_key': 'images',
[36m(main_task pid=77271)[0m           'max_prompt_length': 512,
[36m(main_task pid=77271)[0m           'max_response_length': 8192,
[36m(main_task pid=77271)[0m           'prompt_key': 'prompt',
[36m(main_task pid=77271)[0m           'return_raw_chat': False,
[36m(main_task pid=77271)[0m           'return_raw_input_ids': False,
[36m(main_task pid=77271)[0m           'shuffle': True,
[36m(main_task pid=77271)[0m           'tokenizer': None,
[36m(main_task pid=77271)[0m           'train_batch_size': 512,
[36m(main_task pid=77271)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=77271)[0m           'truncation': 'error',
[36m(main_task pid=77271)[0m           'use_chat_template': False,
[36m(main_task pid=77271)[0m           'val_batch_size': None,
[36m(main_task pid=77271)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=77271)[0m  'reward_model': {'enable': False,
[36m(main_task pid=77271)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=77271)[0m                   'max_length': None,
[36m(main_task pid=77271)[0m                   'micro_batch_size': None,
[36m(main_task pid=77271)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=77271)[0m                   'model': {'external_lib': None,
[36m(main_task pid=77271)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=77271)[0m                                             'param_offload': False,
[36m(main_task pid=77271)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=77271)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=77271)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=77271)[0m                             'use_remove_padding': False},
[36m(main_task pid=77271)[0m                   'reward_manager': 'naive',
[36m(main_task pid=77271)[0m                   'strategy': 'fsdp',
[36m(main_task pid=77271)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=77271)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=77271)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=77271)[0m              'critic_warmup': 0,
[36m(main_task pid=77271)[0m              'default_hdfs_dir': None,
[36m(main_task pid=77271)[0m              'default_local_dir': 'checkpoints/grpo/ppo7B_dapo17k_tok8k',
[36m(main_task pid=77271)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=77271)[0m              'experiment_name': 'ppo7B_dapo17k_tok8k',
[36m(main_task pid=77271)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=77271)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=77271)[0m              'nnodes': 1,
[36m(main_task pid=77271)[0m              'project_name': 'grpo',
[36m(main_task pid=77271)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=77271)[0m              'resume_from_path': False,
[36m(main_task pid=77271)[0m              'resume_mode': 'auto',
[36m(main_task pid=77271)[0m              'save_freq': -1,
[36m(main_task pid=77271)[0m              'test_freq': 5,
[36m(main_task pid=77271)[0m              'total_epochs': 10,
[36m(main_task pid=77271)[0m              'total_training_steps': 500,
[36m(main_task pid=77271)[0m              'val_before_train': False,
[36m(main_task pid=77271)[0m              'val_generations_to_log_to_wandb': 0,
[36m(main_task pid=77271)[0m              'val_only': False}}
[36m(main_task pid=77271)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=77271)[0m No module named 'vllm._version'
[36m(main_task pid=77271)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=77271)[0m 'We use curriculum learning.'
[36m(main_task pid=77271)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=77271)[0m dataset len: 1791700
[36m(main_task pid=77271)[0m Example prompt before filtering: The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=77271)[0m 
[36m(main_task pid=77271)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$. Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=77271)[0m filter dataset len: 1786200
[36m(main_task pid=77271)[0m dataset len: 500
[36m(main_task pid=77271)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=77271)[0m filter dataset len: 497
[36m(main_task pid=77271)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=77271)[0m Size of train dataloader: 3488
[36m(main_task pid=77271)[0m Size of val dataloader: 1
[36m(main_task pid=77271)[0m Total training steps: 500
[36m(main_task pid=77271)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=79035)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=79035)[0m No module named 'vllm._version'
[36m(pid=79035)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=79245)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=79245)[0m No module named 'vllm._version'
[36m(pid=79245)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=79247)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=79247)[0m No module named 'vllm._version'
[36m(pid=79247)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=79035)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=79035)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=79035)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=79035)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=79245)[0m Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  4.62it/s]
[36m(WorkerDict pid=79246)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.74it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.55it/s]
[36m(WorkerDict pid=79246)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-7B and are newly initialized: ['score.bias']
[36m(WorkerDict pid=79246)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(pid=79246)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=79246)[0m No module named 'vllm._version'
[36m(pid=79246)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=79035)[0m Qwen2ForTokenClassification contains 7.07B parameters
[36m(WorkerDict pid=79035)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=79035)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-7B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=79246)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=79246)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79246)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79035)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=79245)[0m Total steps: 500, num_warmup_steps: 0
[36m(WorkerDict pid=79245)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=79035)[0m After critic FSDP, memory allocated (GB): 6.585044860839844, memory reserved (GB): 14.544921875
[36m(WorkerDict pid=79035)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=79035)[0m   "_name_or_path": "Qwen/Qwen2.5-7B",
[36m(WorkerDict pid=79035)[0m   "architectures": [
[36m(WorkerDict pid=79035)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=79035)[0m   ],
[36m(WorkerDict pid=79035)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=79035)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=79035)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=79035)[0m   "hidden_size": 3584,
[36m(WorkerDict pid=79035)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=79035)[0m   "intermediate_size": 18944,
[36m(WorkerDict pid=79035)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=79035)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=79035)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=79035)[0m   "num_attention_heads": 28,
[36m(WorkerDict pid=79035)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=79035)[0m   "num_key_value_heads": 4,
[36m(WorkerDict pid=79035)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=79035)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=79035)[0m   "rope_scaling": null,
[36m(WorkerDict pid=79035)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=79035)[0m   "sliding_window": null,
[36m(WorkerDict pid=79035)[0m   "tie_word_embeddings": false,
[36m(WorkerDict pid=79035)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=79035)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=79035)[0m   "use_cache": true,
[36m(WorkerDict pid=79035)[0m   "use_mrope": false,
[36m(WorkerDict pid=79035)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=79035)[0m   "vocab_size": 152064
[36m(WorkerDict pid=79035)[0m }
[36m(WorkerDict pid=79035)[0m 
[36m(WorkerDict pid=79035)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.37s/it][32m [repeated 11x across cluster][0m
[36m(WorkerDict pid=79035)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.26s/it][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79247)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-7B and are newly initialized: ['score.bias'][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=79035)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79035)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=79245)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=79035)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(WorkerDict pid=79035)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f7a92a7c0d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f7a92a43f40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=79247)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=79247)[0m Total steps: 500, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79247)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79035)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=79035)[0m   "_name_or_path": "Qwen/Qwen2.5-7B",
[36m(WorkerDict pid=79035)[0m   "architectures": [
[36m(WorkerDict pid=79035)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=79035)[0m   ],
[36m(WorkerDict pid=79035)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=79035)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=79035)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=79035)[0m   "hidden_size": 3584,
[36m(WorkerDict pid=79035)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=79035)[0m   "intermediate_size": 18944,
[36m(WorkerDict pid=79035)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=79035)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=79035)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=79035)[0m   "num_attention_heads": 28,
[36m(WorkerDict pid=79035)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=79035)[0m   "num_key_value_heads": 4,
[36m(WorkerDict pid=79035)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=79035)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=79035)[0m   "rope_scaling": null,
[36m(WorkerDict pid=79035)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=79035)[0m   "sliding_window": null,
[36m(WorkerDict pid=79035)[0m   "tie_word_embeddings": false,
[36m(WorkerDict pid=79035)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=79035)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=79035)[0m   "use_cache": true,
[36m(WorkerDict pid=79035)[0m   "use_mrope": false,
[36m(WorkerDict pid=79035)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=79035)[0m   "vocab_size": 152064
[36m(WorkerDict pid=79035)[0m }
[36m(WorkerDict pid=79035)[0m 
[36m(WorkerDict pid=79246)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f82aea7c0d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f82aea43f40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79035)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=79246)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.28it/s][32m [repeated 12x across cluster][0m
[36m(WorkerDict pid=79246)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.58it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.24it/s][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=79246)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=79035)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(WorkerDict pid=79246)[0m Actor use_remove_padding=True[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79035)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f7a92a7c0d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f7a92a43f40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=79247)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79035)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.41s/it][32m [repeated 12x across cluster][0m
[36m(WorkerDict pid=79035)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.38s/it][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=79247)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=79245)[0m wrap_policy: functools.partial(<function _or_policy at 0x7edc184e00d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7edc184a7f40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=79245)[0m Total steps: 500, num_warmup_steps: 0
[36m(WorkerDict pid=79035)[0m Before building vllm rollout, memory allocated (GB): 13.678153038024902, memory reserved (GB): 28.693359375
[36m(WorkerDict pid=79035)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=79247)[0m WARNING 04-20 22:30:44 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=79035)[0m Actor use_remove_padding=True[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=79246)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f82aea7c0d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f82aea43f40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=79247)[0m local rank 0
[36m(WorkerDict pid=79246)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=79035)[0m Total steps: 500, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79246)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79035)[0m before init cache memory allocated: 30.009989632GB, reserved: 30.23044608GB
[36m(WorkerDict pid=79035)[0m after init cache memory allocated: 66.00550656GB, reserved: 66.225963008GB
[36m(WorkerDict pid=79245)[0m WARNING 04-20 22:30:45 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79245)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79247)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=79247)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=79247)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=79247)[0m   warnings.warn(
[36m(main_task pid=77271)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(WorkerDict pid=79035)[0m After building vllm rollout, memory allocated (GB): 47.24077892303467, memory reserved (GB): 61.677734375
[36m(WorkerDict pid=79035)[0m After building sharding manager, memory allocated (GB): 47.24077892303467, memory reserved (GB): 61.677734375
[36m(main_task pid=77271)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=77271)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=77271)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250420_223052-novuv6v5
[36m(main_task pid=77271)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=77271)[0m wandb: Syncing run ppo7B_dapo17k_tok8k
[36m(main_task pid=77271)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=77271)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/novuv6v5
[36m(main_task pid=77271)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=77271)[0m '######################## Total training steps: 500 ########################'
[36m(main_task pid=77271)[0m 'Total training steps: 500'
[36m(main_task pid=77271)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo7B_dapo17k_tok8k/latest_checkpointed_iteration.txt
[36m(main_task pid=77271)[0m Training from scratch
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,489:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,491:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: [' Answer:<|endoftext|>']
[36m(WorkerDict pid=79035)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79035)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,683:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,693:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,719:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1314}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,756:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{35}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,842:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,843:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,859:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2024}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,948:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,950:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{387}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,958:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{506}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,977:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,986:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{594}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,994:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{49}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,998:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{43}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:58,999:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{246}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,030:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,032:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{15}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,035:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{367}'], Pred: [' Okay!<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,049:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,056:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2035151}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,061:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,071:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,081:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: [' \nAnswer: $Answer<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,132:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{28}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,168:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,232:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{34}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,233:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{24}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,238:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,251:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,273:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,278:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{255}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,315:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3987}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,333:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{85}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,351:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1524}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,373:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{53}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,379:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{71}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,382:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10000}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,387:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1983}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,408:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{92}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,494:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{164}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,495:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,515:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2018}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,522:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,930:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{295}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,960:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,992:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2504}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:35:59,998:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{65}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,082:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{43}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,089:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{111888}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,215:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,218:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{10099}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,225:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{45}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,235:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{19}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,237:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{75}'], Pred: [' If you need more information or want to solve another problem, please let me know!<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,238:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2}'], Pred: [' If you need the intermediate steps go to the chat prompt.<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,242:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4004}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,243:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{9}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,244:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [' Also, the last line of your response should be of the form Answer: $\\boxed<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,275:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,312:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{831}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,327:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{337}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,328:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{343}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,335:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{150}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,337:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{11}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,350:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2358}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,368:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,369:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-27}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,390:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{674}'], Pred: [" We don't calculate answers within text.<|endoftext|>"]
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,404:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2006}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,478:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: [' (a+b)^{x}<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,480:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,491:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,523:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{784}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,595:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{21}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,616:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{18}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,628:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{37}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,646:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2331}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,664:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,687:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{92}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,688:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{8}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,691:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1019595}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,698:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{271}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,706:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7200}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,714:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{78}'], Pred: [' **In Progress**<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,716:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{35}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,731:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4021}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,736:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{799}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,737:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{6}'], Pred: [' Answer:<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,751:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{170}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,753:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{12}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,760:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{20}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,776:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{47}'], Pred: ['<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,786:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{25}'], Pred: [' Note: I will output the final answer within \\boxed{} as requested, which will be in the form I can recognize easily.\nAnswer: {}<|endoftext|>']
[36m(main_task pid=77271)[0m WARNING:2025-04-20 22:36:00,790:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{161051}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=79035)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=79035)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
[36m(WorkerDict pid=79035)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=79035)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 4x across cluster][0m
[36m(main_task pid=77271)[0m step:1 - global_seqlen/min:94290.000 - global_seqlen/max:111626.000 - global_seqlen/minmax_diff:17336.000 - global_seqlen/balanced_min:101550.000 - global_seqlen/balanced_max:101551.000 - global_seqlen/mean:101550.500 - critic/kl:0.002 - critic/kl_coeff:0.001 - critic/vf_loss:5.772 - critic/vf_clipfrac:0.000 - critic/vpred_mean:-0.172 - critic/grad_norm:185.979 - perf/mfu/critic:0.052 - critic/lr:0.000 - actor/entropy_loss:1.101 - actor/pg_loss:-0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.067 - perf/mfu/actor:0.155 - perf/max_memory_allocated_gb:68.562 - perf/max_memory_reserved_gb:77.461 - perf/cpu_memory_used_gb:110.902 - actor/lr:0.000 - critic/score/mean:0.115 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.115 - critic/rewards/max:1.001 - critic/rewards/min:-0.006 - critic/advantages/mean:0.000 - critic/advantages/max:4.812 - critic/advantages/min:-5.610 - critic/returns/mean:0.113 - critic/returns/max:1.001 - critic/returns/min:-0.006 - critic/values/mean:-0.044 - critic/values/max:21.375 - critic/values/min:-18.625 - critic/vf_explained_var:-145.321 - response_length/mean:658.693 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.004 - prompt_length/mean:134.670 - prompt_length/max:482.000 - prompt_length/min:56.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:149.309 - timing_s/old_log_prob:22.380 - timing_s/ref:57.136 - timing_s/values:75.898 - timing_s/adv:3.014 - timing_s/update_critic:298.906 - timing_s/update_actor:100.733 - timing_s/step:707.422 - timing_per_token_ms/update_critic:0.736 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/ref:0.141 - timing_per_token_ms/update_actor:0.248 - timing_per_token_ms/values:0.187 - timing_per_token_ms/gen:0.443 - perf/total_num_tokens:406202.000 - perf/time_per_step:707.422 - perf/throughput:143.550
[36m(WorkerDict pid=79035)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=77271)[0m wandb:                                                                                
[36m(main_task pid=77271)[0m wandb: 
[36m(main_task pid=77271)[0m wandb: Run history:
[36m(main_task pid=77271)[0m wandb:                actor/entropy_loss ▁
[36m(main_task pid=77271)[0m wandb:                   actor/grad_norm ▁
[36m(main_task pid=77271)[0m wandb:                          actor/lr ▁
[36m(main_task pid=77271)[0m wandb:                 actor/pg_clipfrac ▁
[36m(main_task pid=77271)[0m wandb:                     actor/pg_loss ▁
[36m(main_task pid=77271)[0m wandb:                      actor/ppo_kl ▁
[36m(main_task pid=77271)[0m wandb:             critic/advantages/max ▁
[36m(main_task pid=77271)[0m wandb:            critic/advantages/mean ▁
[36m(main_task pid=77271)[0m wandb:             critic/advantages/min ▁
[36m(main_task pid=77271)[0m wandb:                  critic/grad_norm ▁
[36m(main_task pid=77271)[0m wandb:                         critic/kl ▁
[36m(main_task pid=77271)[0m wandb:                   critic/kl_coeff ▁
[36m(main_task pid=77271)[0m wandb:                         critic/lr ▁
[36m(main_task pid=77271)[0m wandb:                critic/returns/max ▁
[36m(main_task pid=77271)[0m wandb:               critic/returns/mean ▁
[36m(main_task pid=77271)[0m wandb:                critic/returns/min ▁
[36m(main_task pid=77271)[0m wandb:                critic/rewards/max ▁
[36m(main_task pid=77271)[0m wandb:               critic/rewards/mean ▁
[36m(main_task pid=77271)[0m wandb:                critic/rewards/min ▁
[36m(main_task pid=77271)[0m wandb:                  critic/score/max ▁
[36m(main_task pid=77271)[0m wandb:                 critic/score/mean ▁
[36m(main_task pid=77271)[0m wandb:                  critic/score/min ▁
[36m(main_task pid=77271)[0m wandb:                 critic/values/max ▁
[36m(main_task pid=77271)[0m wandb:                critic/values/mean ▁
[36m(main_task pid=77271)[0m wandb:                 critic/values/min ▁
[36m(main_task pid=77271)[0m wandb:                critic/vf_clipfrac ▁
[36m(main_task pid=77271)[0m wandb:           critic/vf_explained_var ▁
[36m(main_task pid=77271)[0m wandb:                    critic/vf_loss ▁
[36m(main_task pid=77271)[0m wandb:                 critic/vpred_mean ▁
[36m(main_task pid=77271)[0m wandb:        global_seqlen/balanced_max ▁
[36m(main_task pid=77271)[0m wandb:        global_seqlen/balanced_min ▁
[36m(main_task pid=77271)[0m wandb:                 global_seqlen/max ▁
[36m(main_task pid=77271)[0m wandb:                global_seqlen/mean ▁
[36m(main_task pid=77271)[0m wandb:                 global_seqlen/min ▁
[36m(main_task pid=77271)[0m wandb:         global_seqlen/minmax_diff ▁
[36m(main_task pid=77271)[0m wandb:           perf/cpu_memory_used_gb ▁
[36m(main_task pid=77271)[0m wandb:      perf/max_memory_allocated_gb ▁
[36m(main_task pid=77271)[0m wandb:       perf/max_memory_reserved_gb ▁
[36m(main_task pid=77271)[0m wandb:                    perf/mfu/actor ▁
[36m(main_task pid=77271)[0m wandb:                   perf/mfu/critic ▁
[36m(main_task pid=77271)[0m wandb:                   perf/throughput ▁
[36m(main_task pid=77271)[0m wandb:                perf/time_per_step ▁
[36m(main_task pid=77271)[0m wandb:             perf/total_num_tokens ▁
[36m(main_task pid=77271)[0m wandb:          prompt_length/clip_ratio ▁
[36m(main_task pid=77271)[0m wandb:                 prompt_length/max ▁
[36m(main_task pid=77271)[0m wandb:                prompt_length/mean ▁
[36m(main_task pid=77271)[0m wandb:                 prompt_length/min ▁
[36m(main_task pid=77271)[0m wandb:        response_length/clip_ratio ▁
[36m(main_task pid=77271)[0m wandb:               response_length/max ▁
[36m(main_task pid=77271)[0m wandb:              response_length/mean ▁
[36m(main_task pid=77271)[0m wandb:               response_length/min ▁
[36m(main_task pid=77271)[0m wandb:           timing_per_token_ms/adv ▁
[36m(main_task pid=77271)[0m wandb:           timing_per_token_ms/gen ▁
[36m(main_task pid=77271)[0m wandb:           timing_per_token_ms/ref ▁
[36m(main_task pid=77271)[0m wandb:  timing_per_token_ms/update_actor ▁
[36m(main_task pid=77271)[0m wandb: timing_per_token_ms/update_critic ▁
[36m(main_task pid=77271)[0m wandb:        timing_per_token_ms/values ▁
[36m(main_task pid=77271)[0m wandb:                      timing_s/adv ▁
[36m(main_task pid=77271)[0m wandb:                      timing_s/gen ▁
[36m(main_task pid=77271)[0m wandb:             timing_s/old_log_prob ▁
[36m(main_task pid=77271)[0m wandb:                      timing_s/ref ▁
[36m(main_task pid=77271)[0m wandb:                     timing_s/step ▁
[36m(main_task pid=77271)[0m wandb:             timing_s/update_actor ▁
[36m(main_task pid=77271)[0m wandb:            timing_s/update_critic ▁
[36m(main_task pid=77271)[0m wandb:                   timing_s/values ▁
[36m(main_task pid=77271)[0m wandb: 
[36m(main_task pid=77271)[0m wandb: Run summary:
[36m(main_task pid=77271)[0m wandb:                actor/entropy_loss 1.10149
[36m(main_task pid=77271)[0m wandb:                   actor/grad_norm 0.06669
[36m(main_task pid=77271)[0m wandb:                          actor/lr 0.0
[36m(main_task pid=77271)[0m wandb:                 actor/pg_clipfrac 0
[36m(main_task pid=77271)[0m wandb:                     actor/pg_loss -0.00046
[36m(main_task pid=77271)[0m wandb:                      actor/ppo_kl 0
[36m(main_task pid=77271)[0m wandb:             critic/advantages/max 4.81177
[36m(main_task pid=77271)[0m wandb:            critic/advantages/mean 0.0
[36m(main_task pid=77271)[0m wandb:             critic/advantages/min -5.61042
[36m(main_task pid=77271)[0m wandb:                  critic/grad_norm 185.9794
[36m(main_task pid=77271)[0m wandb:                         critic/kl 0.00174
[36m(main_task pid=77271)[0m wandb:                   critic/kl_coeff 0.001
[36m(main_task pid=77271)[0m wandb:                         critic/lr 1e-05
[36m(main_task pid=77271)[0m wandb:                critic/returns/max 1.00134
[36m(main_task pid=77271)[0m wandb:               critic/returns/mean 0.11341
[36m(main_task pid=77271)[0m wandb:                critic/returns/min -0.00583
[36m(main_task pid=77271)[0m wandb:                critic/rewards/max 1.00127
[36m(main_task pid=77271)[0m wandb:               critic/rewards/mean 0.11518
[36m(main_task pid=77271)[0m wandb:                critic/rewards/min -0.0058
[36m(main_task pid=77271)[0m wandb:                  critic/score/max 1
[36m(main_task pid=77271)[0m wandb:                 critic/score/mean 0.11523
[36m(main_task pid=77271)[0m wandb:                  critic/score/min 0
[36m(main_task pid=77271)[0m wandb:                 critic/values/max 21.375
[36m(main_task pid=77271)[0m wandb:                critic/values/mean -0.04443
[36m(main_task pid=77271)[0m wandb:                 critic/values/min -18.625
[36m(main_task pid=77271)[0m wandb:                critic/vf_clipfrac 0
[36m(main_task pid=77271)[0m wandb:           critic/vf_explained_var -145.32077
[36m(main_task pid=77271)[0m wandb:                    critic/vf_loss 5.772
[36m(main_task pid=77271)[0m wandb:                 critic/vpred_mean -0.17155
[36m(main_task pid=77271)[0m wandb:        global_seqlen/balanced_max 101551
[36m(main_task pid=77271)[0m wandb:        global_seqlen/balanced_min 101550
[36m(main_task pid=77271)[0m wandb:                 global_seqlen/max 111626
[36m(main_task pid=77271)[0m wandb:                global_seqlen/mean 101550.5
[36m(main_task pid=77271)[0m wandb:                 global_seqlen/min 94290
[36m(main_task pid=77271)[0m wandb:         global_seqlen/minmax_diff 17336
[36m(main_task pid=77271)[0m wandb:           perf/cpu_memory_used_gb 110.90153
[36m(main_task pid=77271)[0m wandb:      perf/max_memory_allocated_gb 68.56152
[36m(main_task pid=77271)[0m wandb:       perf/max_memory_reserved_gb 77.46094
[36m(main_task pid=77271)[0m wandb:                    perf/mfu/actor 0.15508
[36m(main_task pid=77271)[0m wandb:                   perf/mfu/critic 0.05223
[36m(main_task pid=77271)[0m wandb:                   perf/throughput 143.55009
[36m(main_task pid=77271)[0m wandb:                perf/time_per_step 707.42207
[36m(main_task pid=77271)[0m wandb:             perf/total_num_tokens 406202
[36m(main_task pid=77271)[0m wandb:          prompt_length/clip_ratio 0
[36m(main_task pid=77271)[0m wandb:                 prompt_length/max 482
[36m(main_task pid=77271)[0m wandb:                prompt_length/mean 134.66992
[36m(main_task pid=77271)[0m wandb:                 prompt_length/min 56
[36m(main_task pid=77271)[0m wandb:        response_length/clip_ratio 0.00391
[36m(main_task pid=77271)[0m wandb:               response_length/max 8192
[36m(main_task pid=77271)[0m wandb:              response_length/mean 658.69336
[36m(main_task pid=77271)[0m wandb:               response_length/min 1
[36m(main_task pid=77271)[0m wandb:           timing_per_token_ms/adv 0.00742
[36m(main_task pid=77271)[0m wandb:           timing_per_token_ms/gen 0.44272
[36m(main_task pid=77271)[0m wandb:           timing_per_token_ms/ref 0.14066
[36m(main_task pid=77271)[0m wandb:  timing_per_token_ms/update_actor 0.24799
[36m(main_task pid=77271)[0m wandb: timing_per_token_ms/update_critic 0.73585
[36m(main_task pid=77271)[0m wandb:        timing_per_token_ms/values 0.18685
[36m(main_task pid=77271)[0m wandb:                      timing_s/adv 3.01428
[36m(main_task pid=77271)[0m wandb:                      timing_s/gen 149.30914
[36m(main_task pid=77271)[0m wandb:             timing_s/old_log_prob 22.38048
[36m(main_task pid=77271)[0m wandb:                      timing_s/ref 57.13613
[36m(main_task pid=77271)[0m wandb:                     timing_s/step 707.42207
[36m(main_task pid=77271)[0m wandb:             timing_s/update_actor 100.73288
[36m(main_task pid=77271)[0m wandb:            timing_s/update_critic 298.90559
[36m(main_task pid=77271)[0m wandb:                   timing_s/values 75.89843
[36m(main_task pid=77271)[0m wandb: 
[36m(main_task pid=77271)[0m wandb: 🚀 View run ppo7B_dapo17k_tok8k at: https://wandb.ai/sample-efficient-RL/grpo/runs/novuv6v5
[36m(main_task pid=77271)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=77271)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=77271)[0m wandb: Find logs at: ./wandb/run-20250420_223052-novuv6v5/logs
[36m(WorkerDict pid=79246)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=79246)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 3x across cluster][0m
Error executing job with overrides: ['data.train_files=./data/DAPO-17k-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=512', 'data.max_prompt_length=512', 'data.max_response_length=8192', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-7B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=5e-7', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=128', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=1', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=1', 'critic.optim.lr=5e-6', 'critic.model.path=Qwen/Qwen2.5-7B', 'critic.ppo_micro_batch_size_per_gpu=1', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=False', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.total_training_steps=500', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=5', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo7B_dapo17k_tok8k', 'trainer.total_epochs=10', 'curriculum.use_curriculum_learning=True', 'curriculum.train_batch_size_pool=2048', 'curriculum.warmup_steps=3']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::main_task()[39m (pid=77271, ip=192.168.102.77)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 1064, in fit
    gen_batch_output = self.actor_rollout_wg.generate_sequences(gen_batch)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=79247, ip=192.168.102.77, actor_id=72bb7a1e02cdbe0be41e22a40c000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f13a1a31090>)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 513, in generate_sequences
    output = self.rollout.generate_sequences(prompts=prompts)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 161, in generate_sequences
    self.inference_engine.init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 146, in init_cache_engine
    self.llm_engine.init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 347, in init_cache_engine
    self.model_executor.init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 157, in init_cache_engine
    self.worker._init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 237, in _init_cache_engine
    super()._init_cache_engine()
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 275, in _init_cache_engine
    self.cache_engine = [
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 276, in <listcomp>
    CacheEngine(self.cache_config, self.model_config,
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 63, in __init__
    self.gpu_cache = self._allocate_kv_cache(
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 82, in _allocate_kv_cache
    torch.zeros(kv_cache_shape,
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 100.75 MiB is free. Process 188988 has 79.12 GiB memory in use. Of the allocated memory 74.46 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(main_task pid=77271)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=79245, ip=192.168.102.77, actor_id=cc30ee2f7b1b57c3e9dfd2520c000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7edbb9531870>)
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=77271)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=77271)[0m     return func(*args, **kwargs)
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 513, in generate_sequences
[36m(main_task pid=77271)[0m     output = self.rollout.generate_sequences(prompts=prompts)
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(main_task pid=77271)[0m     return func(*args, **kwargs)
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 161, in generate_sequences
[36m(main_task pid=77271)[0m     self.inference_engine.init_cache_engine()
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 146, in init_cache_engine
[36m(main_task pid=77271)[0m     self.llm_engine.init_cache_engine()
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 347, in init_cache_engine
[36m(main_task pid=77271)[0m     self.model_executor.init_cache_engine()
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 157, in init_cache_engine
[36m(main_task pid=77271)[0m     self.worker._init_cache_engine()
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 237, in _init_cache_engine
[36m(main_task pid=77271)[0m     super()._init_cache_engine()
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 275, in _init_cache_engine
[36m(main_task pid=77271)[0m     self.cache_engine = [
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 276, in <listcomp>
[36m(main_task pid=77271)[0m     CacheEngine(self.cache_config, self.model_config,
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 63, in __init__
[36m(main_task pid=77271)[0m     self.gpu_cache = self._allocate_kv_cache(
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 82, in _allocate_kv_cache
[36m(main_task pid=77271)[0m     torch.zeros(kv_cache_shape,
[36m(main_task pid=77271)[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 472.75 MiB is free. Process 188986 has 78.76 GiB memory in use. Of the allocated memory 74.40 GiB is allocated by PyTorch, and 2.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[36m(main_task pid=77271)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=79035, ip=192.168.102.77, actor_id=7bc518266c2faa5f8b26a9aa0c000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f7a73bf4880>)
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=77271)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=77271)[0m     return func(*args, **kwargs)
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 513, in generate_sequences
[36m(main_task pid=77271)[0m     output = self.rollout.generate_sequences(prompts=prompts)
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(main_task pid=77271)[0m     return func(*args, **kwargs)
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 161, in generate_sequences
[36m(main_task pid=77271)[0m     self.inference_engine.init_cache_engine()
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 146, in init_cache_engine
[36m(main_task pid=77271)[0m     self.llm_engine.init_cache_engine()
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 347, in init_cache_engine
[36m(main_task pid=77271)[0m     self.model_executor.init_cache_engine()
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 157, in init_cache_engine
[36m(main_task pid=77271)[0m     self.worker._init_cache_engine()
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 237, in _init_cache_engine
[36m(main_task pid=77271)[0m     super()._init_cache_engine()
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 275, in _init_cache_engine
[36m(main_task pid=77271)[0m     self.cache_engine = [
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 276, in <listcomp>
[36m(main_task pid=77271)[0m     CacheEngine(self.cache_config, self.model_config,
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 63, in __init__
[36m(main_task pid=77271)[0m     self.gpu_cache = self._allocate_kv_cache(
[36m(main_task pid=77271)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 82, in _allocate_kv_cache
[36m(main_task pid=77271)[0m     torch.zeros(kv_cache_shape,
[36m(main_task pid=77271)[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 346.75 MiB is free. Process 188751 has 78.88 GiB memory in use. Of the allocated memory 74.45 GiB is allocated by PyTorch, and 2.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 5e-7
Critic LR: 5e-6
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 512
PPO Mini Batch Size: 128
PPO Micro Batch Size: 1
Total Epochs: 10
Max Response Length: 2048
GPU Memory Utilization: 0.7
Test Frequency: 5
Number of GPUs: 4
Total Training Steps: 500
Compute Prompts Values: False
Experiment Name: ppo7B_dapo17k_tok8k
2025-04-20 23:27:30,021	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.102.77:6379...
2025-04-20 23:27:30,031	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=91495)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=91495)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=91495)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=91495)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=91495)[0m                                                  'param_offload': False,
[36m(main_task pid=91495)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=91495)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=91495)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=91495)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=91495)[0m                                  'optim': {'lr': 5e-07,
[36m(main_task pid=91495)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=91495)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=91495)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=91495)[0m                                            'total_training_steps': -1,
[36m(main_task pid=91495)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=91495)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=91495)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=91495)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=91495)[0m                                  'ppo_micro_batch_size_per_gpu': 1,
[36m(main_task pid=91495)[0m                                  'ppo_mini_batch_size': 128,
[36m(main_task pid=91495)[0m                                  'response_length': 2048,
[36m(main_task pid=91495)[0m                                  'shuffle': False,
[36m(main_task pid=91495)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=91495)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=91495)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=91495)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=91495)[0m                                  'use_kl_loss': False,
[36m(main_task pid=91495)[0m                                  'use_torch_compile': True},
[36m(main_task pid=91495)[0m                        'hybrid_engine': True,
[36m(main_task pid=91495)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=91495)[0m                                  'external_lib': None,
[36m(main_task pid=91495)[0m                                  'override_config': {},
[36m(main_task pid=91495)[0m                                  'path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=91495)[0m                                  'use_remove_padding': True},
[36m(main_task pid=91495)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=91495)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=91495)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=91495)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=91495)[0m                                'log_prob_micro_batch_size_per_gpu': 1,
[36m(main_task pid=91495)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=91495)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=91495)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=91495)[0m                                    'disable_log_stats': True,
[36m(main_task pid=91495)[0m                                    'do_sample': True,
[36m(main_task pid=91495)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=91495)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=91495)[0m                                    'enforce_eager': True,
[36m(main_task pid=91495)[0m                                    'free_cache_engine': True,
[36m(main_task pid=91495)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=91495)[0m                                    'ignore_eos': False,
[36m(main_task pid=91495)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=91495)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=91495)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=91495)[0m                                    'log_prob_micro_batch_size_per_gpu': 1,
[36m(main_task pid=91495)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=91495)[0m                                    'max_model_len': None,
[36m(main_task pid=91495)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=91495)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=91495)[0m                                    'n': 1,
[36m(main_task pid=91495)[0m                                    'name': 'vllm',
[36m(main_task pid=91495)[0m                                    'prompt_length': 512,
[36m(main_task pid=91495)[0m                                    'response_length': 2048,
[36m(main_task pid=91495)[0m                                    'temperature': 1.0,
[36m(main_task pid=91495)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=91495)[0m                                    'top_k': -1,
[36m(main_task pid=91495)[0m                                    'top_p': 1,
[36m(main_task pid=91495)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=91495)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=91495)[0m                                                   'n': 1,
[36m(main_task pid=91495)[0m                                                   'temperature': 0,
[36m(main_task pid=91495)[0m                                                   'top_k': -1,
[36m(main_task pid=91495)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=91495)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=91495)[0m                'gamma': 1.0,
[36m(main_task pid=91495)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=91495)[0m                'kl_penalty': 'kl',
[36m(main_task pid=91495)[0m                'lam': 1.0},
[36m(main_task pid=91495)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=91495)[0m             'estimate_prompts_value': False,
[36m(main_task pid=91495)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=91495)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=91495)[0m             'forward_micro_batch_size_per_gpu': 1,
[36m(main_task pid=91495)[0m             'grad_clip': 1.0,
[36m(main_task pid=91495)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=91495)[0m                       'external_lib': None,
[36m(main_task pid=91495)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=91495)[0m                                       'optimizer_offload': False,
[36m(main_task pid=91495)[0m                                       'param_offload': False,
[36m(main_task pid=91495)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=91495)[0m                       'override_config': {},
[36m(main_task pid=91495)[0m                       'path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=91495)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=91495)[0m                       'use_remove_padding': False},
[36m(main_task pid=91495)[0m             'optim': {'lr': 5e-06,
[36m(main_task pid=91495)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=91495)[0m                       'min_lr_ratio': None,
[36m(main_task pid=91495)[0m                       'total_training_steps': -1,
[36m(main_task pid=91495)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=91495)[0m             'ppo_epochs': 1,
[36m(main_task pid=91495)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=91495)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=91495)[0m             'ppo_micro_batch_size_per_gpu': 1,
[36m(main_task pid=91495)[0m             'ppo_mini_batch_size': 128,
[36m(main_task pid=91495)[0m             'shuffle': False,
[36m(main_task pid=91495)[0m             'strategy': 'fsdp',
[36m(main_task pid=91495)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=91495)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=91495)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=91495)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=91495)[0m                 'train_batch_size_pool': 2048,
[36m(main_task pid=91495)[0m                 'use_curriculum_learning': True,
[36m(main_task pid=91495)[0m                 'warmup_steps': 3},
[36m(main_task pid=91495)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=91495)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=91495)[0m           'image_key': 'images',
[36m(main_task pid=91495)[0m           'max_prompt_length': 512,
[36m(main_task pid=91495)[0m           'max_response_length': 2048,
[36m(main_task pid=91495)[0m           'prompt_key': 'prompt',
[36m(main_task pid=91495)[0m           'return_raw_chat': False,
[36m(main_task pid=91495)[0m           'return_raw_input_ids': False,
[36m(main_task pid=91495)[0m           'shuffle': True,
[36m(main_task pid=91495)[0m           'tokenizer': None,
[36m(main_task pid=91495)[0m           'train_batch_size': 512,
[36m(main_task pid=91495)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=91495)[0m           'truncation': 'error',
[36m(main_task pid=91495)[0m           'use_chat_template': False,
[36m(main_task pid=91495)[0m           'val_batch_size': None,
[36m(main_task pid=91495)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=91495)[0m  'reward_model': {'enable': False,
[36m(main_task pid=91495)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=91495)[0m                   'max_length': None,
[36m(main_task pid=91495)[0m                   'micro_batch_size': None,
[36m(main_task pid=91495)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=91495)[0m                   'model': {'external_lib': None,
[36m(main_task pid=91495)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=91495)[0m                                             'param_offload': False,
[36m(main_task pid=91495)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=91495)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=91495)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=91495)[0m                             'use_remove_padding': False},
[36m(main_task pid=91495)[0m                   'reward_manager': 'naive',
[36m(main_task pid=91495)[0m                   'strategy': 'fsdp',
[36m(main_task pid=91495)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=91495)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=91495)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=91495)[0m              'critic_warmup': 0,
[36m(main_task pid=91495)[0m              'default_hdfs_dir': None,
[36m(main_task pid=91495)[0m              'default_local_dir': 'checkpoints/grpo/ppo7B_dapo17k_tok8k',
[36m(main_task pid=91495)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=91495)[0m              'experiment_name': 'ppo7B_dapo17k_tok8k',
[36m(main_task pid=91495)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=91495)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=91495)[0m              'nnodes': 1,
[36m(main_task pid=91495)[0m              'project_name': 'grpo',
[36m(main_task pid=91495)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=91495)[0m              'resume_from_path': False,
[36m(main_task pid=91495)[0m              'resume_mode': 'auto',
[36m(main_task pid=91495)[0m              'save_freq': -1,
[36m(main_task pid=91495)[0m              'test_freq': 5,
[36m(main_task pid=91495)[0m              'total_epochs': 10,
[36m(main_task pid=91495)[0m              'total_training_steps': 500,
[36m(main_task pid=91495)[0m              'val_before_train': False,
[36m(main_task pid=91495)[0m              'val_generations_to_log_to_wandb': 0,
[36m(main_task pid=91495)[0m              'val_only': False}}
[36m(main_task pid=91495)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=91495)[0m No module named 'vllm._version'
[36m(main_task pid=91495)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=91495)[0m 'We use curriculum learning.'
[36m(main_task pid=91495)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=91495)[0m dataset len: 1791700
[36m(main_task pid=91495)[0m Example prompt before filtering: The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=91495)[0m 
[36m(main_task pid=91495)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$. Let's think step by step and output the final answer within \boxed{}.
*** SIGTERM received at time=1745217045 on cpu 120 ***
PC: @     0x7f4e8a8d4117  (unknown)  (unknown)
    @     0x7f4e8a885520  (unknown)  (unknown)
    @ ... and at least 1 more frames
[2025-04-20 23:30:45,274 E 91333 91333] logging.cc:484: *** SIGTERM received at time=1745217045 on cpu 120 ***
[2025-04-20 23:30:45,274 E 91333 91333] logging.cc:484: PC: @     0x7f4e8a8d4117  (unknown)  (unknown)
[2025-04-20 23:30:45,275 E 91333 91333] logging.cc:484:     @     0x7f4e8a885520  (unknown)  (unknown)
[2025-04-20 23:30:45,275 E 91333 91333] logging.cc:484:     @ ... and at least 1 more frames
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 5e-7
Critic LR: 5e-6
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 128
PPO Mini Batch Size: 32
PPO Micro Batch Size: 2
Total Epochs: 10
Max Response Length: 2048
GPU Memory Utilization: 0.7
Test Frequency: 5
Number of GPUs: 4
Total Training Steps: 500
Compute Prompts Values: False
Experiment Name: ppo7B_dapo17k_tok2k-test
2025-04-20 23:31:23,941	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.102.77:6379...
2025-04-20 23:31:23,952	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=92894)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=92894)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=92894)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=92894)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=92894)[0m                                                  'param_offload': False,
[36m(main_task pid=92894)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=92894)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=92894)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=92894)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=92894)[0m                                  'optim': {'lr': 5e-07,
[36m(main_task pid=92894)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=92894)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=92894)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=92894)[0m                                            'total_training_steps': -1,
[36m(main_task pid=92894)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=92894)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=92894)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=92894)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=92894)[0m                                  'ppo_micro_batch_size_per_gpu': 2,
[36m(main_task pid=92894)[0m                                  'ppo_mini_batch_size': 32,
[36m(main_task pid=92894)[0m                                  'response_length': 2048,
[36m(main_task pid=92894)[0m                                  'shuffle': False,
[36m(main_task pid=92894)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=92894)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=92894)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=92894)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=92894)[0m                                  'use_kl_loss': False,
[36m(main_task pid=92894)[0m                                  'use_torch_compile': True},
[36m(main_task pid=92894)[0m                        'hybrid_engine': True,
[36m(main_task pid=92894)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=92894)[0m                                  'external_lib': None,
[36m(main_task pid=92894)[0m                                  'override_config': {},
[36m(main_task pid=92894)[0m                                  'path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=92894)[0m                                  'use_remove_padding': True},
[36m(main_task pid=92894)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=92894)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=92894)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=92894)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=92894)[0m                                'log_prob_micro_batch_size_per_gpu': 2,
[36m(main_task pid=92894)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=92894)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=92894)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=92894)[0m                                    'disable_log_stats': True,
[36m(main_task pid=92894)[0m                                    'do_sample': True,
[36m(main_task pid=92894)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=92894)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=92894)[0m                                    'enforce_eager': True,
[36m(main_task pid=92894)[0m                                    'free_cache_engine': True,
[36m(main_task pid=92894)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=92894)[0m                                    'ignore_eos': False,
[36m(main_task pid=92894)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=92894)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=92894)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=92894)[0m                                    'log_prob_micro_batch_size_per_gpu': 2,
[36m(main_task pid=92894)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=92894)[0m                                    'max_model_len': None,
[36m(main_task pid=92894)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=92894)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=92894)[0m                                    'n': 1,
[36m(main_task pid=92894)[0m                                    'name': 'vllm',
[36m(main_task pid=92894)[0m                                    'prompt_length': 512,
[36m(main_task pid=92894)[0m                                    'response_length': 2048,
[36m(main_task pid=92894)[0m                                    'temperature': 1.0,
[36m(main_task pid=92894)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=92894)[0m                                    'top_k': -1,
[36m(main_task pid=92894)[0m                                    'top_p': 1,
[36m(main_task pid=92894)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=92894)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=92894)[0m                                                   'n': 1,
[36m(main_task pid=92894)[0m                                                   'temperature': 0,
[36m(main_task pid=92894)[0m                                                   'top_k': -1,
[36m(main_task pid=92894)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=92894)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=92894)[0m                'gamma': 1.0,
[36m(main_task pid=92894)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=92894)[0m                'kl_penalty': 'kl',
[36m(main_task pid=92894)[0m                'lam': 1.0},
[36m(main_task pid=92894)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=92894)[0m             'estimate_prompts_value': False,
[36m(main_task pid=92894)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=92894)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=92894)[0m             'forward_micro_batch_size_per_gpu': 2,
[36m(main_task pid=92894)[0m             'grad_clip': 1.0,
[36m(main_task pid=92894)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=92894)[0m                       'external_lib': None,
[36m(main_task pid=92894)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=92894)[0m                                       'optimizer_offload': False,
[36m(main_task pid=92894)[0m                                       'param_offload': False,
[36m(main_task pid=92894)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=92894)[0m                       'override_config': {},
[36m(main_task pid=92894)[0m                       'path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=92894)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=92894)[0m                       'use_remove_padding': False},
[36m(main_task pid=92894)[0m             'optim': {'lr': 5e-06,
[36m(main_task pid=92894)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=92894)[0m                       'min_lr_ratio': None,
[36m(main_task pid=92894)[0m                       'total_training_steps': -1,
[36m(main_task pid=92894)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=92894)[0m             'ppo_epochs': 1,
[36m(main_task pid=92894)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=92894)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=92894)[0m             'ppo_micro_batch_size_per_gpu': 2,
[36m(main_task pid=92894)[0m             'ppo_mini_batch_size': 32,
[36m(main_task pid=92894)[0m             'shuffle': False,
[36m(main_task pid=92894)[0m             'strategy': 'fsdp',
[36m(main_task pid=92894)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=92894)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=92894)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=92894)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=92894)[0m                 'train_batch_size_pool': 2048,
[36m(main_task pid=92894)[0m                 'use_curriculum_learning': True,
[36m(main_task pid=92894)[0m                 'warmup_steps': 3},
[36m(main_task pid=92894)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=92894)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=92894)[0m           'image_key': 'images',
[36m(main_task pid=92894)[0m           'max_prompt_length': 512,
[36m(main_task pid=92894)[0m           'max_response_length': 2048,
[36m(main_task pid=92894)[0m           'prompt_key': 'prompt',
[36m(main_task pid=92894)[0m           'return_raw_chat': False,
[36m(main_task pid=92894)[0m           'return_raw_input_ids': False,
[36m(main_task pid=92894)[0m           'shuffle': True,
[36m(main_task pid=92894)[0m           'tokenizer': None,
[36m(main_task pid=92894)[0m           'train_batch_size': 128,
[36m(main_task pid=92894)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=92894)[0m           'truncation': 'error',
[36m(main_task pid=92894)[0m           'use_chat_template': False,
[36m(main_task pid=92894)[0m           'val_batch_size': None,
[36m(main_task pid=92894)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=92894)[0m  'reward_model': {'enable': False,
[36m(main_task pid=92894)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=92894)[0m                   'max_length': None,
[36m(main_task pid=92894)[0m                   'micro_batch_size': None,
[36m(main_task pid=92894)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=92894)[0m                   'model': {'external_lib': None,
[36m(main_task pid=92894)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=92894)[0m                                             'param_offload': False,
[36m(main_task pid=92894)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=92894)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=92894)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=92894)[0m                             'use_remove_padding': False},
[36m(main_task pid=92894)[0m                   'reward_manager': 'naive',
[36m(main_task pid=92894)[0m                   'strategy': 'fsdp',
[36m(main_task pid=92894)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=92894)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=92894)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=92894)[0m              'critic_warmup': 0,
[36m(main_task pid=92894)[0m              'default_hdfs_dir': None,
[36m(main_task pid=92894)[0m              'default_local_dir': 'checkpoints/grpo/ppo7B_dapo17k_tok2k-test',
[36m(main_task pid=92894)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=92894)[0m              'experiment_name': 'ppo7B_dapo17k_tok2k-test',
[36m(main_task pid=92894)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=92894)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=92894)[0m              'nnodes': 1,
[36m(main_task pid=92894)[0m              'project_name': 'grpo',
[36m(main_task pid=92894)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=92894)[0m              'resume_from_path': False,
[36m(main_task pid=92894)[0m              'resume_mode': 'auto',
[36m(main_task pid=92894)[0m              'save_freq': -1,
[36m(main_task pid=92894)[0m              'test_freq': 5,
[36m(main_task pid=92894)[0m              'total_epochs': 10,
[36m(main_task pid=92894)[0m              'total_training_steps': 500,
[36m(main_task pid=92894)[0m              'val_before_train': False,
[36m(main_task pid=92894)[0m              'val_generations_to_log_to_wandb': 0,
[36m(main_task pid=92894)[0m              'val_only': False}}
[36m(main_task pid=92894)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=92894)[0m No module named 'vllm._version'
[36m(main_task pid=92894)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=92894)[0m 'We use curriculum learning.'
[36m(main_task pid=92894)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=92894)[0m dataset len: 1791700
[36m(main_task pid=92894)[0m Example prompt before filtering: The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=92894)[0m 
[36m(main_task pid=92894)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$. Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=92894)[0m filter dataset len: 1786200
[36m(main_task pid=92894)[0m dataset len: 500
[36m(main_task pid=92894)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=92894)[0m filter dataset len: 497
[36m(main_task pid=92894)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=92894)[0m Size of train dataloader: 13954
[36m(main_task pid=92894)[0m Size of val dataloader: 1
[36m(main_task pid=92894)[0m Total training steps: 500
[36m(main_task pid=92894)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=94658)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=94658)[0m No module named 'vllm._version'
[36m(pid=94658)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=94881)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=94881)[0m No module named 'vllm._version'
[36m(pid=94881)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=94880)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=94880)[0m No module named 'vllm._version'
[36m(pid=94880)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=94658)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=94658)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=94658)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=94658)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=94881)[0m Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.84it/s]
[36m(WorkerDict pid=94881)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.55it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.61it/s]
[36m(WorkerDict pid=94881)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-7B and are newly initialized: ['score.bias']
[36m(WorkerDict pid=94881)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(pid=94882)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=94882)[0m No module named 'vllm._version'
[36m(pid=94882)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=94658)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-7B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=94880)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=94880)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94880)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94658)[0m Qwen2ForTokenClassification contains 7.07B parameters
[36m(WorkerDict pid=94658)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=94658)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=94880)[0m Total steps: 500, num_warmup_steps: 0
[36m(WorkerDict pid=94880)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=94658)[0m After critic FSDP, memory allocated (GB): 6.585044860839844, memory reserved (GB): 14.33203125
[36m(WorkerDict pid=94658)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=94658)[0m   "_name_or_path": "Qwen/Qwen2.5-7B",
[36m(WorkerDict pid=94658)[0m   "architectures": [
[36m(WorkerDict pid=94658)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=94658)[0m   ],
[36m(WorkerDict pid=94658)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=94658)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=94658)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=94658)[0m   "hidden_size": 3584,
[36m(WorkerDict pid=94658)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=94658)[0m   "intermediate_size": 18944,
[36m(WorkerDict pid=94658)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=94658)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=94658)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=94658)[0m   "num_attention_heads": 28,
[36m(WorkerDict pid=94658)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=94658)[0m   "num_key_value_heads": 4,
[36m(WorkerDict pid=94658)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=94658)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=94658)[0m   "rope_scaling": null,
[36m(WorkerDict pid=94658)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=94658)[0m   "sliding_window": null,
[36m(WorkerDict pid=94658)[0m   "tie_word_embeddings": false,
[36m(WorkerDict pid=94658)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=94658)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=94658)[0m   "use_cache": true,
[36m(WorkerDict pid=94658)[0m   "use_mrope": false,
[36m(WorkerDict pid=94658)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=94658)[0m   "vocab_size": 152064
[36m(WorkerDict pid=94658)[0m }
[36m(WorkerDict pid=94658)[0m 
[36m(WorkerDict pid=94658)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.37s/it][32m [repeated 11x across cluster][0m
[36m(WorkerDict pid=94658)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.26s/it][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94880)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-7B and are newly initialized: ['score.bias'][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=94658)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94658)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=94880)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=94658)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(WorkerDict pid=94658)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f0f413a80d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f0f4136ff40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=94658)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=94882)[0m Total steps: 500, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94882)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94882)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=94882)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  6.25it/s][32m [repeated 12x across cluster][0m
[36m(WorkerDict pid=94882)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.92it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.18it/s][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=94882)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=94658)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=94658)[0m   "_name_or_path": "Qwen/Qwen2.5-7B",
[36m(WorkerDict pid=94658)[0m   "architectures": [
[36m(WorkerDict pid=94658)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=94658)[0m   ],
[36m(WorkerDict pid=94658)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=94658)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=94658)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=94658)[0m   "hidden_size": 3584,
[36m(WorkerDict pid=94658)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=94658)[0m   "intermediate_size": 18944,
[36m(WorkerDict pid=94658)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=94658)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=94658)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=94658)[0m   "num_attention_heads": 28,
[36m(WorkerDict pid=94658)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=94658)[0m   "num_key_value_heads": 4,
[36m(WorkerDict pid=94658)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=94658)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=94658)[0m   "rope_scaling": null,
[36m(WorkerDict pid=94658)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=94658)[0m   "sliding_window": null,
[36m(WorkerDict pid=94658)[0m   "tie_word_embeddings": false,
[36m(WorkerDict pid=94658)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=94658)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=94658)[0m   "use_cache": true,
[36m(WorkerDict pid=94658)[0m   "use_mrope": false,
[36m(WorkerDict pid=94658)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=94658)[0m   "vocab_size": 152064
[36m(WorkerDict pid=94658)[0m }
[36m(WorkerDict pid=94658)[0m 
[36m(WorkerDict pid=94882)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f58810040d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f5880fcbf40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94658)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(WorkerDict pid=94882)[0m Actor use_remove_padding=True[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94658)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f0f413a80d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f0f4136ff40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=94880)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94658)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.40s/it][32m [repeated 12x across cluster][0m
[36m(WorkerDict pid=94658)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.38s/it][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=94880)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=94880)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fb4cd8fc0d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fb4cd8c3f40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=94880)[0m Total steps: 500, num_warmup_steps: 0
[36m(WorkerDict pid=94658)[0m Before building vllm rollout, memory allocated (GB): 13.678153038024902, memory reserved (GB): 28.48046875
[36m(WorkerDict pid=94658)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=94658)[0m WARNING 04-20 23:39:48 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=94658)[0m Actor use_remove_padding=True[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=94882)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f58810040d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f5880fcbf40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=94882)[0m local rank 0
[36m(WorkerDict pid=94658)[0m Total steps: 500, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94880)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=94882)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94658)[0m before init cache memory allocated: 30.013116416GB, reserved: 30.203183104GB
[36m(WorkerDict pid=94658)[0m after init cache memory allocated: 66.008633344GB, reserved: 66.198700032GB
[36m(WorkerDict pid=94881)[0m WARNING 04-20 23:39:49 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94658)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94882)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=94882)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 2048, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=94882)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=94882)[0m   warnings.warn(
[36m(WorkerDict pid=94658)[0m After building vllm rollout, memory allocated (GB): 47.24077892303467, memory reserved (GB): 61.65234375
[36m(WorkerDict pid=94658)[0m After building sharding manager, memory allocated (GB): 47.24077892303467, memory reserved (GB): 61.65234375
[36m(main_task pid=92894)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=92894)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=92894)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=92894)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250420_233956-xurbgu30
[36m(main_task pid=92894)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=92894)[0m wandb: Syncing run ppo7B_dapo17k_tok2k-test
[36m(main_task pid=92894)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=92894)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/xurbgu30
[36m(main_task pid=92894)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=92894)[0m '######################## Total training steps: 500 ########################'
[36m(main_task pid=92894)[0m 'Total training steps: 500'
[36m(main_task pid=92894)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo7B_dapo17k_tok2k-test/latest_checkpointed_iteration.txt
[36m(main_task pid=92894)[0m Training from scratch
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,570:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{34}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=94881)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94881)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,595:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,716:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{38}'], Pred: [' Absolutely!<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,731:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,750:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{118}'], Pred: ['<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,751:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2024}'], Pred: [' The answer to this problem is {5546} inches.<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,771:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2504}'], Pred: ['<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,778:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{875}'], Pred: ['<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,828:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,906:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{192}'], Pred: ['<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,921:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [' Reference material found at https://en.wikipedia.org/wiki/Cubic_function<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,933:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,940:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,991:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1537}'], Pred: ['<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,996:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{80}'], Pred: ['<|endoftext|>']
[36m(main_task pid=92894)[0m WARNING:2025-04-20 23:41:07,999:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-1}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=94658)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=94658)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
[36m(WorkerDict pid=94658)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=94658)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 4x across cluster][0m
[36m(main_task pid=92894)[0m step:1 - global_seqlen/min:20274.000 - global_seqlen/max:23672.000 - global_seqlen/minmax_diff:3398.000 - global_seqlen/balanced_min:22483.000 - global_seqlen/balanced_max:22493.000 - global_seqlen/mean:22489.750 - critic/kl:0.000 - critic/kl_coeff:0.001 - critic/vf_loss:9.801 - critic/vf_clipfrac:0.000 - critic/vpred_mean:-2.531 - critic/grad_norm:710.586 - perf/mfu/critic:0.131 - critic/lr:0.000 - actor/entropy_loss:0.551 - actor/pg_loss:0.011 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.761 - perf/mfu/actor:0.210 - perf/max_memory_allocated_gb:68.558 - perf/max_memory_reserved_gb:76.842 - perf/cpu_memory_used_gb:109.813 - actor/lr:0.000 - critic/score/mean:0.148 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.149 - critic/rewards/max:1.001 - critic/rewards/min:-0.002 - critic/advantages/mean:-0.000 - critic/advantages/max:3.632 - critic/advantages/min:-5.418 - critic/returns/mean:0.185 - critic/returns/max:1.001 - critic/returns/min:-0.003 - critic/values/mean:-2.578 - critic/values/max:16.500 - critic/values/min:-15.562 - critic/vf_explained_var:-82.826 - response_length/mean:571.336 - response_length/max:2048.000 - response_length/min:1.000 - response_length/clip_ratio:0.031 - prompt_length/mean:131.469 - prompt_length/max:476.000 - prompt_length/min:56.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:46.341 - timing_s/old_log_prob:4.465 - timing_s/ref:12.452 - timing_s/values:6.153 - timing_s/adv:0.989 - timing_s/update_critic:25.846 - timing_s/update_actor:16.106 - timing_s/step:112.360 - timing_per_token_ms/update_actor:0.179 - timing_per_token_ms/values:0.068 - timing_per_token_ms/adv:0.011 - timing_per_token_ms/gen:0.634 - timing_per_token_ms/update_critic:0.287 - timing_per_token_ms/ref:0.138 - perf/total_num_tokens:89959.000 - perf/time_per_step:112.360 - perf/throughput:200.159
[36m(WorkerDict pid=94881)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 2048, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=92894)[0m wandb:                                                                                
[36m(main_task pid=92894)[0m wandb: 
[36m(main_task pid=92894)[0m wandb: Run history:
[36m(main_task pid=92894)[0m wandb:                actor/entropy_loss ▁
[36m(main_task pid=92894)[0m wandb:                   actor/grad_norm ▁
[36m(main_task pid=92894)[0m wandb:                          actor/lr ▁
[36m(main_task pid=92894)[0m wandb:                 actor/pg_clipfrac ▁
[36m(main_task pid=92894)[0m wandb:                     actor/pg_loss ▁
[36m(main_task pid=92894)[0m wandb:                      actor/ppo_kl ▁
[36m(main_task pid=92894)[0m wandb:             critic/advantages/max ▁
[36m(main_task pid=92894)[0m wandb:            critic/advantages/mean ▁
[36m(main_task pid=92894)[0m wandb:             critic/advantages/min ▁
[36m(main_task pid=92894)[0m wandb:                  critic/grad_norm ▁
[36m(main_task pid=92894)[0m wandb:                         critic/kl ▁
[36m(main_task pid=92894)[0m wandb:                   critic/kl_coeff ▁
[36m(main_task pid=92894)[0m wandb:                         critic/lr ▁
[36m(main_task pid=92894)[0m wandb:                critic/returns/max ▁
[36m(main_task pid=92894)[0m wandb:               critic/returns/mean ▁
[36m(main_task pid=92894)[0m wandb:                critic/returns/min ▁
[36m(main_task pid=92894)[0m wandb:                critic/rewards/max ▁
[36m(main_task pid=92894)[0m wandb:               critic/rewards/mean ▁
[36m(main_task pid=92894)[0m wandb:                critic/rewards/min ▁
[36m(main_task pid=92894)[0m wandb:                  critic/score/max ▁
[36m(main_task pid=92894)[0m wandb:                 critic/score/mean ▁
[36m(main_task pid=92894)[0m wandb:                  critic/score/min ▁
[36m(main_task pid=92894)[0m wandb:                 critic/values/max ▁
[36m(main_task pid=92894)[0m wandb:                critic/values/mean ▁
[36m(main_task pid=92894)[0m wandb:                 critic/values/min ▁
[36m(main_task pid=92894)[0m wandb:                critic/vf_clipfrac ▁
[36m(main_task pid=92894)[0m wandb:           critic/vf_explained_var ▁
[36m(main_task pid=92894)[0m wandb:                    critic/vf_loss ▁
[36m(main_task pid=92894)[0m wandb:                 critic/vpred_mean ▁
[36m(main_task pid=92894)[0m wandb:        global_seqlen/balanced_max ▁
[36m(main_task pid=92894)[0m wandb:        global_seqlen/balanced_min ▁
[36m(main_task pid=92894)[0m wandb:                 global_seqlen/max ▁
[36m(main_task pid=92894)[0m wandb:                global_seqlen/mean ▁
[36m(main_task pid=92894)[0m wandb:                 global_seqlen/min ▁
[36m(main_task pid=92894)[0m wandb:         global_seqlen/minmax_diff ▁
[36m(main_task pid=92894)[0m wandb:           perf/cpu_memory_used_gb ▁
[36m(main_task pid=92894)[0m wandb:      perf/max_memory_allocated_gb ▁
[36m(main_task pid=92894)[0m wandb:       perf/max_memory_reserved_gb ▁
[36m(main_task pid=92894)[0m wandb:                    perf/mfu/actor ▁
[36m(main_task pid=92894)[0m wandb:                   perf/mfu/critic ▁
[36m(main_task pid=92894)[0m wandb:                   perf/throughput ▁
[36m(main_task pid=92894)[0m wandb:                perf/time_per_step ▁
[36m(main_task pid=92894)[0m wandb:             perf/total_num_tokens ▁
[36m(main_task pid=92894)[0m wandb:          prompt_length/clip_ratio ▁
[36m(main_task pid=92894)[0m wandb:                 prompt_length/max ▁
[36m(main_task pid=92894)[0m wandb:                prompt_length/mean ▁
[36m(main_task pid=92894)[0m wandb:                 prompt_length/min ▁
[36m(main_task pid=92894)[0m wandb:        response_length/clip_ratio ▁
[36m(main_task pid=92894)[0m wandb:               response_length/max ▁
[36m(main_task pid=92894)[0m wandb:              response_length/mean ▁
[36m(main_task pid=92894)[0m wandb:               response_length/min ▁
[36m(main_task pid=92894)[0m wandb:           timing_per_token_ms/adv ▁
[36m(main_task pid=92894)[0m wandb:           timing_per_token_ms/gen ▁
[36m(main_task pid=92894)[0m wandb:           timing_per_token_ms/ref ▁
[36m(main_task pid=92894)[0m wandb:  timing_per_token_ms/update_actor ▁
[36m(main_task pid=92894)[0m wandb: timing_per_token_ms/update_critic ▁
[36m(main_task pid=92894)[0m wandb:        timing_per_token_ms/values ▁
[36m(main_task pid=92894)[0m wandb:                      timing_s/adv ▁
[36m(main_task pid=92894)[0m wandb:                      timing_s/gen ▁
[36m(main_task pid=92894)[0m wandb:             timing_s/old_log_prob ▁
[36m(main_task pid=92894)[0m wandb:                      timing_s/ref ▁
[36m(main_task pid=92894)[0m wandb:                     timing_s/step ▁
[36m(main_task pid=92894)[0m wandb:             timing_s/update_actor ▁
[36m(main_task pid=92894)[0m wandb:            timing_s/update_critic ▁
[36m(main_task pid=92894)[0m wandb:                   timing_s/values ▁
[36m(main_task pid=92894)[0m wandb: 
[36m(main_task pid=92894)[0m wandb: Run summary:
[36m(main_task pid=92894)[0m wandb:                actor/entropy_loss 0.55094
[36m(main_task pid=92894)[0m wandb:                   actor/grad_norm 0.76105
[36m(main_task pid=92894)[0m wandb:                          actor/lr 0.0
[36m(main_task pid=92894)[0m wandb:                 actor/pg_clipfrac 0
[36m(main_task pid=92894)[0m wandb:                     actor/pg_loss 0.01131
[36m(main_task pid=92894)[0m wandb:                      actor/ppo_kl 0
[36m(main_task pid=92894)[0m wandb:             critic/advantages/max 3.63248
[36m(main_task pid=92894)[0m wandb:            critic/advantages/mean -0.0
[36m(main_task pid=92894)[0m wandb:             critic/advantages/min -5.41788
[36m(main_task pid=92894)[0m wandb:                  critic/grad_norm 710.58568
[36m(main_task pid=92894)[0m wandb:                         critic/kl 0.00048
[36m(main_task pid=92894)[0m wandb:                   critic/kl_coeff 0.001
[36m(main_task pid=92894)[0m wandb:                         critic/lr 1e-05
[36m(main_task pid=92894)[0m wandb:                critic/returns/max 1.00149
[36m(main_task pid=92894)[0m wandb:               critic/returns/mean 0.18512
[36m(main_task pid=92894)[0m wandb:                critic/returns/min -0.00347
[36m(main_task pid=92894)[0m wandb:                critic/rewards/max 1.00149
[36m(main_task pid=92894)[0m wandb:               critic/rewards/mean 0.14851
[36m(main_task pid=92894)[0m wandb:                critic/rewards/min -0.00249
[36m(main_task pid=92894)[0m wandb:                  critic/score/max 1
[36m(main_task pid=92894)[0m wandb:                 critic/score/mean 0.14844
[36m(main_task pid=92894)[0m wandb:                  critic/score/min 0
[36m(main_task pid=92894)[0m wandb:                 critic/values/max 16.5
[36m(main_task pid=92894)[0m wandb:                critic/values/mean -2.57812
[36m(main_task pid=92894)[0m wandb:                 critic/values/min -15.5625
[36m(main_task pid=92894)[0m wandb:                critic/vf_clipfrac 0
[36m(main_task pid=92894)[0m wandb:           critic/vf_explained_var -82.82558
[36m(main_task pid=92894)[0m wandb:                    critic/vf_loss 9.80056
[36m(main_task pid=92894)[0m wandb:                 critic/vpred_mean -2.53125
[36m(main_task pid=92894)[0m wandb:        global_seqlen/balanced_max 22493
[36m(main_task pid=92894)[0m wandb:        global_seqlen/balanced_min 22483
[36m(main_task pid=92894)[0m wandb:                 global_seqlen/max 23672
[36m(main_task pid=92894)[0m wandb:                global_seqlen/mean 22489.75
[36m(main_task pid=92894)[0m wandb:                 global_seqlen/min 20274
[36m(main_task pid=92894)[0m wandb:         global_seqlen/minmax_diff 3398
[36m(main_task pid=92894)[0m wandb:           perf/cpu_memory_used_gb 109.81264
[36m(main_task pid=92894)[0m wandb:      perf/max_memory_allocated_gb 68.55848
[36m(main_task pid=92894)[0m wandb:       perf/max_memory_reserved_gb 76.8418
[36m(main_task pid=92894)[0m wandb:                    perf/mfu/actor 0.21012
[36m(main_task pid=92894)[0m wandb:                   perf/mfu/critic 0.13087
[36m(main_task pid=92894)[0m wandb:                   perf/throughput 200.1586
[36m(main_task pid=92894)[0m wandb:                perf/time_per_step 112.35965
[36m(main_task pid=92894)[0m wandb:             perf/total_num_tokens 89959
[36m(main_task pid=92894)[0m wandb:          prompt_length/clip_ratio 0
[36m(main_task pid=92894)[0m wandb:                 prompt_length/max 476
[36m(main_task pid=92894)[0m wandb:                prompt_length/mean 131.46875
[36m(main_task pid=92894)[0m wandb:                 prompt_length/min 56
[36m(main_task pid=92894)[0m wandb:        response_length/clip_ratio 0.03125
[36m(main_task pid=92894)[0m wandb:               response_length/max 2048
[36m(main_task pid=92894)[0m wandb:              response_length/mean 571.33594
[36m(main_task pid=92894)[0m wandb:               response_length/min 1
[36m(main_task pid=92894)[0m wandb:           timing_per_token_ms/adv 0.01099
[36m(main_task pid=92894)[0m wandb:           timing_per_token_ms/gen 0.63367
[36m(main_task pid=92894)[0m wandb:           timing_per_token_ms/ref 0.13842
[36m(main_task pid=92894)[0m wandb:  timing_per_token_ms/update_actor 0.17903
[36m(main_task pid=92894)[0m wandb: timing_per_token_ms/update_critic 0.28731
[36m(main_task pid=92894)[0m wandb:        timing_per_token_ms/values 0.0684
[36m(main_task pid=92894)[0m wandb:                      timing_s/adv 0.98902
[36m(main_task pid=92894)[0m wandb:                      timing_s/gen 46.34065
[36m(main_task pid=92894)[0m wandb:             timing_s/old_log_prob 4.46532
[36m(main_task pid=92894)[0m wandb:                      timing_s/ref 12.45212
[36m(main_task pid=92894)[0m wandb:                     timing_s/step 112.35965
[36m(main_task pid=92894)[0m wandb:             timing_s/update_actor 16.10578
[36m(main_task pid=92894)[0m wandb:            timing_s/update_critic 25.84577
[36m(main_task pid=92894)[0m wandb:                   timing_s/values 6.15329
[36m(main_task pid=92894)[0m wandb: 
[36m(main_task pid=92894)[0m wandb: 🚀 View run ppo7B_dapo17k_tok2k-test at: https://wandb.ai/sample-efficient-RL/grpo/runs/xurbgu30
[36m(main_task pid=92894)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=92894)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=92894)[0m wandb: Find logs at: ./wandb/run-20250420_233956-xurbgu30/logs
[36m(WorkerDict pid=94882)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=94882)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 3x across cluster][0m
[36m(main_task pid=92894)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=94882, ip=192.168.102.77, actor_id=fb97e97549e622d5931bb2680e000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f58623857b0>)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=92894)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=92894)[0m     return func(*args, **kwargs)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 513, in generate_sequences
[36m(main_task pid=92894)[0m     output = self.rollout.generate_sequences(prompts=prompts)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(main_task pid=92894)[0m     return func(*args, **kwargs)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 161, in generate_sequences
[36m(main_task pid=92894)[0m     self.inference_engine.init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 146, in init_cache_engine
[36m(main_task pid=92894)[0m     self.llm_engine.init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 347, in init_cache_engine
[36m(main_task pid=92894)[0m     self.model_executor.init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 157, in init_cache_engine
[36m(main_task pid=92894)[0m     self.worker._init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 237, in _init_cache_engine
[36m(main_task pid=92894)[0m     super()._init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 275, in _init_cache_engine
[36m(main_task pid=92894)[0m     self.cache_engine = [
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 276, in <listcomp>
[36m(main_task pid=92894)[0m     CacheEngine(self.cache_config, self.model_config,
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 63, in __init__
[36m(main_task pid=92894)[0m     self.gpu_cache = self._allocate_kv_cache(
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 82, in _allocate_kv_cache
[36m(main_task pid=92894)[0m     torch.zeros(kv_cache_shape,
[36m(main_task pid=92894)[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 304.75 MiB is free. Process 253744 has 78.92 GiB memory in use. Of the allocated memory 75.66 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[36m(main_task pid=92894)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=94658, ip=192.168.102.77, actor_id=cb89dda06fae1aa479cf17f30e000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f0f22510ac0>)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=92894)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=92894)[0m     return func(*args, **kwargs)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 513, in generate_sequences
[36m(main_task pid=92894)[0m     output = self.rollout.generate_sequences(prompts=prompts)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(main_task pid=92894)[0m     return func(*args, **kwargs)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 161, in generate_sequences
[36m(main_task pid=92894)[0m     self.inference_engine.init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 146, in init_cache_engine
[36m(main_task pid=92894)[0m     self.llm_engine.init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 347, in init_cache_engine
[36m(main_task pid=92894)[0m     self.model_executor.init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 157, in init_cache_engine
[36m(main_task pid=92894)[0m     self.worker._init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 237, in _init_cache_engine
[36m(main_task pid=92894)[0m     super()._init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 275, in _init_cache_engine
[36m(main_task pid=92894)[0m     self.cache_engine = [
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 276, in <listcomp>
[36m(main_task pid=92894)[0m     CacheEngine(self.cache_config, self.model_config,
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 63, in __init__
[36m(main_task pid=92894)[0m     self.gpu_cache = self._allocate_kv_cache(
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 82, in _allocate_kv_cache
[36m(main_task pid=92894)[0m     torch.zeros(kv_cache_shape,
[36m(main_task pid=92894)[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 812.75 MiB is free. Process 253426 has 78.43 GiB memory in use. Of the allocated memory 74.45 GiB is allocated by PyTorch, and 2.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[36m(main_task pid=92894)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=94880, ip=192.168.102.77, actor_id=1473ad1e90eddb0566f998040e000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7fb4aebd6a40>)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=92894)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=92894)[0m     return func(*args, **kwargs)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 513, in generate_sequences
[36m(main_task pid=92894)[0m     output = self.rollout.generate_sequences(prompts=prompts)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(main_task pid=92894)[0m     return func(*args, **kwargs)
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 161, in generate_sequences
[36m(main_task pid=92894)[0m     self.inference_engine.init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 146, in init_cache_engine
[36m(main_task pid=92894)[0m     self.llm_engine.init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 347, in init_cache_engine
[36m(main_task pid=92894)[0m     self.model_executor.init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 157, in init_cache_engine
[36m(main_task pid=92894)[0m     self.worker._init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 237, in _init_cache_engine
[36m(main_task pid=92894)[0m     super()._init_cache_engine()
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 275, in _init_cache_engine
[36m(main_task pid=92894)[0m     self.cache_engine = [
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 276, in <listcomp>
[36m(main_task pid=92894)[0m     CacheEngine(self.cache_config, self.model_config,
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 63, in __init__
[36m(main_task pid=92894)[0m     self.gpu_cache = self._allocate_kv_cache(
[36m(main_task pid=92894)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 82, in _allocate_kv_cache
[36m(main_task pid=92894)[0m     torch.zeros(kv_cache_shape,
[36m(main_task pid=92894)[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 18.75 MiB is free. Process 253742 has 79.20 GiB memory in use. Of the allocated memory 75.60 GiB is allocated by PyTorch, and 1.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: ['data.train_files=./data/DAPO-17k-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=128', 'data.max_prompt_length=512', 'data.max_response_length=2048', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-7B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=5e-7', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=32', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=2', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=2', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=2', 'critic.optim.lr=5e-6', 'critic.model.path=Qwen/Qwen2.5-7B', 'critic.ppo_micro_batch_size_per_gpu=2', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=False', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.total_training_steps=500', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=5', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo7B_dapo17k_tok2k-test', 'trainer.total_epochs=10', 'curriculum.use_curriculum_learning=True', 'curriculum.train_batch_size_pool=2048', 'curriculum.warmup_steps=3']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::main_task()[39m (pid=92894, ip=192.168.102.77)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 1064, in fit
    gen_batch_output = self.actor_rollout_wg.generate_sequences(gen_batch)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=94881, ip=192.168.102.77, actor_id=46cc47354f200919e307c8dd0e000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f16f54f5870>)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 513, in generate_sequences
    output = self.rollout.generate_sequences(prompts=prompts)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 161, in generate_sequences
    self.inference_engine.init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 146, in init_cache_engine
    self.llm_engine.init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 347, in init_cache_engine
    self.model_executor.init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 157, in init_cache_engine
    self.worker._init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 237, in _init_cache_engine
    super()._init_cache_engine()
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 275, in _init_cache_engine
    self.cache_engine = [
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 276, in <listcomp>
    CacheEngine(self.cache_config, self.model_config,
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 63, in __init__
    self.gpu_cache = self._allocate_kv_cache(
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 82, in _allocate_kv_cache
    torch.zeros(kv_cache_shape,
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 292.75 MiB is free. Process 253743 has 78.93 GiB memory in use. Of the allocated memory 75.59 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Running with hyperparameters:
Actor LR: 5e-7
Critic LR: 5e-6
KL Coefficient: 0.001
Number of Generations Validation: 1
Train Batch Size: 128
PPO Mini Batch Size: 32
PPO Micro Batch Size: 1
Total Epochs: 10
Max Response Length: 2048
GPU Memory Utilization: 0.7
Test Frequency: 5
Number of GPUs: 4
Total Training Steps: 500
Compute Prompts Values: False
Experiment Name: ppo7B_dapo17k_tok2k-test
2025-04-20 23:59:10,773	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.102.77:6379...
2025-04-20 23:59:10,784	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=100416)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=100416)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=100416)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=100416)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=100416)[0m                                                  'param_offload': False,
[36m(main_task pid=100416)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=100416)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=100416)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=100416)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=100416)[0m                                  'optim': {'lr': 5e-07,
[36m(main_task pid=100416)[0m                                            'lr_warmup_steps': -1,
[36m(main_task pid=100416)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=100416)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=100416)[0m                                            'total_training_steps': -1,
[36m(main_task pid=100416)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=100416)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=100416)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=100416)[0m                                  'ppo_micro_batch_size': None,
[36m(main_task pid=100416)[0m                                  'ppo_micro_batch_size_per_gpu': 1,
[36m(main_task pid=100416)[0m                                  'ppo_mini_batch_size': 32,
[36m(main_task pid=100416)[0m                                  'response_length': 2048,
[36m(main_task pid=100416)[0m                                  'shuffle': False,
[36m(main_task pid=100416)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=100416)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=100416)[0m                                  'use_doctor_grpo': True,
[36m(main_task pid=100416)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=100416)[0m                                  'use_kl_loss': False,
[36m(main_task pid=100416)[0m                                  'use_torch_compile': True},
[36m(main_task pid=100416)[0m                        'hybrid_engine': True,
[36m(main_task pid=100416)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=100416)[0m                                  'external_lib': None,
[36m(main_task pid=100416)[0m                                  'override_config': {},
[36m(main_task pid=100416)[0m                                  'path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=100416)[0m                                  'use_remove_padding': True},
[36m(main_task pid=100416)[0m                        'ref': {'fsdp_config': {'param_offload': False,
[36m(main_task pid=100416)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=100416)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=100416)[0m                                'log_prob_micro_batch_size': None,
[36m(main_task pid=100416)[0m                                'log_prob_micro_batch_size_per_gpu': 1,
[36m(main_task pid=100416)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=100416)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=100416)[0m                        'rollout': {'compute_prompts_values': False,
[36m(main_task pid=100416)[0m                                    'disable_log_stats': True,
[36m(main_task pid=100416)[0m                                    'do_sample': True,
[36m(main_task pid=100416)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=100416)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=100416)[0m                                    'enforce_eager': True,
[36m(main_task pid=100416)[0m                                    'free_cache_engine': True,
[36m(main_task pid=100416)[0m                                    'gpu_memory_utilization': 0.7,
[36m(main_task pid=100416)[0m                                    'ignore_eos': False,
[36m(main_task pid=100416)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=100416)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=100416)[0m                                    'log_prob_micro_batch_size': None,
[36m(main_task pid=100416)[0m                                    'log_prob_micro_batch_size_per_gpu': 1,
[36m(main_task pid=100416)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=100416)[0m                                    'max_model_len': None,
[36m(main_task pid=100416)[0m                                    'max_num_batched_tokens': 9216,
[36m(main_task pid=100416)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=100416)[0m                                    'n': 1,
[36m(main_task pid=100416)[0m                                    'name': 'vllm',
[36m(main_task pid=100416)[0m                                    'prompt_length': 512,
[36m(main_task pid=100416)[0m                                    'response_length': 2048,
[36m(main_task pid=100416)[0m                                    'temperature': 1.0,
[36m(main_task pid=100416)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=100416)[0m                                    'top_k': -1,
[36m(main_task pid=100416)[0m                                    'top_p': 1,
[36m(main_task pid=100416)[0m                                    'use_fire_sampling': False,
[36m(main_task pid=100416)[0m                                    'val_kwargs': {'do_sample': False,
[36m(main_task pid=100416)[0m                                                   'n': 1,
[36m(main_task pid=100416)[0m                                                   'temperature': 0,
[36m(main_task pid=100416)[0m                                                   'top_k': -1,
[36m(main_task pid=100416)[0m                                                   'top_p': 1.0}}},
[36m(main_task pid=100416)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=100416)[0m                'gamma': 1.0,
[36m(main_task pid=100416)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=100416)[0m                'kl_penalty': 'kl',
[36m(main_task pid=100416)[0m                'lam': 1.0},
[36m(main_task pid=100416)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=100416)[0m             'estimate_prompts_value': False,
[36m(main_task pid=100416)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=100416)[0m             'forward_micro_batch_size': None,
[36m(main_task pid=100416)[0m             'forward_micro_batch_size_per_gpu': 1,
[36m(main_task pid=100416)[0m             'grad_clip': 1.0,
[36m(main_task pid=100416)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=100416)[0m                       'external_lib': None,
[36m(main_task pid=100416)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=100416)[0m                                       'optimizer_offload': False,
[36m(main_task pid=100416)[0m                                       'param_offload': False,
[36m(main_task pid=100416)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=100416)[0m                       'override_config': {},
[36m(main_task pid=100416)[0m                       'path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=100416)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=100416)[0m                       'use_remove_padding': False},
[36m(main_task pid=100416)[0m             'optim': {'lr': 5e-06,
[36m(main_task pid=100416)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=100416)[0m                       'min_lr_ratio': None,
[36m(main_task pid=100416)[0m                       'total_training_steps': -1,
[36m(main_task pid=100416)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=100416)[0m             'ppo_epochs': 1,
[36m(main_task pid=100416)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=100416)[0m             'ppo_micro_batch_size': None,
[36m(main_task pid=100416)[0m             'ppo_micro_batch_size_per_gpu': 1,
[36m(main_task pid=100416)[0m             'ppo_mini_batch_size': 32,
[36m(main_task pid=100416)[0m             'shuffle': False,
[36m(main_task pid=100416)[0m             'strategy': 'fsdp',
[36m(main_task pid=100416)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=100416)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=100416)[0m  'curriculum': {'p_thres': 0.5,
[36m(main_task pid=100416)[0m                 'subsample_criterion': 'square-inverse',
[36m(main_task pid=100416)[0m                 'train_batch_size_pool': 2048,
[36m(main_task pid=100416)[0m                 'use_curriculum_learning': True,
[36m(main_task pid=100416)[0m                 'warmup_steps': 3},
[36m(main_task pid=100416)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(main_task pid=100416)[0m  'data': {'filter_overlong_prompts': True,
[36m(main_task pid=100416)[0m           'image_key': 'images',
[36m(main_task pid=100416)[0m           'max_prompt_length': 512,
[36m(main_task pid=100416)[0m           'max_response_length': 2048,
[36m(main_task pid=100416)[0m           'prompt_key': 'prompt',
[36m(main_task pid=100416)[0m           'return_raw_chat': False,
[36m(main_task pid=100416)[0m           'return_raw_input_ids': False,
[36m(main_task pid=100416)[0m           'shuffle': True,
[36m(main_task pid=100416)[0m           'tokenizer': None,
[36m(main_task pid=100416)[0m           'train_batch_size': 128,
[36m(main_task pid=100416)[0m           'train_files': './data/DAPO-17k-base/train.parquet',
[36m(main_task pid=100416)[0m           'truncation': 'error',
[36m(main_task pid=100416)[0m           'use_chat_template': False,
[36m(main_task pid=100416)[0m           'val_batch_size': None,
[36m(main_task pid=100416)[0m           'val_files': './data/math500-base/test.parquet'},
[36m(main_task pid=100416)[0m  'reward_model': {'enable': False,
[36m(main_task pid=100416)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=100416)[0m                   'max_length': None,
[36m(main_task pid=100416)[0m                   'micro_batch_size': None,
[36m(main_task pid=100416)[0m                   'micro_batch_size_per_gpu': None,
[36m(main_task pid=100416)[0m                   'model': {'external_lib': None,
[36m(main_task pid=100416)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=100416)[0m                                             'param_offload': False,
[36m(main_task pid=100416)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=100416)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-7B',
[36m(main_task pid=100416)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=100416)[0m                             'use_remove_padding': False},
[36m(main_task pid=100416)[0m                   'reward_manager': 'naive',
[36m(main_task pid=100416)[0m                   'strategy': 'fsdp',
[36m(main_task pid=100416)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=100416)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=100416)[0m  'trainer': {'balance_batch': True,
[36m(main_task pid=100416)[0m              'critic_warmup': 0,
[36m(main_task pid=100416)[0m              'default_hdfs_dir': None,
[36m(main_task pid=100416)[0m              'default_local_dir': 'checkpoints/grpo/ppo7B_dapo17k_tok2k-test',
[36m(main_task pid=100416)[0m              'del_local_ckpt_after_load': False,
[36m(main_task pid=100416)[0m              'experiment_name': 'ppo7B_dapo17k_tok2k-test',
[36m(main_task pid=100416)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=100416)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=100416)[0m              'nnodes': 1,
[36m(main_task pid=100416)[0m              'project_name': 'grpo',
[36m(main_task pid=100416)[0m              'remove_previous_ckpt_in_save': False,
[36m(main_task pid=100416)[0m              'resume_from_path': False,
[36m(main_task pid=100416)[0m              'resume_mode': 'auto',
[36m(main_task pid=100416)[0m              'save_freq': -1,
[36m(main_task pid=100416)[0m              'test_freq': 5,
[36m(main_task pid=100416)[0m              'total_epochs': 10,
[36m(main_task pid=100416)[0m              'total_training_steps': 500,
[36m(main_task pid=100416)[0m              'val_before_train': False,
[36m(main_task pid=100416)[0m              'val_generations_to_log_to_wandb': 0,
[36m(main_task pid=100416)[0m              'val_only': False}}
[36m(main_task pid=100416)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=100416)[0m No module named 'vllm._version'
[36m(main_task pid=100416)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(main_task pid=100416)[0m 'We use curriculum learning.'
[36m(main_task pid=100416)[0m [validate_config] All configuration checks passed successfully!
[36m(main_task pid=100416)[0m dataset len: 1791700
[36m(main_task pid=100416)[0m Example prompt before filtering: The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.
[36m(main_task pid=100416)[0m 
[36m(main_task pid=100416)[0m In triangle $ABC$, $\sin \angle A = \frac{4}{5}$ and $\angle A < 90^\circ$. Let $D$ be a point outside triangle $ABC$ such that $\angle BAD = \angle DAC$ and $\angle BDC = 90^\circ$. Suppose that $AD = 1$ and that $\frac{BD}{CD} = \frac{3}{2}$. If $AB + AC$ can be expressed in the form $\frac{a\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$. Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=100416)[0m filter dataset len: 1786200
[36m(main_task pid=100416)[0m dataset len: 500
[36m(main_task pid=100416)[0m Example prompt before filtering: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\theta),$ where $r > 0$ and $0 \le \theta < 2 \pi.$ Let's think step by step and output the final answer within \boxed{}.
[36m(main_task pid=100416)[0m filter dataset len: 497
[36m(main_task pid=100416)[0m Reducing validation dataset from 497 to 496 examples to make it divisible by 4 GPUs
[36m(main_task pid=100416)[0m Size of train dataloader: 13954
[36m(main_task pid=100416)[0m Size of val dataloader: 1
[36m(main_task pid=100416)[0m Total training steps: 500
[36m(main_task pid=100416)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=102175)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=102175)[0m No module named 'vllm._version'
[36m(pid=102175)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=102442)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=102442)[0m No module named 'vllm._version'
[36m(pid=102442)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=102441)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=102441)[0m No module named 'vllm._version'
[36m(pid=102441)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=102175)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=102175)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=102175)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=102175)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=102442)[0m Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.00it/s]
[36m(WorkerDict pid=102442)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.45it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.53it/s]
[36m(WorkerDict pid=102442)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-7B and are newly initialized: ['score.bias']
[36m(WorkerDict pid=102442)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(pid=102443)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=102443)[0m No module named 'vllm._version'
[36m(pid=102443)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=102175)[0m Qwen2ForTokenClassification contains 7.07B parameters
[36m(WorkerDict pid=102175)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=102175)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-7B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=102443)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=102443)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102443)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102175)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=102442)[0m Total steps: 500, num_warmup_steps: 0
[36m(WorkerDict pid=102442)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=102175)[0m After critic FSDP, memory allocated (GB): 6.585044860839844, memory reserved (GB): 14.544921875
[36m(WorkerDict pid=102175)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=102175)[0m   "_name_or_path": "Qwen/Qwen2.5-7B",
[36m(WorkerDict pid=102175)[0m   "architectures": [
[36m(WorkerDict pid=102175)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=102175)[0m   ],
[36m(WorkerDict pid=102175)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=102175)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=102175)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=102175)[0m   "hidden_size": 3584,
[36m(WorkerDict pid=102175)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=102175)[0m   "intermediate_size": 18944,
[36m(WorkerDict pid=102175)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=102175)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=102175)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=102175)[0m   "num_attention_heads": 28,
[36m(WorkerDict pid=102175)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=102175)[0m   "num_key_value_heads": 4,
[36m(WorkerDict pid=102175)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=102175)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=102175)[0m   "rope_scaling": null,
[36m(WorkerDict pid=102175)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=102175)[0m   "sliding_window": null,
[36m(WorkerDict pid=102175)[0m   "tie_word_embeddings": false,
[36m(WorkerDict pid=102175)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=102175)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=102175)[0m   "use_cache": true,
[36m(WorkerDict pid=102175)[0m   "use_mrope": false,
[36m(WorkerDict pid=102175)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=102175)[0m   "vocab_size": 152064
[36m(WorkerDict pid=102175)[0m }
[36m(WorkerDict pid=102175)[0m 
[36m(WorkerDict pid=102175)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.37s/it][32m [repeated 11x across cluster][0m
[36m(WorkerDict pid=102175)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.27s/it][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102443)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-7B and are newly initialized: ['score.bias'][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=102175)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102175)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=102441)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=102175)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(WorkerDict pid=102175)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fc3685fc0d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fc3685bff40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=102443)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=102443)[0m Total steps: 500, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102443)[0m Critic use_remove_padding=False[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102443)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=102443)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.49it/s][32m [repeated 12x across cluster][0m
[36m(WorkerDict pid=102443)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.14it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.37it/s][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=102443)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=102175)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=102175)[0m   "_name_or_path": "Qwen/Qwen2.5-7B",
[36m(WorkerDict pid=102175)[0m   "architectures": [
[36m(WorkerDict pid=102175)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=102175)[0m   ],
[36m(WorkerDict pid=102175)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=102175)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=102175)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=102175)[0m   "hidden_size": 3584,
[36m(WorkerDict pid=102175)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=102175)[0m   "intermediate_size": 18944,
[36m(WorkerDict pid=102175)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=102175)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=102175)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=102175)[0m   "num_attention_heads": 28,
[36m(WorkerDict pid=102175)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=102175)[0m   "num_key_value_heads": 4,
[36m(WorkerDict pid=102175)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=102175)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=102175)[0m   "rope_scaling": null,
[36m(WorkerDict pid=102175)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=102175)[0m   "sliding_window": null,
[36m(WorkerDict pid=102175)[0m   "tie_word_embeddings": false,
[36m(WorkerDict pid=102175)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=102175)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=102175)[0m   "use_cache": true,
[36m(WorkerDict pid=102175)[0m   "use_mrope": false,
[36m(WorkerDict pid=102175)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=102175)[0m   "vocab_size": 152064
[36m(WorkerDict pid=102175)[0m }
[36m(WorkerDict pid=102175)[0m 
[36m(WorkerDict pid=102443)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f0164d180d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f0164cdff40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102175)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(WorkerDict pid=102441)[0m Actor use_remove_padding=True[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102175)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fc3685fc0d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fc3685bff40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=102442)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102175)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.42s/it][32m [repeated 12x across cluster][0m
[36m(WorkerDict pid=102175)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.39s/it][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=102175)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=102442)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f29a44380d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f29a43fff40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=102442)[0m Total steps: 500, num_warmup_steps: 0
[36m(WorkerDict pid=102175)[0m Before building vllm rollout, memory allocated (GB): 13.678153038024902, memory reserved (GB): 28.693359375
[36m(WorkerDict pid=102175)[0m model_hf_config.max_position_embeddings: 131072
[36m(WorkerDict pid=102441)[0m WARNING 04-21 00:07:31 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=102175)[0m Actor use_remove_padding=True[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=102443)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f0164d180d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f0164cdff40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=102441)[0m local rank 0
[36m(WorkerDict pid=102442)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=102175)[0m Total steps: 500, num_warmup_steps: 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102443)[0m model_hf_config.max_position_embeddings: 131072[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102175)[0m before init cache memory allocated: 30.009989632GB, reserved: 30.23044608GB
[36m(WorkerDict pid=102175)[0m after init cache memory allocated: 66.00550656GB, reserved: 66.225963008GB
[36m(WorkerDict pid=102442)[0m WARNING 04-21 00:07:31 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102442)[0m local rank 0[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102443)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 2048, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=102443)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=102443)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=102443)[0m   warnings.warn(
[36m(WorkerDict pid=102175)[0m After building vllm rollout, memory allocated (GB): 47.24077892303467, memory reserved (GB): 61.677734375
[36m(WorkerDict pid=102175)[0m After building sharding manager, memory allocated (GB): 47.24077892303467, memory reserved (GB): 61.677734375
[36m(main_task pid=100416)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=100416)[0m wandb: Currently logged in as: rqzhang (sample-efficient-RL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=100416)[0m wandb: Tracking run with wandb version 0.19.8
[36m(main_task pid=100416)[0m wandb: Run data is saved locally in /home/jovyan/project/verl/wandb/run-20250421_000738-8343ns3w
[36m(main_task pid=100416)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=100416)[0m wandb: Syncing run ppo7B_dapo17k_tok2k-test
[36m(main_task pid=100416)[0m wandb: ⭐️ View project at https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=100416)[0m wandb: 🚀 View run at https://wandb.ai/sample-efficient-RL/grpo/runs/8343ns3w
[36m(main_task pid=100416)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=100416)[0m '######################## Total training steps: 500 ########################'
[36m(main_task pid=100416)[0m 'Total training steps: 500'
[36m(main_task pid=100416)[0m Checkpoint tracker file does not exist: %s /home/jovyan/project/verl/checkpoints/grpo/ppo7B_dapo17k_tok2k-test/latest_checkpointed_iteration.txt
[36m(main_task pid=100416)[0m Training from scratch
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:58,681:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{34}'], Pred: ['<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:58,707:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=102441)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102441)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:58,828:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{38}'], Pred: [' Absolutely!<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:58,842:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{5}'], Pred: ['<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:58,861:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{118}'], Pred: ['<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:58,862:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2024}'], Pred: [' The answer to this problem is {5546} inches.<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:58,885:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{2504}'], Pred: ['<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:58,893:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{875}'], Pred: ['<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:58,943:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-3}'], Pred: ['<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:59,025:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{192}'], Pred: ['<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:59,041:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{7}'], Pred: [' Reference material found at https://en.wikipedia.org/wiki/Cubic_function<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:59,054:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{4}'], Pred: ['<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:59,061:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{14}'], Pred: ['<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:59,115:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{1537}'], Pred: ['<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:59,120:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{80}'], Pred: ['<|endoftext|>']
[36m(main_task pid=100416)[0m WARNING:2025-04-21 00:08:59,123:We did not manage to extract a prediction in the correct format. Gold: ['\\boxed{-1}'], Pred: ['<|endoftext|>']
[36m(WorkerDict pid=102175)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=102175)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
[36m(WorkerDict pid=102442)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=102442)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 4x across cluster][0m
[36m(main_task pid=100416)[0m step:1 - global_seqlen/min:20274.000 - global_seqlen/max:23672.000 - global_seqlen/minmax_diff:3398.000 - global_seqlen/balanced_min:22483.000 - global_seqlen/balanced_max:22493.000 - global_seqlen/mean:22489.750 - critic/kl:0.001 - critic/kl_coeff:0.001 - critic/vf_loss:8.443 - critic/vf_clipfrac:0.000 - critic/vpred_mean:-1.530 - critic/grad_norm:505.608 - perf/mfu/critic:0.110 - critic/lr:0.000 - actor/entropy_loss:0.817 - actor/pg_loss:-0.001 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.349 - perf/mfu/actor:0.134 - perf/max_memory_allocated_gb:68.560 - perf/max_memory_reserved_gb:76.998 - perf/cpu_memory_used_gb:110.210 - actor/lr:0.000 - critic/score/mean:0.148 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.149 - critic/rewards/max:1.002 - critic/rewards/min:-0.002 - critic/advantages/mean:0.000 - critic/advantages/max:4.438 - critic/advantages/min:-5.310 - critic/returns/mean:0.185 - critic/returns/max:1.002 - critic/returns/min:-0.002 - critic/values/mean:-1.148 - critic/values/max:19.500 - critic/values/min:-18.750 - critic/vf_explained_var:-101.044 - response_length/mean:571.336 - response_length/max:2048.000 - response_length/min:1.000 - response_length/clip_ratio:0.031 - prompt_length/mean:131.469 - prompt_length/max:476.000 - prompt_length/min:56.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:46.131 - timing_s/old_log_prob:7.372 - timing_s/ref:18.185 - timing_s/values:6.725 - timing_s/adv:1.012 - timing_s/update_critic:30.849 - timing_s/update_actor:25.206 - timing_s/step:135.498 - timing_per_token_ms/adv:0.011 - timing_per_token_ms/ref:0.202 - timing_per_token_ms/update_actor:0.280 - timing_per_token_ms/values:0.075 - timing_per_token_ms/gen:0.631 - timing_per_token_ms/update_critic:0.343 - perf/total_num_tokens:89959.000 - perf/time_per_step:135.498 - perf/throughput:165.979
[36m(WorkerDict pid=102441)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 2048, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 3x across cluster][0m
[36m(main_task pid=100416)[0m wandb:                                                                                
[36m(main_task pid=100416)[0m wandb: 
[36m(main_task pid=100416)[0m wandb: Run history:
[36m(main_task pid=100416)[0m wandb:                actor/entropy_loss ▁
[36m(main_task pid=100416)[0m wandb:                   actor/grad_norm ▁
[36m(main_task pid=100416)[0m wandb:                          actor/lr ▁
[36m(main_task pid=100416)[0m wandb:                 actor/pg_clipfrac ▁
[36m(main_task pid=100416)[0m wandb:                     actor/pg_loss ▁
[36m(main_task pid=100416)[0m wandb:                      actor/ppo_kl ▁
[36m(main_task pid=100416)[0m wandb:             critic/advantages/max ▁
[36m(main_task pid=100416)[0m wandb:            critic/advantages/mean ▁
[36m(main_task pid=100416)[0m wandb:             critic/advantages/min ▁
[36m(main_task pid=100416)[0m wandb:                  critic/grad_norm ▁
[36m(main_task pid=100416)[0m wandb:                         critic/kl ▁
[36m(main_task pid=100416)[0m wandb:                   critic/kl_coeff ▁
[36m(main_task pid=100416)[0m wandb:                         critic/lr ▁
[36m(main_task pid=100416)[0m wandb:                critic/returns/max ▁
[36m(main_task pid=100416)[0m wandb:               critic/returns/mean ▁
[36m(main_task pid=100416)[0m wandb:                critic/returns/min ▁
[36m(main_task pid=100416)[0m wandb:                critic/rewards/max ▁
[36m(main_task pid=100416)[0m wandb:               critic/rewards/mean ▁
[36m(main_task pid=100416)[0m wandb:                critic/rewards/min ▁
[36m(main_task pid=100416)[0m wandb:                  critic/score/max ▁
[36m(main_task pid=100416)[0m wandb:                 critic/score/mean ▁
[36m(main_task pid=100416)[0m wandb:                  critic/score/min ▁
[36m(main_task pid=100416)[0m wandb:                 critic/values/max ▁
[36m(main_task pid=100416)[0m wandb:                critic/values/mean ▁
[36m(main_task pid=100416)[0m wandb:                 critic/values/min ▁
[36m(main_task pid=100416)[0m wandb:                critic/vf_clipfrac ▁
[36m(main_task pid=100416)[0m wandb:           critic/vf_explained_var ▁
[36m(main_task pid=100416)[0m wandb:                    critic/vf_loss ▁
[36m(main_task pid=100416)[0m wandb:                 critic/vpred_mean ▁
[36m(main_task pid=100416)[0m wandb:        global_seqlen/balanced_max ▁
[36m(main_task pid=100416)[0m wandb:        global_seqlen/balanced_min ▁
[36m(main_task pid=100416)[0m wandb:                 global_seqlen/max ▁
[36m(main_task pid=100416)[0m wandb:                global_seqlen/mean ▁
[36m(main_task pid=100416)[0m wandb:                 global_seqlen/min ▁
[36m(main_task pid=100416)[0m wandb:         global_seqlen/minmax_diff ▁
[36m(main_task pid=100416)[0m wandb:           perf/cpu_memory_used_gb ▁
[36m(main_task pid=100416)[0m wandb:      perf/max_memory_allocated_gb ▁
[36m(main_task pid=100416)[0m wandb:       perf/max_memory_reserved_gb ▁
[36m(main_task pid=100416)[0m wandb:                    perf/mfu/actor ▁
[36m(main_task pid=100416)[0m wandb:                   perf/mfu/critic ▁
[36m(main_task pid=100416)[0m wandb:                   perf/throughput ▁
[36m(main_task pid=100416)[0m wandb:                perf/time_per_step ▁
[36m(main_task pid=100416)[0m wandb:             perf/total_num_tokens ▁
[36m(main_task pid=100416)[0m wandb:          prompt_length/clip_ratio ▁
[36m(main_task pid=100416)[0m wandb:                 prompt_length/max ▁
[36m(main_task pid=100416)[0m wandb:                prompt_length/mean ▁
[36m(main_task pid=100416)[0m wandb:                 prompt_length/min ▁
[36m(main_task pid=100416)[0m wandb:        response_length/clip_ratio ▁
[36m(main_task pid=100416)[0m wandb:               response_length/max ▁
[36m(main_task pid=100416)[0m wandb:              response_length/mean ▁
[36m(main_task pid=100416)[0m wandb:               response_length/min ▁
[36m(main_task pid=100416)[0m wandb:           timing_per_token_ms/adv ▁
[36m(main_task pid=100416)[0m wandb:           timing_per_token_ms/gen ▁
[36m(main_task pid=100416)[0m wandb:           timing_per_token_ms/ref ▁
[36m(main_task pid=100416)[0m wandb:  timing_per_token_ms/update_actor ▁
[36m(main_task pid=100416)[0m wandb: timing_per_token_ms/update_critic ▁
[36m(main_task pid=100416)[0m wandb:        timing_per_token_ms/values ▁
[36m(main_task pid=100416)[0m wandb:                      timing_s/adv ▁
[36m(main_task pid=100416)[0m wandb:                      timing_s/gen ▁
[36m(main_task pid=100416)[0m wandb:             timing_s/old_log_prob ▁
[36m(main_task pid=100416)[0m wandb:                      timing_s/ref ▁
[36m(main_task pid=100416)[0m wandb:                     timing_s/step ▁
[36m(main_task pid=100416)[0m wandb:             timing_s/update_actor ▁
[36m(main_task pid=100416)[0m wandb:            timing_s/update_critic ▁
[36m(main_task pid=100416)[0m wandb:                   timing_s/values ▁
[36m(main_task pid=100416)[0m wandb: 
[36m(main_task pid=100416)[0m wandb: Run summary:
[36m(main_task pid=100416)[0m wandb:                actor/entropy_loss 0.81686
[36m(main_task pid=100416)[0m wandb:                   actor/grad_norm 0.34906
[36m(main_task pid=100416)[0m wandb:                          actor/lr 0.0
[36m(main_task pid=100416)[0m wandb:                 actor/pg_clipfrac 0
[36m(main_task pid=100416)[0m wandb:                     actor/pg_loss -0.00107
[36m(main_task pid=100416)[0m wandb:                      actor/ppo_kl 0
[36m(main_task pid=100416)[0m wandb:             critic/advantages/max 4.43785
[36m(main_task pid=100416)[0m wandb:            critic/advantages/mean 0.0
[36m(main_task pid=100416)[0m wandb:             critic/advantages/min -5.31011
[36m(main_task pid=100416)[0m wandb:                  critic/grad_norm 505.60805
[36m(main_task pid=100416)[0m wandb:                         critic/kl 0.00054
[36m(main_task pid=100416)[0m wandb:                   critic/kl_coeff 0.001
[36m(main_task pid=100416)[0m wandb:                         critic/lr 1e-05
[36m(main_task pid=100416)[0m wandb:                critic/returns/max 1.00201
[36m(main_task pid=100416)[0m wandb:               critic/returns/mean 0.18524
[36m(main_task pid=100416)[0m wandb:                critic/returns/min -0.00182
[36m(main_task pid=100416)[0m wandb:                critic/rewards/max 1.00158
[36m(main_task pid=100416)[0m wandb:               critic/rewards/mean 0.14852
[36m(main_task pid=100416)[0m wandb:                critic/rewards/min -0.00162
[36m(main_task pid=100416)[0m wandb:                  critic/score/max 1
[36m(main_task pid=100416)[0m wandb:                 critic/score/mean 0.14844
[36m(main_task pid=100416)[0m wandb:                  critic/score/min 0
[36m(main_task pid=100416)[0m wandb:                 critic/values/max 19.5
[36m(main_task pid=100416)[0m wandb:                critic/values/mean -1.14844
[36m(main_task pid=100416)[0m wandb:                 critic/values/min -18.75
[36m(main_task pid=100416)[0m wandb:                critic/vf_clipfrac 0
[36m(main_task pid=100416)[0m wandb:           critic/vf_explained_var -101.04446
[36m(main_task pid=100416)[0m wandb:                    critic/vf_loss 8.443
[36m(main_task pid=100416)[0m wandb:                 critic/vpred_mean -1.52966
[36m(main_task pid=100416)[0m wandb:        global_seqlen/balanced_max 22493
[36m(main_task pid=100416)[0m wandb:        global_seqlen/balanced_min 22483
[36m(main_task pid=100416)[0m wandb:                 global_seqlen/max 23672
[36m(main_task pid=100416)[0m wandb:                global_seqlen/mean 22489.75
[36m(main_task pid=100416)[0m wandb:                 global_seqlen/min 20274
[36m(main_task pid=100416)[0m wandb:         global_seqlen/minmax_diff 3398
[36m(main_task pid=100416)[0m wandb:           perf/cpu_memory_used_gb 110.20998
[36m(main_task pid=100416)[0m wandb:      perf/max_memory_allocated_gb 68.56042
[36m(main_task pid=100416)[0m wandb:       perf/max_memory_reserved_gb 76.99805
[36m(main_task pid=100416)[0m wandb:                    perf/mfu/actor 0.1342
[36m(main_task pid=100416)[0m wandb:                   perf/mfu/critic 0.10965
[36m(main_task pid=100416)[0m wandb:                   perf/throughput 165.97857
[36m(main_task pid=100416)[0m wandb:                perf/time_per_step 135.49791
[36m(main_task pid=100416)[0m wandb:             perf/total_num_tokens 89959
[36m(main_task pid=100416)[0m wandb:          prompt_length/clip_ratio 0
[36m(main_task pid=100416)[0m wandb:                 prompt_length/max 476
[36m(main_task pid=100416)[0m wandb:                prompt_length/mean 131.46875
[36m(main_task pid=100416)[0m wandb:                 prompt_length/min 56
[36m(main_task pid=100416)[0m wandb:        response_length/clip_ratio 0.03125
[36m(main_task pid=100416)[0m wandb:               response_length/max 2048
[36m(main_task pid=100416)[0m wandb:              response_length/mean 571.33594
[36m(main_task pid=100416)[0m wandb:               response_length/min 1
[36m(main_task pid=100416)[0m wandb:           timing_per_token_ms/adv 0.01125
[36m(main_task pid=100416)[0m wandb:           timing_per_token_ms/gen 0.63081
[36m(main_task pid=100416)[0m wandb:           timing_per_token_ms/ref 0.20215
[36m(main_task pid=100416)[0m wandb:  timing_per_token_ms/update_actor 0.2802
[36m(main_task pid=100416)[0m wandb: timing_per_token_ms/update_critic 0.34292
[36m(main_task pid=100416)[0m wandb:        timing_per_token_ms/values 0.07476
[36m(main_task pid=100416)[0m wandb:                      timing_s/adv 1.01192
[36m(main_task pid=100416)[0m wandb:                      timing_s/gen 46.13141
[36m(main_task pid=100416)[0m wandb:             timing_s/old_log_prob 7.3719
[36m(main_task pid=100416)[0m wandb:                      timing_s/ref 18.18505
[36m(main_task pid=100416)[0m wandb:                     timing_s/step 135.49791
[36m(main_task pid=100416)[0m wandb:             timing_s/update_actor 25.20617
[36m(main_task pid=100416)[0m wandb:            timing_s/update_critic 30.84878
[36m(main_task pid=100416)[0m wandb:                   timing_s/values 6.72498
[36m(main_task pid=100416)[0m wandb: 
[36m(main_task pid=100416)[0m wandb: 🚀 View run ppo7B_dapo17k_tok2k-test at: https://wandb.ai/sample-efficient-RL/grpo/runs/8343ns3w
[36m(main_task pid=100416)[0m wandb: ⭐️ View project at: https://wandb.ai/sample-efficient-RL/grpo
[36m(main_task pid=100416)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[36m(main_task pid=100416)[0m wandb: Find logs at: ./wandb/run-20250421_000738-8343ns3w/logs
[36m(WorkerDict pid=102443)[0m /home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102443)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 3x across cluster][0m
[36m(main_task pid=100416)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=102442, ip=192.168.102.77, actor_id=6e26f8939b7b649b1942bd4d0f000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f29582f57b0>)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=100416)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=100416)[0m     return func(*args, **kwargs)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 513, in generate_sequences
[36m(main_task pid=100416)[0m     output = self.rollout.generate_sequences(prompts=prompts)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(main_task pid=100416)[0m     return func(*args, **kwargs)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 161, in generate_sequences
[36m(main_task pid=100416)[0m     self.inference_engine.init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 146, in init_cache_engine
[36m(main_task pid=100416)[0m     self.llm_engine.init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 347, in init_cache_engine
[36m(main_task pid=100416)[0m     self.model_executor.init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 157, in init_cache_engine
[36m(main_task pid=100416)[0m     self.worker._init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 237, in _init_cache_engine
[36m(main_task pid=100416)[0m     super()._init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 275, in _init_cache_engine
[36m(main_task pid=100416)[0m     self.cache_engine = [
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 276, in <listcomp>
[36m(main_task pid=100416)[0m     CacheEngine(self.cache_config, self.model_config,
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 63, in __init__
[36m(main_task pid=100416)[0m     self.gpu_cache = self._allocate_kv_cache(
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 82, in _allocate_kv_cache
[36m(main_task pid=100416)[0m     torch.zeros(kv_cache_shape,
[36m(main_task pid=100416)[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 142.75 MiB is free. Process 281040 has 79.08 GiB memory in use. Of the allocated memory 75.59 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[36m(main_task pid=100416)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=102175, ip=192.168.102.77, actor_id=db71059fbd924ea3c45ddef00f000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7fc30547dcf0>)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=100416)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=100416)[0m     return func(*args, **kwargs)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 513, in generate_sequences
[36m(main_task pid=100416)[0m     output = self.rollout.generate_sequences(prompts=prompts)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(main_task pid=100416)[0m     return func(*args, **kwargs)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 161, in generate_sequences
[36m(main_task pid=100416)[0m     self.inference_engine.init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 146, in init_cache_engine
[36m(main_task pid=100416)[0m     self.llm_engine.init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 347, in init_cache_engine
[36m(main_task pid=100416)[0m     self.model_executor.init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 157, in init_cache_engine
[36m(main_task pid=100416)[0m     self.worker._init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 237, in _init_cache_engine
[36m(main_task pid=100416)[0m     super()._init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 275, in _init_cache_engine
[36m(main_task pid=100416)[0m     self.cache_engine = [
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 276, in <listcomp>
[36m(main_task pid=100416)[0m     CacheEngine(self.cache_config, self.model_config,
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 63, in __init__
[36m(main_task pid=100416)[0m     self.gpu_cache = self._allocate_kv_cache(
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 82, in _allocate_kv_cache
[36m(main_task pid=100416)[0m     torch.zeros(kv_cache_shape,
[36m(main_task pid=100416)[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 744.75 MiB is free. Process 280664 has 78.49 GiB memory in use. Of the allocated memory 74.45 GiB is allocated by PyTorch, and 2.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[36m(main_task pid=100416)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=102441, ip=192.168.102.77, actor_id=6f397bc25c87b3edd55b80c10f000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7fb03cd20880>)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
[36m(main_task pid=100416)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=100416)[0m     return func(*args, **kwargs)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 513, in generate_sequences
[36m(main_task pid=100416)[0m     output = self.rollout.generate_sequences(prompts=prompts)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(main_task pid=100416)[0m     return func(*args, **kwargs)
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 161, in generate_sequences
[36m(main_task pid=100416)[0m     self.inference_engine.init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 146, in init_cache_engine
[36m(main_task pid=100416)[0m     self.llm_engine.init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 347, in init_cache_engine
[36m(main_task pid=100416)[0m     self.model_executor.init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 157, in init_cache_engine
[36m(main_task pid=100416)[0m     self.worker._init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 237, in _init_cache_engine
[36m(main_task pid=100416)[0m     super()._init_cache_engine()
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 275, in _init_cache_engine
[36m(main_task pid=100416)[0m     self.cache_engine = [
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 276, in <listcomp>
[36m(main_task pid=100416)[0m     CacheEngine(self.cache_config, self.model_config,
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 63, in __init__
[36m(main_task pid=100416)[0m     self.gpu_cache = self._allocate_kv_cache(
[36m(main_task pid=100416)[0m   File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 82, in _allocate_kv_cache
[36m(main_task pid=100416)[0m     torch.zeros(kv_cache_shape,
[36m(main_task pid=100416)[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 14.75 MiB is free. Process 281039 has 79.21 GiB memory in use. Of the allocated memory 75.59 GiB is allocated by PyTorch, and 1.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: ['data.train_files=./data/DAPO-17k-base/train.parquet', 'data.val_files=./data/math500-base/test.parquet', 'data.train_batch_size=128', 'data.max_prompt_length=512', 'data.max_response_length=2048', 'data.filter_overlong_prompts=True', 'data.use_chat_template=False', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-7B', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.optim.lr=5e-7', 'actor_rollout_ref.actor.use_dynamic_bsz=False', 'actor_rollout_ref.actor.use_doctor_grpo=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=32', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=1', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.max_num_batched_tokens=9216', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.val_kwargs.n=1', 'actor_rollout_ref.rollout.compute_prompts_values=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=1', 'critic.optim.lr=5e-6', 'critic.model.path=Qwen/Qwen2.5-7B', 'critic.ppo_micro_batch_size_per_gpu=1', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[console,wandb]', '+trainer.val_before_train=False', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=4', 'trainer.total_training_steps=500', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=5', 'trainer.project_name=grpo', 'trainer.experiment_name=ppo7B_dapo17k_tok2k-test', 'trainer.total_epochs=10', 'curriculum.use_curriculum_learning=True', 'curriculum.train_batch_size_pool=2048', 'curriculum.warmup_steps=3']
Traceback (most recent call last):
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 54, in main
    run_ppo(config)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 71, in run_ppo
    ray.get(main_task.remote(config))
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::main_task()[39m (pid=100416, ip=192.168.102.77)
  File "/home/jovyan/project/verl/verl/trainer/main_ppo.py", line 179, in main_task
    trainer.fit() # RZ: runs as a single process.
  File "/home/jovyan/project/verl/verl/trainer/ppo/ray_trainer.py", line 1064, in fit
    gen_batch_output = self.actor_rollout_wg.generate_sequences(gen_batch)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=102443, ip=192.168.102.77, actor_id=5a499fdf13d7074daa10d7e10f000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f0118b9d7b0>)
  File "/home/jovyan/project/verl/verl/single_controller/ray/base.py", line 419, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/workers/fsdp_workers.py", line 513, in generate_sequences
    output = self.rollout.generate_sequences(prompts=prompts)
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jovyan/project/verl/verl/workers/rollout/vllm_rollout/vllm_rollout.py", line 161, in generate_sequences
    self.inference_engine.init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm.py", line 146, in init_cache_engine
    self.llm_engine.init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/llm_engine_sp.py", line 347, in init_cache_engine
    self.model_executor.init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/spmd_gpu_executor.py", line 157, in init_cache_engine
    self.worker._init_cache_engine()
  File "/home/jovyan/project/verl/verl/third_party/vllm/vllm_v_0_6_3/worker.py", line 237, in _init_cache_engine
    super()._init_cache_engine()
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 275, in _init_cache_engine
    self.cache_engine = [
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/worker.py", line 276, in <listcomp>
    CacheEngine(self.cache_config, self.model_config,
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 63, in __init__
    self.gpu_cache = self._allocate_kv_cache(
  File "/home/jovyan/project/miniconda/envs/verl/lib/python3.10/site-packages/vllm/worker/cache_engine.py", line 82, in _allocate_kv_cache
    torch.zeros(kv_cache_shape,
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 352.75 MiB is free. Process 281041 has 78.88 GiB memory in use. Of the allocated memory 75.66 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
